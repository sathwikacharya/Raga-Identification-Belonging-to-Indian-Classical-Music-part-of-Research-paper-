{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of RagaClass-FeatureExtraction+Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vtUfs1dSVny9",
        "0tJE0GAKV23p",
        "mudDHU__WQjs",
        "C505xrRMWUfW",
        "ee2tiasjcrjQ",
        "6e1ds6rGWlmb",
        "yb5rlMcAQfWM",
        "q0-ESm45Qrit",
        "svfT6Pg7QrjD",
        "QivMgCiyQrjU"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtUfs1dSVny9",
        "colab_type": "text"
      },
      "source": [
        "#Feature Extraction(skip if .csv made)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX_8ltaHtCQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axmeu3bkt1LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl https://sdk.cloud.google.com | bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cRTOxBSuSGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://ragaclass/raga.zip ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkdjCmMxsQ-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3b5185-9d13-47ab-a0bf-a519877f8f6b"
      },
      "source": [
        "!gsutil cp 'gs://ragaclass/New Data.zip' ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://ragaclass/New Data.zip...\n",
            "- [1 files][  1.7 GiB/  1.7 GiB]   11.0 MiB/s                                   \n",
            "Operation completed over 1 objects/1.7 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdcnUkqoxzfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unrar raga.zip .\n",
        "!rm raga.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8nFojn3sgdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26dced2-7213-4470-a285-0251ff3fe7ed"
      },
      "source": [
        "!unzip '/content/New Data.zip' -d /content/Audio/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/New Data.zip\n",
            "   creating: /content/Audio/New Data/\n",
            "   creating: /content/Audio/New Data/darbar/\n",
            "  inflating: /content/Audio/New Data/darbar/Aruna Sairam - Adiya Pada Darishanam.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Bombay Jayashri - Munduvenuga.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/M. S. Gopalakrishnan - Ramabhirama.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/M. S. Gopalakrishnan - Yachana.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Maharajapuram Santhanam - Mundu Venuga.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Prasanna Venkataraman - Chalamela Jesevura.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Prasanna Venkataraman - Mundu Venuga.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/R. K. Srikantan - Shoure.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/S. Ramanathan - Chalamela.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Sangeetha Swaminathan - Mundu Venuga.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Sanjay Subrahmanyan - Mundu Venuga.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Sanjay Subrahmanyan - Munduvenuka.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/T. N. Seshagopalan - Nayakanai Ninra.mp3  \n",
            "  inflating: /content/Audio/New Data/darbar/T. R. Mahalingam - Yochana.mp3  \n",
            "   creating: /content/Audio/New Data/jaganmohini/\n",
            "  inflating: /content/Audio/New Data/jaganmohini/Dr Pantula Rama - So Billu Saptaswara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/G. N. Balasubramaniam - So Billu Saptaswara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Hyderabad Brothers - Sobhillu Sapthaswara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/M. L. Vasanthakumari - Sivakama Sundari.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/M. S. Gopalakrishnan - So Billu Saptaswara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Modhumudi Sudhakar - Shobillu Saptasvara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Parassala Ponnammal - Pahittarakshu.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/R Vedavalli - Sri vidya rajagopalam.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Sikkil Sisters - So Billu Saptaswara.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Sumithra Vasudev - Sri Vidhya Rajagopala.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/T M Thiagarajan - Sivakama.mp3  \n",
            "  inflating: /content/Audio/New Data/jaganmohini/Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3  \n",
            "   creating: /content/Audio/New Data/jaunpuri/\n",
            "  inflating: /content/Audio/New Data/jaunpuri/Amritha Murali - Sapashyat.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Aruna Sairam - Nittiraiyil.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/K.V. Narayanaswami - Dasaratha Sutha.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Madurai Mani Iyer - Eppo Paduvaro.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Madurai Mani Iyer - Eppo Varuvaro.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Rithvik Raja - Sapasyat Kausalya.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Sanjay Subrahmanyan - Malaasai Kobam.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Sanjay Subrahmanyan - Malasai.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Srividya Janakiraman - Nenindal Agaadadu undo.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/T. V. Sankaranarayanan - Yeppo Varuvaro.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Unnikrishnan - Eppo Varuvaro.mp3  \n",
            "  inflating: /content/Audio/New Data/jaunpuri/Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3  \n",
            "   creating: /content/Audio/New Data/mayamalava gaula/\n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Amritha Murali - Vidulaku.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Amrutha Venkatesh - Vidulaku Mrokkeda.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Aruna Sairam - Vidulaku Mrokkeda.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/D. K. Pattammal - Vaiyagam Parano.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Gayathri Venkataraghavan - Deva Deva Kalayami.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Jayanthi Kumaresh - Meru Samana.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/K.V. Narayanaswami - Sarasija Nabha.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/M. D. Ramanathan - Maya Tita Swaroopini.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Musiri Subramania Iyer - Merusamana.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Nisha P Rajagopal - Deva Deva Kalayami.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Sangeetha Swaminathan - Sri Raja Rajeswari.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3  \n",
            "  inflating: /content/Audio/New Data/mayamalava gaula/T. Brinda - Meru Samana.mp3  \n",
            "   creating: /content/Audio/New Data/ragamalika/\n",
            "  inflating: /content/Audio/New Data/ragamalika/- Simhasanasthithey.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Dandapani Desikar - Nalla Penmani.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/E Gayathri - Sri Chakra Raja Nilaya.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/G. N. Balasubramaniam - Slokam.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/K.V. Narayanaswami - Jaya Jaya Vande.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Maharajapuram S Ramachandran - Tunga Teera.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Nithyasree Mahadevan - Tillana.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Semmangudi Srinivasa Iyer - Slokam.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Sikkil Gurucharan - Maitreem Bhajata.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Sumithra Vasudev - Gurupaduka Stotram.mp3  \n",
            "  inflating: /content/Audio/New Data/ragamalika/Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3  \n",
            "New Data/ragamalika/Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3:  mismatching \"local\" filename (New Data/ragamalika/Vijay Siva - Sri Saradha Bujanga Prayadashtakam тАУ Ragamalika.mp3),\n",
            "         continuing with \"central\" filename version\n",
            "  inflating: /content/Audio/New Data/ragamalika/Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3  \n",
            "   creating: /content/Audio/New Data/shanmukhapriya/\n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Abhishek Raghuram - Sadaanandamu.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Akkarai Sisters - Siddhi Vinayakam.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Aruna Sairam - Vellai Panivade Yen Vellai.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Dr Pantula Rama - Maamava Karunaya.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Lalgudi Jayaraman - Vaddhane.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Maharajapuram Santhanam - Vilayada Idu Nerama.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Mahati - Ragam Tanam Pallavi.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Nedunuri Krishnamurthy - Sharavana Bhava.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Nithyasree Mahadevan - Velan Varuvaradi.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/S. Sowmya - Kandanai Nesithaal.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Sanjay Subrahmanyan - Saravanabhava Enum.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/Sheik Chinna Moulana - Vallinayagane.mp3  \n",
            "  inflating: /content/Audio/New Data/shanmukhapriya/T K Rangachari - Kannanai Pani Maname.mp3  \n",
            "   creating: /content/Audio/New Data/varali/\n",
            "  inflating: /content/Audio/New Data/varali/- Azhi Mazhai.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Amritha Murali - Kamakshi.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Amritha Murali - Karunaelagante.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Aruna Sairam - Eti Janmam.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/E Gayathri - Kamakshi.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Gayathri Venkataraghavan - Seshachalanayakam.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Madurai Mani Iyer - Ka Va Va.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Maharajapuram S Ramachandran - Seshachala Nayakam.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Nisha P Rajagopal - Mamava Minakshi.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Ranjani _ Gayathri - Eti Janmam.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Sanjay Subrahmanyan - Eti Janmam.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/Semmangudi Srinivasa Iyer - Kaa Va Va.mp3  \n",
            "  inflating: /content/Audio/New Data/varali/T K Rangachari - Nepokada.mp3  \n",
            "   creating: /content/Audio/New Data/vasanta/\n",
            "  inflating: /content/Audio/New Data/vasanta/Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/D. K. Pattammal - Rama Rama.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Dr Pantula Rama - Ninnu Kori.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/G. N. Balasubramaniam - Ramachandram.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Gayathri Girish - Seetamma Maayyama.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Gayathri Venkataraghavan - Hari Hara Putram.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/KP Nandini - Seethamma.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Kunnakkudi M Balamuralikrishna - Etla Tori.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/M. D. Ramanathan - Ramachandram Bhavayami.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/M.S. Subbulakshmi - Hariharaputram.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Nisha P Rajagopal - Malmaruga Shanmukha.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/S. Sowmya - Maranam Agattra.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Semmangudi Srinivasa Iyer - Hariharaputram.mp3  \n",
            "  inflating: /content/Audio/New Data/vasanta/Sikkil Gurucharan - Ninnukori Yunnanura.mp3  \n",
            "   creating: /content/Audio/New Data/yadukula kambhoji/\n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Abhishek Raghuram - Sri Rama Jaya Rama.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/K.V. Narayanaswami - Bhujaga Sayinam.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/M. D. Ramanathan - Srirama Raghurama.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Madurai Mani Iyer - Diwakara Tanujam.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Parassala Ponnammal - Bhujaga Sayinam.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Parassala Ponnammal - Mohanamayee.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/S. Ramanathan - Hecharikaga Rara.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/S. Sowmya - Diwakara Tanujam.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/Sanjay Subrahmanyan - Kalai Tukki.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/T K Rangachari - Etavuna.mp3  \n",
            "  inflating: /content/Audio/New Data/yadukula kambhoji/T. Brinda - Ninnusevinchina.mp3  \n",
            "   creating: /content/Audio/New Data/yamuna kalyani/\n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Amrutha Venkatesh - Nandagopala.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Ananthalakshmi Sadagopan - Chalo Mana.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Aneesh Vidyashankar - Krishna Nee Begane.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Aruna Sairam - Krishna Nee Begane.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Bombay Jayashri - Thillana.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Kadri Gopalnath - Krishna Nee Begane.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Kuldeep Pai - Krishna Nee Begane Baaro.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Kuldeep Pai - Vasudeva Sutam Devam.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/M.S. Subbulakshmi - Pibare Ramarasam.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Maharajapuram Santhanam - Nadagopala.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Maharajapuram Santhanam - Vandheham Sharadham.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Nisha P Rajagopal - Veera Sutantiram.mp3  \n",
            "  inflating: /content/Audio/New Data/yamuna kalyani/Sanjay Subrahmanyan - Nanda Gopala.mp3  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjCfu0ldWNSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcEl8VFLVz8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns=['filename','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19','raga']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "ragas=os.listdir('/content/content/Audio/')\n",
        "for raga in ragas:\n",
        "  path = '/content/content/Audio/'+raga\n",
        "  musics=os.listdir(path)\n",
        "  for name in musics:\n",
        "    vocals=path+'/'+name+'/'+'vocals.wav'\n",
        "    songname=vocals\n",
        "    filename=name\n",
        "    y, sr = librosa.load(songname, mono=True)\n",
        "    dur = librosa.get_duration(y=y, sr=sr)\n",
        "    off=0\n",
        "\n",
        "\n",
        "    if dur > 300:\n",
        "      for i in range(10):\n",
        "        x, sr = librosa.load(songname, mono=True,offset=off,duration=30)\n",
        "        rmse = librosa.feature.rmse(y=x)[0]\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(x)\n",
        "        mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "        filename = name+'-'+str(i+1)\n",
        "        data=[filename,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19]),raga]\n",
        "        dataseries = pd.Series(data, index = dataset.columns)\n",
        "        dataset = dataset.append(dataseries, ignore_index=True)\n",
        "        print(filename+\" \"+raga+\" added\" + 'dur '+str(dur))\n",
        "        if i in range(0,3):\n",
        "          off=off+30\n",
        "        if i in range(3,7):\n",
        "          off=(dur/10)*i\n",
        "        if i in range(7,10):\n",
        "          off= dur - ((10-i)*30)\n",
        "\n",
        "    else:\n",
        "      for i in range(10):\n",
        "        x, sr = librosa.load(songname, mono=True,offset=off,duration=(dur/10))\n",
        "        rmse = librosa.feature.rmse(y=x)[0]\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(x)\n",
        "        mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "        filename = name+'-'+str(i+1)\n",
        "        data=[filename,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19]),raga]\n",
        "        dataseries = pd.Series(data, index = dataset.columns)\n",
        "        dataset = dataset.append(dataseries, ignore_index=True)\n",
        "        print(filename+\" \"+raga+\" added(small)\"+'dur '+str(dur))\n",
        "        off=(dur/10)*(i)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ImxrGdehVcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff27618-8eee-4fe6-fd9e-b53d4df2c547"
      },
      "source": [
        "columns=['filename','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19','raga']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "ragas=os.listdir('/content/Audio/New Data/')\n",
        "for raga in ragas:\n",
        "  path = '/content/Audio/New Data/'+raga\n",
        "  musics=os.listdir(path)\n",
        "  for name in musics:\n",
        "    vocals=path+'/'+name\n",
        "    songname=vocals\n",
        "    filename=name\n",
        "    y, sr = librosa.load(songname, mono=True)\n",
        "    dur = librosa.get_duration(y=y, sr=sr)\n",
        "    off=0\n",
        "\n",
        "\n",
        "    if dur > 300:\n",
        "      for i in range(10):\n",
        "        x, sr = librosa.load(songname, mono=True,offset=off,duration=30)\n",
        "        rmse = librosa.feature.rmse(y=x)[0]\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(x)\n",
        "        mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "        filename = name+'-'+str(i+1)\n",
        "        data=[filename,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19]),raga]\n",
        "        dataseries = pd.Series(data, index = dataset.columns)\n",
        "        dataset = dataset.append(dataseries, ignore_index=True)\n",
        "        print(filename+\" \"+raga+\" added\" + 'dur '+str(dur))\n",
        "        if i in range(0,3):\n",
        "          off=off+30\n",
        "        if i in range(3,7):\n",
        "          off=(dur/10)*i\n",
        "        if i in range(7,10):\n",
        "          off= dur - ((10-i)*30)\n",
        "\n",
        "    else:\n",
        "      for i in range(10):\n",
        "        x, sr = librosa.load(songname, mono=True,offset=off,duration=(dur/10))\n",
        "        rmse = librosa.feature.rmse(y=x)[0]\n",
        "        chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "        spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "        spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "        rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(x)\n",
        "        mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "        filename = name+'-'+str(i+1)\n",
        "        data=[filename,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19]),raga]\n",
        "        dataseries = pd.Series(data, index = dataset.columns)\n",
        "        dataset = dataset.append(dataseries, ignore_index=True)\n",
        "        print(filename+\" \"+raga+\" added(small)\"+'dur '+str(dur))\n",
        "        off=(dur/10)*(i)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M. S. Gopalakrishnan - Ramabhirama.mp3-1 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-2 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-3 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-4 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-5 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-6 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-7 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-8 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-9 darbar added(small)dur 248.52897959183673\n",
            "M. S. Gopalakrishnan - Ramabhirama.mp3-10 darbar added(small)dur 248.52897959183673\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-1 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-2 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-3 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-4 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-5 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-6 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-7 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-8 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-9 darbar addeddur 1224.0\n",
            "Sanjay Subrahmanyan - Munduvenuka.mp3-10 darbar addeddur 1224.0\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-1 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-2 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-3 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-4 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-5 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-6 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-7 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-8 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-9 darbar addeddur 943.4644897959183\n",
            "Maharajapuram Santhanam - Mundu Venuga.mp3-10 darbar addeddur 943.4644897959183\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-1 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-2 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-3 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-4 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-5 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-6 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-7 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-8 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-9 darbar addeddur 315.42857142857144\n",
            "Prasanna Venkataraman - Chalamela Jesevura.mp3-10 darbar addeddur 315.42857142857144\n",
            "T. R. Mahalingam - Yochana.mp3-1 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-2 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-3 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-4 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-5 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-6 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-7 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-8 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-9 darbar added(small)dur 172.74775510204083\n",
            "T. R. Mahalingam - Yochana.mp3-10 darbar added(small)dur 172.74775510204083\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-1 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-2 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-3 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-4 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-5 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-6 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-7 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-8 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-9 darbar added(small)dur 234.99755102040817\n",
            "T. N. Seshagopalan - Nayakanai Ninra.mp3-10 darbar added(small)dur 234.99755102040817\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-1 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-2 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-3 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-4 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-5 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-6 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-7 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-8 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-9 darbar addeddur 1987.9444897959183\n",
            "Prasanna Venkataraman - Mundu Venuga.mp3-10 darbar addeddur 1987.9444897959183\n",
            "Bombay Jayashri - Munduvenuga.mp3-1 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-2 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-3 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-4 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-5 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-6 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-7 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-8 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-9 darbar addeddur 627.7224489795918\n",
            "Bombay Jayashri - Munduvenuga.mp3-10 darbar addeddur 627.7224489795918\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-1 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-2 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-3 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-4 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-5 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-6 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-7 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-8 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-9 darbar addeddur 511.5559183673469\n",
            "Sangeetha Swaminathan - Mundu Venuga.mp3-10 darbar addeddur 511.5559183673469\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-1 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-2 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-3 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-4 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-5 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-6 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-7 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-8 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-9 darbar addeddur 386.63836734693876\n",
            "Aruna Sairam - Adiya Pada Darishanam.mp3-10 darbar addeddur 386.63836734693876\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-1 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-2 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-3 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-4 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-5 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-6 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-7 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-8 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-9 darbar addeddur 507.454693877551\n",
            "Semmangudi Srinivasa Iyer - Naarada Guruswaami.mp3-10 darbar addeddur 507.454693877551\n",
            "M. S. Gopalakrishnan - Yachana.mp3-1 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-2 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-3 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-4 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-5 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-6 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-7 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-8 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-9 darbar addeddur 333.55755102040814\n",
            "M. S. Gopalakrishnan - Yachana.mp3-10 darbar addeddur 333.55755102040814\n",
            "S. Ramanathan - Chalamela.mp3-1 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-2 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-3 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-4 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-5 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-6 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-7 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-8 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-9 darbar addeddur 614.8440816326531\n",
            "S. Ramanathan - Chalamela.mp3-10 darbar addeddur 614.8440816326531\n",
            "R. K. Srikantan - Shoure.mp3-1 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-2 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-3 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-4 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-5 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-6 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-7 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-8 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-9 darbar addeddur 858.9061224489795\n",
            "R. K. Srikantan - Shoure.mp3-10 darbar addeddur 858.9061224489795\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-1 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-2 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-3 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-4 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-5 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-6 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-7 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-8 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-9 darbar addeddur 1908.9763265306121\n",
            "Sanjay Subrahmanyan - Mundu Venuga.mp3-10 darbar addeddur 1908.9763265306121\n",
            "Aruna Sairam - Eti Janmam.mp3-1 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-2 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-3 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-4 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-5 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-6 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-7 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-8 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-9 varali addeddur 1297.6587755102041\n",
            "Aruna Sairam - Eti Janmam.mp3-10 varali addeddur 1297.6587755102041\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-1 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-2 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-3 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-4 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-5 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-6 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-7 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-8 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-9 varali addeddur 366.0277551020408\n",
            "Sanjay Subrahmanyan - Eti Janmam.mp3-10 varali addeddur 366.0277551020408\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-1 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-2 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-3 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-4 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-5 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-6 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-7 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-8 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-9 varali addeddur 1640.96\n",
            "Maharajapuram S Ramachandran - Seshachala Nayakam.mp3-10 varali addeddur 1640.96\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-1 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-2 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-3 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-4 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-5 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-6 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-7 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-8 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-9 varali addeddur 1221.5118367346938\n",
            "Nisha P Rajagopal - Mamava Minakshi.mp3-10 varali addeddur 1221.5118367346938\n",
            "Amritha Murali - Karunaelagante.mp3-1 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-2 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-3 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-4 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-5 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-6 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-7 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-8 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-9 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Karunaelagante.mp3-10 varali addeddur 752.5616326530612\n",
            "Amritha Murali - Kamakshi.mp3-1 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-2 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-3 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-4 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-5 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-6 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-7 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-8 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-9 varali addeddur 1595.5591836734693\n",
            "Amritha Murali - Kamakshi.mp3-10 varali addeddur 1595.5591836734693\n",
            "T K Rangachari - Nepokada.mp3-1 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-2 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-3 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-4 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-5 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-6 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-7 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-8 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-9 varali addeddur 381.7795918367347\n",
            "T K Rangachari - Nepokada.mp3-10 varali addeddur 381.7795918367347\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-1 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-2 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-3 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-4 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-5 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-6 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-7 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-8 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-9 varali addeddur 1547.6767346938775\n",
            "Gayathri Venkataraghavan - Seshachalanayakam.mp3-10 varali addeddur 1547.6767346938775\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-1 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-2 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-3 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-4 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-5 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-6 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-7 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-8 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-9 varali addeddur 731.141224489796\n",
            "Ranjani _ Gayathri - Eti Janmam.mp3-10 varali addeddur 731.141224489796\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-1 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-2 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-3 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-4 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-5 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-6 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-7 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-8 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-9 varali addeddur 1027.709387755102\n",
            "Ariyakudi Ramanuja Iyengar - Azhi Mazhai Kanna.mp3-10 varali addeddur 1027.709387755102\n",
            "- Azhi Mazhai.mp3-1 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-2 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-3 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-4 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-5 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-6 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-7 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-8 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-9 varali addeddur 598.3733333333333\n",
            "- Azhi Mazhai.mp3-10 varali addeddur 598.3733333333333\n",
            "E Gayathri - Kamakshi.mp3-1 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-2 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-3 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-4 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-5 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-6 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-7 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-8 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-9 varali addeddur 395.4155102040816\n",
            "E Gayathri - Kamakshi.mp3-10 varali addeddur 395.4155102040816\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-1 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-2 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-3 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-4 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-5 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-6 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-7 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-8 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-9 varali addeddur 1069.9232653061224\n",
            "Madurai Mani Iyer - Ka Va Va.mp3-10 varali addeddur 1069.9232653061224\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-1 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-2 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-3 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-4 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-5 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-6 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-7 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-8 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-9 varali addeddur 906.7624489795918\n",
            "Kunnakkudi M Balamuralikrishna - Eti Janmam.mp3-10 varali addeddur 906.7624489795918\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-1 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-2 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-3 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-4 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-5 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-6 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-7 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-8 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-9 varali added(small)dur 266.0310204081633\n",
            "Semmangudi Srinivasa Iyer - Kaa Va Va.mp3-10 varali added(small)dur 266.0310204081633\n",
            "Aruna Sairam - Nittiraiyil.mp3-1 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-2 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-3 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-4 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-5 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-6 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-7 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-8 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-9 jaunpuri added(small)dur 195.8922448979592\n",
            "Aruna Sairam - Nittiraiyil.mp3-10 jaunpuri added(small)dur 195.8922448979592\n",
            "Sanjay Subrahmanyan - Malasai.mp3-1 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-2 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-3 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-4 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-5 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-6 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-7 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-8 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-9 jaunpuri added(small)dur 183.0661224489796\n",
            "Sanjay Subrahmanyan - Malasai.mp3-10 jaunpuri added(small)dur 183.0661224489796\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-1 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-2 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-3 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-4 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-5 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-6 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-7 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-8 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-9 jaunpuri added(small)dur 273.0057142857143\n",
            "Nedunuri Krishnamurthy - Ramamantrava Japiso.mp3-10 jaunpuri added(small)dur 273.0057142857143\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-1 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-2 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-3 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-4 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-5 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-6 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-7 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-8 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-9 jaunpuri added(small)dur 210.35210884353742\n",
            "Srividya Janakiraman - Nenindal Agaadadu undo.mp3-10 jaunpuri added(small)dur 210.35210884353742\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-1 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-2 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-3 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-4 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-5 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-6 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-7 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-8 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-9 jaunpuri added(small)dur 175.07265306122449\n",
            "Unnikrishnan - Eppo Varuvaro.mp3-10 jaunpuri added(small)dur 175.07265306122449\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-1 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-2 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-3 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-4 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-5 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-6 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-7 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-8 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-9 jaunpuri added(small)dur 49.606530612244896\n",
            "Madurai Mani Iyer - Eppo Varuvaro.mp3-10 jaunpuri added(small)dur 49.606530612244896\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-1 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-2 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-3 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-4 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-5 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-6 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-7 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-8 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-9 jaunpuri added(small)dur 232.6465306122449\n",
            "T. V. Sankaranarayanan - Yeppo Varuvaro.mp3-10 jaunpuri added(small)dur 232.6465306122449\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-1 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-2 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-3 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-4 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-5 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-6 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-7 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-8 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-9 jaunpuri addeddur 340.807619047619\n",
            "Vasundara Rajagopal - Ni Ninaindhal Aagadhadhu.mp3-10 jaunpuri addeddur 340.807619047619\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-1 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-2 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-3 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-4 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-5 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-6 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-7 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-8 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-9 jaunpuri added(small)dur 161.69795918367348\n",
            "Sanjay Subrahmanyan - Malaasai Kobam.mp3-10 jaunpuri added(small)dur 161.69795918367348\n",
            "Amritha Murali - Sapashyat.mp3-1 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-2 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-3 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-4 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-5 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-6 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-7 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-8 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-9 jaunpuri added(small)dur 178.41632653061225\n",
            "Amritha Murali - Sapashyat.mp3-10 jaunpuri added(small)dur 178.41632653061225\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-1 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-2 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-3 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-4 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-5 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-6 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-7 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-8 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-9 jaunpuri added(small)dur 244.84571428571428\n",
            "Madurai Mani Iyer - Eppo Paduvaro.mp3-10 jaunpuri added(small)dur 244.84571428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-1 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-2 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-3 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-4 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-5 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-6 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-7 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-8 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-9 jaunpuri addeddur 660.2971428571428\n",
            "Prasanna Venkataraman - Janati Ramam - Dasharatha Suta.mp3-10 jaunpuri addeddur 660.2971428571428\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-1 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-2 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-3 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-4 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-5 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-6 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-7 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-8 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-9 jaunpuri added(small)dur 291.10131519274375\n",
            "Rithvik Raja - Sapasyat Kausalya.mp3-10 jaunpuri added(small)dur 291.10131519274375\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-1 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-2 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-3 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-4 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-5 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-6 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-7 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-8 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-9 jaunpuri added(small)dur 173.03510204081633\n",
            "K.V. Narayanaswami - Dasaratha Sutha.mp3-10 jaunpuri added(small)dur 173.03510204081633\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-1 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-2 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-3 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-4 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-5 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-6 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-7 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-8 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-9 yamuna kalyani addeddur 440.0326530612245\n",
            "Maharajapuram Santhanam - Nadagopala.mp3-10 yamuna kalyani addeddur 440.0326530612245\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-1 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-2 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-3 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-4 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-5 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-6 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-7 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-8 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-9 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kuldeep Pai - Vasudeva Sutam Devam.mp3-10 yamuna kalyani added(small)dur 78.8517006802721\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-1 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-2 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-3 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-4 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-5 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-6 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-7 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-8 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-9 yamuna kalyani addeddur 448.78367346938774\n",
            "Kadri Gopalnath - Krishna Nee Begane.mp3-10 yamuna kalyani addeddur 448.78367346938774\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-1 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-2 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-3 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-4 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-5 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-6 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-7 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-8 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-9 yamuna kalyani addeddur 470.90938775510205\n",
            "Bombay Jayashri - Tillana - Sarva Mangalamangalye.mp3-10 yamuna kalyani addeddur 470.90938775510205\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-1 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-2 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-3 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-4 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-5 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-6 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-7 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-8 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-9 yamuna kalyani addeddur 332.06857142857143\n",
            "Ananthalakshmi Sadagopan - Chalo Mana.mp3-10 yamuna kalyani addeddur 332.06857142857143\n",
            "Amrutha Venkatesh - Nandagopala.mp3-1 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-2 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-3 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-4 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-5 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-6 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-7 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-8 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-9 yamuna kalyani addeddur 374.5436734693877\n",
            "Amrutha Venkatesh - Nandagopala.mp3-10 yamuna kalyani addeddur 374.5436734693877\n",
            "Bombay Jayashri - Thillana.mp3-1 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-2 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-3 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-4 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-5 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-6 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-7 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-8 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-9 yamuna kalyani addeddur 409.0514285714286\n",
            "Bombay Jayashri - Thillana.mp3-10 yamuna kalyani addeddur 409.0514285714286\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-1 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-2 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-3 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-4 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-5 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-6 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-7 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-8 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-9 yamuna kalyani addeddur 557.8710204081633\n",
            "Aruna Sairam - Krishna Nee Begane.mp3-10 yamuna kalyani addeddur 557.8710204081633\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-1 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-2 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-3 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-4 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-5 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-6 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-7 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-8 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-9 yamuna kalyani addeddur 316.63020408163266\n",
            "Aneesh Vidyashankar - Krishna Nee Begane.mp3-10 yamuna kalyani addeddur 316.63020408163266\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-1 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-2 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-3 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-4 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-5 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-6 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-7 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-8 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-9 yamuna kalyani addeddur 506.4359183673469\n",
            "Gayathri Venkataraghavan - Gopala Ratnam - Bhavayami Gopalabalam.mp3-10 yamuna kalyani addeddur 506.4359183673469\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-1 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-2 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-3 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-4 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-5 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-6 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-7 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-8 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-9 yamuna kalyani addeddur 348.20027210884354\n",
            "Kuldeep Pai - Krishna Nee Begane Baaro.mp3-10 yamuna kalyani addeddur 348.20027210884354\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-1 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-2 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-3 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-4 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-5 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-6 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-7 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-8 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-9 yamuna kalyani added(small)dur 274.7820408163265\n",
            "Maharajapuram Santhanam - Vandheham Sharadham.mp3-10 yamuna kalyani added(small)dur 274.7820408163265\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-1 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-2 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-3 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-4 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-5 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-6 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-7 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-8 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-9 yamuna kalyani added(small)dur 241.00571428571428\n",
            "M.S. Subbulakshmi - Pibare Ramarasam.mp3-10 yamuna kalyani added(small)dur 241.00571428571428\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-1 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-2 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-3 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-4 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-5 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-6 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-7 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-8 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-9 yamuna kalyani addeddur 1757.1526530612246\n",
            "Nisha P Rajagopal - Veera Sutantiram.mp3-10 yamuna kalyani addeddur 1757.1526530612246\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-1 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-2 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-3 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-4 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-5 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-6 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-7 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-8 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-9 yamuna kalyani addeddur 1514.6057142857144\n",
            "Sanjay Subrahmanyan - Nanda Gopala.mp3-10 yamuna kalyani addeddur 1514.6057142857144\n",
            "T K Rangachari - Etavuna.mp3-1 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-2 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-3 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-4 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-5 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-6 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-7 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-8 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-9 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "T K Rangachari - Etavuna.mp3-10 yadukula kambhoji added(small)dur 277.31591836734697\n",
            "Parassala Ponnammal - Mohanamayee.mp3-1 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-2 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-3 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-4 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-5 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-6 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-7 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-8 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-9 yadukula kambhoji addeddur 611.7616326530613\n",
            "Parassala Ponnammal - Mohanamayee.mp3-10 yadukula kambhoji addeddur 611.7616326530613\n",
            "S. Sowmya - Diwakara Tanujam.mp3-1 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-2 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-3 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-4 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-5 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-6 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-7 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-8 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-9 yadukula kambhoji addeddur 493.8187755102041\n",
            "S. Sowmya - Diwakara Tanujam.mp3-10 yadukula kambhoji addeddur 493.8187755102041\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-1 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-2 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-3 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-4 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-5 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-6 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-7 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-8 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-9 yadukula kambhoji addeddur 705.9069387755102\n",
            "M. D. Ramanathan - Srirama Raghurama.mp3-10 yadukula kambhoji addeddur 705.9069387755102\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-1 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-2 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-3 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-4 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-5 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-6 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-7 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-8 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-9 yadukula kambhoji addeddur 665.5477551020408\n",
            "M.S. Subbulakshmi - Amba Kamakshi Padayugame.mp3-10 yadukula kambhoji addeddur 665.5477551020408\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-1 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-2 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-3 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-4 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-5 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-6 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-7 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-8 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-9 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Parassala Ponnammal - Bhujaga Sayinam.mp3-10 yadukula kambhoji added(small)dur 131.42204081632653\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-1 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-2 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-3 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-4 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-5 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-6 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-7 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-8 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-9 yadukula kambhoji addeddur 1166.0538775510204\n",
            "Sanjay Subrahmanyan - Kalai Tukki.mp3-10 yadukula kambhoji addeddur 1166.0538775510204\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-1 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-2 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-3 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-4 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-5 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-6 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-7 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-8 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-9 yadukula kambhoji addeddur 614.6612244897959\n",
            "K.V. Narayanaswami - Bhujaga Sayinam.mp3-10 yadukula kambhoji addeddur 614.6612244897959\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-1 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-2 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-3 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-4 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-5 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-6 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-7 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-8 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-9 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Abhishek Raghuram - Sri Rama Jaya Rama.mp3-10 yadukula kambhoji added(small)dur 271.41224489795917\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-1 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-2 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-3 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-4 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-5 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-6 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-7 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-8 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-9 yadukula kambhoji addeddur 371.069387755102\n",
            "Madurai Mani Iyer - Diwakara Tanujam.mp3-10 yadukula kambhoji addeddur 371.069387755102\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-1 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-2 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-3 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-4 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-5 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-6 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-7 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-8 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-9 yadukula kambhoji addeddur 308.21877551020407\n",
            "S. Ramanathan - Hecharikaga Rara.mp3-10 yadukula kambhoji addeddur 308.21877551020407\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-1 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-2 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-3 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-4 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-5 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-6 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-7 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-8 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-9 yadukula kambhoji addeddur 357.0677551020408\n",
            "Malladi Brothers - Sri Rama Jaya Rama - Ni Nama Rupa.mp3-10 yadukula kambhoji addeddur 357.0677551020408\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-1 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-2 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-3 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-4 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-5 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-6 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-7 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-8 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-9 yadukula kambhoji addeddur 481.28\n",
            "Kunnakkudi M Balamuralikrishna - Yarenru Raghavanai.mp3-10 yadukula kambhoji addeddur 481.28\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-1 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-2 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-3 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-4 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-5 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-6 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-7 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-8 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-9 yadukula kambhoji addeddur 774.7657142857142\n",
            "Ariyakudi Ramanuja Iyengar - Hecharikaga.mp3-10 yadukula kambhoji addeddur 774.7657142857142\n",
            "T. Brinda - Ninnusevinchina.mp3-1 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-2 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-3 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-4 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-5 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-6 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-7 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-8 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-9 yadukula kambhoji addeddur 865.2277551020408\n",
            "T. Brinda - Ninnusevinchina.mp3-10 yadukula kambhoji addeddur 865.2277551020408\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-1 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-2 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-3 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-4 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-5 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-6 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-7 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-8 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-9 jaganmohini addeddur 368.74448979591835\n",
            "Kunnakkudi M Balamuralikrishna - So Billu Saptaswara.mp3-10 jaganmohini addeddur 368.74448979591835\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-1 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-2 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-3 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-4 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-5 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-6 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-7 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-8 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-9 jaganmohini addeddur 389.35510204081635\n",
            "M. L. Vasanthakumari - Sivakama Sundari.mp3-10 jaganmohini addeddur 389.35510204081635\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-1 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-2 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-3 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-4 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-5 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-6 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-7 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-8 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-9 jaganmohini added(small)dur 266.7840362811791\n",
            "R Vedavalli - Sri vidya rajagopalam.mp3-10 jaganmohini added(small)dur 266.7840362811791\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-1 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-2 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-3 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-4 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-5 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-6 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-7 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-8 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-9 jaganmohini added(small)dur 161.5673469387755\n",
            "Dr Pantula Rama - So Billu Saptaswara.mp3-10 jaganmohini added(small)dur 161.5673469387755\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-1 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-2 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-3 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-4 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-5 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-6 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-7 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-8 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-9 jaganmohini addeddur 558.915918367347\n",
            "Hyderabad Brothers - Sobhillu Sapthaswara.mp3-10 jaganmohini addeddur 558.915918367347\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-1 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-2 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-3 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-4 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-5 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-6 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-7 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-8 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-9 jaganmohini addeddur 717.4149659863946\n",
            "Modhumudi Sudhakar - Shobillu Saptasvara.mp3-10 jaganmohini addeddur 717.4149659863946\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-1 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-2 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-3 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-4 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-5 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-6 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-7 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-8 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-9 jaganmohini addeddur 538.6710204081633\n",
            "Parassala Ponnammal - Pahittarakshu.mp3-10 jaganmohini addeddur 538.6710204081633\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-1 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-2 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-3 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-4 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-5 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-6 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-7 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-8 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-9 jaganmohini added(small)dur 278.02122448979594\n",
            "Sikkil Sisters - So Billu Saptaswara.mp3-10 jaganmohini added(small)dur 278.02122448979594\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-1 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-2 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-3 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-4 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-5 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-6 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-7 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-8 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-9 jaganmohini addeddur 581.0155102040816\n",
            "Sanjay Subrahmanyan - Sidhi Vinayakaneundan.mp3-10 jaganmohini addeddur 581.0155102040816\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-1 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-2 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-3 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-4 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-5 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-6 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-7 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-8 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-9 jaganmohini addeddur 669.44\n",
            "Tanjore S. Kalyanaraman - Sobillu Sapthaswara.mp3-10 jaganmohini addeddur 669.44\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-1 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-2 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-3 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-4 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-5 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-6 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-7 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-8 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-9 jaganmohini added(small)dur 265.9526530612245\n",
            "G. N. Balasubramaniam - So Billu Saptaswara.mp3-10 jaganmohini added(small)dur 265.9526530612245\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-1 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-2 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-3 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-4 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-5 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-6 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-7 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-8 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-9 jaganmohini addeddur 325.7991836734694\n",
            "M. S. Gopalakrishnan - So Billu Saptaswara.mp3-10 jaganmohini addeddur 325.7991836734694\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-1 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-2 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-3 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-4 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-5 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-6 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-7 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-8 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-9 jaganmohini added(small)dur 266.6721088435374\n",
            "Sumithra Vasudev - Sri Vidhya Rajagopala.mp3-10 jaganmohini added(small)dur 266.6721088435374\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-1 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-2 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-3 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-4 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-5 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-6 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-7 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-8 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-9 jaganmohini addeddur 363.7551020408163\n",
            "Sikkil Mala Chandrasekhar - Sobhillu Sapthaswara.mp3-10 jaganmohini addeddur 363.7551020408163\n",
            "T M Thiagarajan - Sivakama.mp3-1 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-2 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-3 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-4 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-5 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-6 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-7 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-8 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-9 jaganmohini added(small)dur 205.47918367346938\n",
            "T M Thiagarajan - Sivakama.mp3-10 jaganmohini added(small)dur 205.47918367346938\n",
            "- Simhasanasthithey.mp3-1 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-2 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-3 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-4 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-5 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-6 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-7 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-8 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-9 ragamalika addeddur 386.1159183673469\n",
            "- Simhasanasthithey.mp3-10 ragamalika addeddur 386.1159183673469\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-1 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-2 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-3 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-4 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-5 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-6 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-7 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-8 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-9 ragamalika addeddur 387.3175510204082\n",
            "Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-10 ragamalika addeddur 387.3175510204082\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-1 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-2 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-3 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-4 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-5 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-6 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-7 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-8 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-9 ragamalika addeddur 494.49795918367346\n",
            "Sumithra Vasudev - Gurupaduka Stotram.mp3-10 ragamalika addeddur 494.49795918367346\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-1 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-2 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-3 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-4 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-5 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-6 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-7 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-8 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-9 ragamalika addeddur 405.86448979591836\n",
            "E Gayathri - Sri Chakra Raja Nilaya.mp3-10 ragamalika addeddur 405.86448979591836\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-1 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-2 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-3 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-4 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-5 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-6 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-7 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-8 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-9 ragamalika added(small)dur 292.8065306122449\n",
            "K.V. Narayanaswami - Jaya Jaya Vande.mp3-10 ragamalika added(small)dur 292.8065306122449\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-1 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-2 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-3 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-4 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-5 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-6 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-7 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-8 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-9 ragamalika addeddur 1051.6375510204082\n",
            "Semmangudi Srinivasa Iyer - Slokam.mp3-10 ragamalika addeddur 1051.6375510204082\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-1 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-2 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-3 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-4 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-5 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-6 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-7 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-8 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-9 ragamalika added(small)dur 151.14448979591836\n",
            "Sikkil Gurucharan - Maitreem Bhajata.mp3-10 ragamalika added(small)dur 151.14448979591836\n",
            "G. N. Balasubramaniam - Slokam.mp3-1 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-2 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-3 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-4 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-5 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-6 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-7 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-8 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-9 ragamalika addeddur 872.0457142857143\n",
            "G. N. Balasubramaniam - Slokam.mp3-10 ragamalika addeddur 872.0457142857143\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-1 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-2 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-3 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-4 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-5 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-6 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-7 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-8 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-9 ragamalika added(small)dur 290.37714285714287\n",
            "Maharajapuram S Ramachandran - Tunga Teera.mp3-10 ragamalika added(small)dur 290.37714285714287\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-1 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-2 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-3 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-4 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-5 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-6 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-7 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-8 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-9 ragamalika added(small)dur 281.7866666666667\n",
            "M.S. Subbulakshmi - Mudi Ondri (Pashuram).mp3-10 ragamalika added(small)dur 281.7866666666667\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-1 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-2 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-3 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-4 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-5 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-6 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-7 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-8 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-9 ragamalika addeddur 369.3975510204082\n",
            "Sangeetha Swaminathan - Karunai Madi Tavazhum.mp3-10 ragamalika addeddur 369.3975510204082\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-1 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-2 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-3 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-4 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-5 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-6 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-7 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-8 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-9 ragamalika addeddur 1695.5820408163265\n",
            "Tanjore S. Kalyanaraman - RTP in 4 Ragas - Ranjani, Manoranjani, Janaranjani and Sriranjani.mp3-10 ragamalika addeddur 1695.5820408163265\n",
            "Dandapani Desikar - Nalla Penmani.mp3-1 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-2 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-3 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-4 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-5 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-6 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-7 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-8 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-9 ragamalika addeddur 537.9333333333333\n",
            "Dandapani Desikar - Nalla Penmani.mp3-10 ragamalika addeddur 537.9333333333333\n",
            "Nithyasree Mahadevan - Tillana.mp3-1 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-2 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-3 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-4 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-5 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-6 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-7 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-8 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-9 ragamalika addeddur 394.44897959183675\n",
            "Nithyasree Mahadevan - Tillana.mp3-10 ragamalika addeddur 394.44897959183675\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-1 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-2 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-3 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-4 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-5 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-6 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-7 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-8 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-9 ragamalika addeddur 338.67755102040815\n",
            "Vijay Siva - Sri Saradha Bujanga Prayadashtakam – Ragamalika.mp3-10 ragamalika addeddur 338.67755102040815\n",
            "S. Sowmya - Maranam Agattra.mp3-1 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-2 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-3 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-4 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-5 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-6 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-7 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-8 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-9 vasanta addeddur 320.2612244897959\n",
            "S. Sowmya - Maranam Agattra.mp3-10 vasanta addeddur 320.2612244897959\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-1 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-2 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-3 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-4 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-5 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-6 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-7 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-8 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-9 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Etla Tori.mp3-10 vasanta addeddur 681.2734693877551\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-1 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-2 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-3 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-4 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-5 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-6 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-7 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-8 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-9 vasanta addeddur 342.90938775510205\n",
            "Kunnakkudi M Balamuralikrishna - Sithamma Mayamma.mp3-10 vasanta addeddur 342.90938775510205\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-1 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-2 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-3 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-4 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-5 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-6 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-7 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-8 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-9 vasanta addeddur 486.58285714285716\n",
            "Sikkil Gurucharan - Ninnukori Yunnanura.mp3-10 vasanta addeddur 486.58285714285716\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-1 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-2 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-3 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-4 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-5 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-6 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-7 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-8 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-9 vasanta added(small)dur 256.07836734693876\n",
            "Gayathri Girish - Seetamma Maayyama.mp3-10 vasanta added(small)dur 256.07836734693876\n",
            "D. K. Pattammal - Rama Rama.mp3-1 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-2 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-3 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-4 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-5 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-6 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-7 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-8 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-9 vasanta added(small)dur 136.15020408163267\n",
            "D. K. Pattammal - Rama Rama.mp3-10 vasanta added(small)dur 136.15020408163267\n",
            "KP Nandini - Seethamma.mp3-1 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-2 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-3 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-4 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-5 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-6 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-7 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-8 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-9 vasanta added(small)dur 299.0639455782313\n",
            "KP Nandini - Seethamma.mp3-10 vasanta added(small)dur 299.0639455782313\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-1 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-2 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-3 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-4 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-5 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-6 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-7 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-8 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-9 vasanta addeddur 663.9542857142857\n",
            "Ariyakudi Ramanuja Iyengar - Hariharaputram.mp3-10 vasanta addeddur 663.9542857142857\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-1 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-2 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-3 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-4 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-5 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-6 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-7 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-8 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-9 vasanta addeddur 962.1681632653061\n",
            "Semmangudi Srinivasa Iyer - Hariharaputram.mp3-10 vasanta addeddur 962.1681632653061\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-1 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-2 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-3 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-4 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-5 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-6 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-7 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-8 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-9 vasanta addeddur 476.05551020408166\n",
            "M.S. Subbulakshmi - Hariharaputram.mp3-10 vasanta addeddur 476.05551020408166\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-1 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-2 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-3 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-4 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-5 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-6 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-7 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-8 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-9 vasanta added(small)dur 282.4359183673469\n",
            "M. D. Ramanathan - Ramachandram Bhavayami.mp3-10 vasanta added(small)dur 282.4359183673469\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-1 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-2 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-3 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-4 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-5 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-6 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-7 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-8 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-9 vasanta added(small)dur 203.62448979591838\n",
            "Nisha P Rajagopal - Malmaruga Shanmukha.mp3-10 vasanta added(small)dur 203.62448979591838\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-1 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-2 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-3 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-4 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-5 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-6 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-7 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-8 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-9 vasanta added(small)dur 198.0081632653061\n",
            "G. N. Balasubramaniam - Ramachandram.mp3-10 vasanta added(small)dur 198.0081632653061\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-1 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-2 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-3 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-4 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-5 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-6 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-7 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-8 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-9 vasanta addeddur 317.62285714285713\n",
            "Dr Pantula Rama - Ninnu Kori.mp3-10 vasanta addeddur 317.62285714285713\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-1 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-2 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-3 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-4 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-5 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-6 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-7 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-8 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-9 vasanta addeddur 1695.5297959183674\n",
            "Gayathri Venkataraghavan - Hari Hara Putram.mp3-10 vasanta addeddur 1695.5297959183674\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-1 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-2 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-3 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-4 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-5 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-6 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-7 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-8 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-9 mayamalava gaula addeddur 451.68326530612245\n",
            "Aruna Sairam - Vidulaku Mrokkeda.mp3-10 mayamalava gaula addeddur 451.68326530612245\n",
            "T. Brinda - Meru Samana.mp3-1 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-2 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-3 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-4 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-5 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-6 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-7 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-8 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-9 mayamalava gaula addeddur 710.6873469387755\n",
            "T. Brinda - Meru Samana.mp3-10 mayamalava gaula addeddur 710.6873469387755\n",
            "Amritha Murali - Vidulaku.mp3-1 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-2 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-3 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-4 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-5 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-6 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-7 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-8 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-9 mayamalava gaula addeddur 756.9502040816327\n",
            "Amritha Murali - Vidulaku.mp3-10 mayamalava gaula addeddur 756.9502040816327\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-1 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-2 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-3 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-4 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-5 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-6 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-7 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-8 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-9 mayamalava gaula addeddur 772.858775510204\n",
            "Semmangudi Srinivasa Iyer - Deva Deva Kalayamite.mp3-10 mayamalava gaula addeddur 772.858775510204\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-1 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-2 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-3 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-4 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-5 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-6 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-7 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-8 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-9 mayamalava gaula addeddur 670.5371428571428\n",
            "Gayathri Venkataraghavan - Deva Deva Kalayami.mp3-10 mayamalava gaula addeddur 670.5371428571428\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-1 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-2 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-3 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-4 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-5 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-6 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-7 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-8 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-9 mayamalava gaula addeddur 346.4620408163265\n",
            "K.V. Narayanaswami - Sarasija Nabha.mp3-10 mayamalava gaula addeddur 346.4620408163265\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-1 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-2 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-3 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-4 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-5 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-6 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-7 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-8 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-9 mayamalava gaula addeddur 1355.833469387755\n",
            "M.S. Subbulakshmi - Ksheera Sagara Shayana.mp3-10 mayamalava gaula addeddur 1355.833469387755\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-1 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-2 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-3 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-4 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-5 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-6 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-7 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-8 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-9 mayamalava gaula addeddur 352.4179591836735\n",
            "Sangeetha Swaminathan - Sri Raja Rajeswari.mp3-10 mayamalava gaula addeddur 352.4179591836735\n",
            "Musiri Subramania Iyer - Merusamana.mp3-1 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-2 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-3 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-4 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-5 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-6 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-7 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-8 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-9 mayamalava gaula addeddur 662.4914285714286\n",
            "Musiri Subramania Iyer - Merusamana.mp3-10 mayamalava gaula addeddur 662.4914285714286\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-1 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-2 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-3 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-4 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-5 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-6 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-7 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-8 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-9 mayamalava gaula addeddur 1331.069387755102\n",
            "M. D. Ramanathan - Maya Tita Swaroopini.mp3-10 mayamalava gaula addeddur 1331.069387755102\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-1 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-2 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-3 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-4 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-5 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-6 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-7 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-8 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-9 mayamalava gaula addeddur 828.7608163265306\n",
            "Amrutha Venkatesh - Vidulaku Mrokkeda.mp3-10 mayamalava gaula addeddur 828.7608163265306\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-1 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-2 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-3 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-4 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-5 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-6 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-7 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-8 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-9 mayamalava gaula added(small)dur 290.2987755102041\n",
            "D. K. Pattammal - Vaiyagam Parano.mp3-10 mayamalava gaula added(small)dur 290.2987755102041\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-1 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-2 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-3 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-4 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-5 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-6 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-7 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-8 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-9 mayamalava gaula addeddur 642.6122448979592\n",
            "Nisha P Rajagopal - Deva Deva Kalayami.mp3-10 mayamalava gaula addeddur 642.6122448979592\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-1 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-2 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-3 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-4 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-5 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-6 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-7 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-8 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-9 mayamalava gaula addeddur 713.4302040816326\n",
            "M.S. Subbulakshmi - Vidulaku Mrokkeda.mp3-10 mayamalava gaula addeddur 713.4302040816326\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-1 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-2 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-3 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-4 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-5 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-6 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-7 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-8 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-9 mayamalava gaula addeddur 903.1575510204082\n",
            "Jayanthi Kumaresh - Meru Samana.mp3-10 mayamalava gaula addeddur 903.1575510204082\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-1 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-2 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-3 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-4 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-5 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-6 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-7 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-8 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-9 shanmukhapriya addeddur 405.9689795918367\n",
            "S. Sowmya - Kandanai Nesithaal.mp3-10 shanmukhapriya addeddur 405.9689795918367\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-1 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-2 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-3 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-4 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-5 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-6 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-7 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-8 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-9 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Nedunuri Krishnamurthy - Sharavana Bhava.mp3-10 shanmukhapriya added(small)dur 263.0530612244898\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-1 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-2 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-3 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-4 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-5 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-6 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-7 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-8 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-9 shanmukhapriya addeddur 499.0955102040816\n",
            "Sheik Chinna Moulana - Vallinayagane.mp3-10 shanmukhapriya addeddur 499.0955102040816\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-1 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-2 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-3 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-4 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-5 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-6 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-7 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-8 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-9 shanmukhapriya addeddur 2940.76\n",
            "Abhishek Raghuram - Sadaanandamu.mp3-10 shanmukhapriya addeddur 2940.76\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-1 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-2 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-3 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-4 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-5 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-6 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-7 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-8 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-9 shanmukhapriya added(small)dur 208.6661224489796\n",
            "T K Rangachari - Kannanai Pani Maname.mp3-10 shanmukhapriya added(small)dur 208.6661224489796\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-1 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-2 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-3 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-4 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-5 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-6 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-7 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-8 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-9 shanmukhapriya added(small)dur 206.08\n",
            "Maharajapuram Santhanam - Vilayada Idu Nerama.mp3-10 shanmukhapriya added(small)dur 206.08\n",
            "Mahati - Ragam Tanam Pallavi.mp3-1 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-2 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-3 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-4 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-5 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-6 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-7 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-8 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-9 shanmukhapriya addeddur 4580.063129251701\n",
            "Mahati - Ragam Tanam Pallavi.mp3-10 shanmukhapriya addeddur 4580.063129251701\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-1 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-2 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-3 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-4 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-5 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-6 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-7 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-8 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-9 shanmukhapriya addeddur 742.1648979591837\n",
            "Kunnakkudi M Balamuralikrishna - Siddhi Vinayakam.mp3-10 shanmukhapriya addeddur 742.1648979591837\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-1 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-2 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-3 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-4 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-5 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-6 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-7 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-8 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-9 shanmukhapriya addeddur 386.56\n",
            "Nithyasree Mahadevan - Velan Varuvaradi.mp3-10 shanmukhapriya addeddur 386.56\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-1 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-2 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-3 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-4 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-5 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-6 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-7 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-8 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-9 shanmukhapriya addeddur 2666.26612244898\n",
            "Aruna Sairam - Vellai Panivade Yen Vellai.mp3-10 shanmukhapriya addeddur 2666.26612244898\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-1 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-2 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-3 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-4 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-5 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-6 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-7 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-8 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-9 shanmukhapriya addeddur 429.9755102040816\n",
            "Prasanna Venkataraman - Viruttam - Vizhikkuthunai followed by Saravanabhava.mp3-10 shanmukhapriya addeddur 429.9755102040816\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-1 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-2 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-3 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-4 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-5 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-6 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-7 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-8 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-9 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Ragam Thanam Pallavi - Shanmukhapriya.mp3-10 shanmukhapriya addeddur 3788.042448979592\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-1 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-2 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-3 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-4 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-5 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-6 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-7 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-8 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-9 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Sanjay Subrahmanyan - Saravanabhava Enum.mp3-10 shanmukhapriya added(small)dur 177.36956916099774\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-1 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-2 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-3 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-4 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-5 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-6 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-7 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-8 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-9 shanmukhapriya addeddur 754.9790476190476\n",
            "Akkarai Sisters - Siddhi Vinayakam.mp3-10 shanmukhapriya addeddur 754.9790476190476\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-1 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-2 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-3 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-4 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-5 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-6 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-7 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-8 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-9 shanmukhapriya addeddur 1599.0595918367346\n",
            "Dr Pantula Rama - Maamava Karunaya.mp3-10 shanmukhapriya addeddur 1599.0595918367346\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-1 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-2 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-3 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-4 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-5 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-6 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-7 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-8 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-9 shanmukhapriya addeddur 935.0791836734694\n",
            "Lalgudi Jayaraman - Vaddhane.mp3-10 shanmukhapriya addeddur 935.0791836734694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAqYm5QuXRcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13dbacac-32bb-46b7-c16b-fe30951a7027"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2340, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcwBtb7gSfCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNFQ15C0ut3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ragas=os.listdir('/content/content/Audio/')\n",
        "for raga in ragas:\n",
        "  path = '/content/content/Audio/'+raga\n",
        "  musics=os.listdir(path)\n",
        "  for name in musics:\n",
        "    vocals=path+'/'+name+'/'+'vocals.wav'\n",
        "    songname=vocals\n",
        "    filename=name\n",
        "    y, sr = librosa.load(songname, mono=True, duration=30)\n",
        "    rmse = librosa.feature.rmse(y=y)[0]\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "    zcr = librosa.feature.zero_crossing_rate(y)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "    data=[filename,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19]),raga]\n",
        "    dataseries = pd.Series(data, index = dataset.columns)\n",
        "    dataset = dataset.append(dataseries, ignore_index=True)\n",
        "    print(name+\" \"+raga+\" added\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1THtTXt5xuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_2yzIaWBYn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.to_csv('dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_CWXO-MhtdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.to_csv('dataset-nosource2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WXNjupOA_Lj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa5b87da-3655-4269-910b-e6cbc898e493"
      },
      "source": [
        "!gsutil cp '/content/dataset-nosource.csv' 'gs://ragaclass/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/dataset-nosource.csv [Content-Type=text/csv]...\n",
            "-\n",
            "Operation completed over 1 objects/817.9 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tJE0GAKV23p",
        "colab_type": "text"
      },
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XnWgr8vuqnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import layers\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Bidirectional\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjVeDl6QCphf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('dataset-best.csv')\n",
        "# Dropping unneccesary columns\n",
        "data = data.drop(['filename'],axis=1)\n",
        "#Encoding the Labels\n",
        "raga_list = data.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG--D-vsRPPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = pd.read_csv('dataset-nosource.csv')\n",
        "# Dropping unneccesary columns\n",
        "data2 = data2.drop(['filename'],axis=1)\n",
        "#Encoding the Labels\n",
        "raga_list2 = data2.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "Y2 = encoder.fit_transform(raga_list2)\n",
        "#Scaling the Feature columns\n",
        "scaler = StandardScaler()\n",
        "X2 = scaler.fit_transform(np.array(data2.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkjYa-JcHReV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "c7497c91-acd5-4745-d751-01d275a7ce92"
      },
      "source": [
        "use_tpu=True\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "tpu_address = TF_MASTER\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TF_MASTER)\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.85.146:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.85.146:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mudDHU__WQjs",
        "colab_type": "text"
      },
      "source": [
        "#ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXMiOsV1GhNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "bf93f557-8837-4f8a-fdf3-473be50367bc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 256)               7168      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 48,970\n",
            "Trainable params: 48,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6xZwuElGjAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83e83bf4-ac11-4ae6-b55e-46a5092f67f7"
      },
      "source": [
        "classifier = model.fit(X_train, y_train,batch_size=128, epochs=500, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " 1/14 [=>............................] - ETA: 0s - loss: 2.3321 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0089s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0089s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/14 [====================>.........] - ETA: 0s - loss: 2.2157 - accuracy: 0.2016WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 33ms/step - loss: 2.1781 - accuracy: 0.2308 - val_loss: 2.0283 - val_accuracy: 0.3179\n",
            "Epoch 2/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.8014 - accuracy: 0.4154 - val_loss: 1.6797 - val_accuracy: 0.4376\n",
            "Epoch 3/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 1.4292 - accuracy: 0.5442 - val_loss: 1.3575 - val_accuracy: 0.5214\n",
            "Epoch 4/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.1043 - accuracy: 0.6689 - val_loss: 1.1072 - val_accuracy: 0.6068\n",
            "Epoch 5/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.8766 - accuracy: 0.7413 - val_loss: 0.9400 - val_accuracy: 0.6752\n",
            "Epoch 6/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.7160 - accuracy: 0.7869 - val_loss: 0.8203 - val_accuracy: 0.6872\n",
            "Epoch 7/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.5921 - accuracy: 0.8251 - val_loss: 0.7174 - val_accuracy: 0.7487\n",
            "Epoch 8/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.4928 - accuracy: 0.8644 - val_loss: 0.6450 - val_accuracy: 0.7624\n",
            "Epoch 9/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.4169 - accuracy: 0.8877 - val_loss: 0.5738 - val_accuracy: 0.8017\n",
            "Epoch 10/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.3525 - accuracy: 0.9134 - val_loss: 0.5187 - val_accuracy: 0.8188\n",
            "Epoch 11/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.3148 - accuracy: 0.9145 - val_loss: 0.5001 - val_accuracy: 0.8256\n",
            "Epoch 12/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.2720 - accuracy: 0.9293 - val_loss: 0.4692 - val_accuracy: 0.8376\n",
            "Epoch 13/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.2386 - accuracy: 0.9425 - val_loss: 0.4450 - val_accuracy: 0.8496\n",
            "Epoch 14/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.2051 - accuracy: 0.9584 - val_loss: 0.3969 - val_accuracy: 0.8872\n",
            "Epoch 15/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1742 - accuracy: 0.9761 - val_loss: 0.3886 - val_accuracy: 0.8786\n",
            "Epoch 16/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1486 - accuracy: 0.9812 - val_loss: 0.3605 - val_accuracy: 0.8974\n",
            "Epoch 17/500\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.1349 - accuracy: 0.9795 - val_loss: 0.3619 - val_accuracy: 0.8872\n",
            "Epoch 18/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1183 - accuracy: 0.9835 - val_loss: 0.3672 - val_accuracy: 0.8786\n",
            "Epoch 19/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1140 - accuracy: 0.9835 - val_loss: 0.3689 - val_accuracy: 0.8752\n",
            "Epoch 20/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1039 - accuracy: 0.9869 - val_loss: 0.3517 - val_accuracy: 0.8786\n",
            "Epoch 21/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0872 - accuracy: 0.9903 - val_loss: 0.3213 - val_accuracy: 0.8957\n",
            "Epoch 22/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0767 - accuracy: 0.9954 - val_loss: 0.3104 - val_accuracy: 0.9009\n",
            "Epoch 23/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0688 - accuracy: 0.9926 - val_loss: 0.3280 - val_accuracy: 0.9077\n",
            "Epoch 24/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0630 - accuracy: 0.9949 - val_loss: 0.3316 - val_accuracy: 0.9009\n",
            "Epoch 25/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0554 - accuracy: 0.9983 - val_loss: 0.3120 - val_accuracy: 0.9111\n",
            "Epoch 26/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0510 - accuracy: 0.9960 - val_loss: 0.3186 - val_accuracy: 0.9026\n",
            "Epoch 27/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.9972 - val_loss: 0.2990 - val_accuracy: 0.9026\n",
            "Epoch 28/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0398 - accuracy: 0.9989 - val_loss: 0.2933 - val_accuracy: 0.9128\n",
            "Epoch 29/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0361 - accuracy: 0.9989 - val_loss: 0.2979 - val_accuracy: 0.9111\n",
            "Epoch 30/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0326 - accuracy: 0.9994 - val_loss: 0.3109 - val_accuracy: 0.9043\n",
            "Epoch 31/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0303 - accuracy: 0.9989 - val_loss: 0.3038 - val_accuracy: 0.9145\n",
            "Epoch 32/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9994 - val_loss: 0.2969 - val_accuracy: 0.9111\n",
            "Epoch 33/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9128\n",
            "Epoch 34/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9197\n",
            "Epoch 35/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9994 - val_loss: 0.2891 - val_accuracy: 0.9162\n",
            "Epoch 36/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9994 - val_loss: 0.2999 - val_accuracy: 0.9077\n",
            "Epoch 37/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9994 - val_loss: 0.2845 - val_accuracy: 0.9197\n",
            "Epoch 38/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9128\n",
            "Epoch 39/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9994 - val_loss: 0.2996 - val_accuracy: 0.9145\n",
            "Epoch 40/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9111\n",
            "Epoch 41/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9145\n",
            "Epoch 42/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9214\n",
            "Epoch 43/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9111\n",
            "Epoch 44/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9094\n",
            "Epoch 45/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9145\n",
            "Epoch 46/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9145\n",
            "Epoch 47/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9111\n",
            "Epoch 48/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9162\n",
            "Epoch 49/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9197\n",
            "Epoch 50/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9128\n",
            "Epoch 51/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9214\n",
            "Epoch 52/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9214\n",
            "Epoch 53/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9128\n",
            "Epoch 54/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9179\n",
            "Epoch 55/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9145\n",
            "Epoch 56/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9162\n",
            "Epoch 57/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9197\n",
            "Epoch 58/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9162\n",
            "Epoch 59/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9145\n",
            "Epoch 60/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9162\n",
            "Epoch 61/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9145\n",
            "Epoch 62/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9145\n",
            "Epoch 63/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9197\n",
            "Epoch 64/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9214\n",
            "Epoch 65/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9162\n",
            "Epoch 66/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9162\n",
            "Epoch 67/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9197\n",
            "Epoch 68/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9179\n",
            "Epoch 69/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9231\n",
            "Epoch 70/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9162\n",
            "Epoch 71/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9197\n",
            "Epoch 72/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9197\n",
            "Epoch 73/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9145\n",
            "Epoch 74/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9179\n",
            "Epoch 75/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9162\n",
            "Epoch 76/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9197\n",
            "Epoch 77/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9179\n",
            "Epoch 78/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9179\n",
            "Epoch 79/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9197\n",
            "Epoch 80/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9179\n",
            "Epoch 81/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9162\n",
            "Epoch 82/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9197\n",
            "Epoch 83/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9179\n",
            "Epoch 84/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9197\n",
            "Epoch 85/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9179\n",
            "Epoch 86/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9179\n",
            "Epoch 87/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9179\n",
            "Epoch 88/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9214\n",
            "Epoch 89/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9214\n",
            "Epoch 90/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9179\n",
            "Epoch 91/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9197\n",
            "Epoch 92/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9197\n",
            "Epoch 93/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9197\n",
            "Epoch 94/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9197\n",
            "Epoch 95/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9179\n",
            "Epoch 96/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9231\n",
            "Epoch 97/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9231\n",
            "Epoch 98/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9214\n",
            "Epoch 99/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9179\n",
            "Epoch 100/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9197\n",
            "Epoch 101/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9197\n",
            "Epoch 102/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9179\n",
            "Epoch 103/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9214\n",
            "Epoch 104/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9197\n",
            "Epoch 105/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.9197\n",
            "Epoch 106/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9248\n",
            "Epoch 107/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9179\n",
            "Epoch 108/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9231\n",
            "Epoch 109/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9231\n",
            "Epoch 110/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9231\n",
            "Epoch 111/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9231\n",
            "Epoch 112/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9214\n",
            "Epoch 113/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 9.6976e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9231\n",
            "Epoch 114/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 9.4023e-04 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.9214\n",
            "Epoch 115/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 9.1783e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9214\n",
            "Epoch 116/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 9.0175e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9214\n",
            "Epoch 117/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 8.8265e-04 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9214\n",
            "Epoch 118/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 8.5480e-04 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9248\n",
            "Epoch 119/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.3749e-04 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.9214\n",
            "Epoch 120/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.2433e-04 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9214\n",
            "Epoch 121/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 8.0262e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9197\n",
            "Epoch 122/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 7.8682e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9231\n",
            "Epoch 123/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.7978e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9197\n",
            "Epoch 124/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.6565e-04 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9248\n",
            "Epoch 125/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.4719e-04 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9231\n",
            "Epoch 126/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.2638e-04 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9248\n",
            "Epoch 127/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 7.1939e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9231\n",
            "Epoch 128/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.0509e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9231\n",
            "Epoch 129/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.9301e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9231\n",
            "Epoch 130/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.7217e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9231\n",
            "Epoch 131/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.6219e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9248\n",
            "Epoch 132/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.5148e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9231\n",
            "Epoch 133/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.3942e-04 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9231\n",
            "Epoch 134/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.3289e-04 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9231\n",
            "Epoch 135/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.1741e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9231\n",
            "Epoch 136/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 5.9964e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9248\n",
            "Epoch 137/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.8905e-04 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9231\n",
            "Epoch 138/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.7808e-04 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9248\n",
            "Epoch 139/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.6447e-04 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9231\n",
            "Epoch 140/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.5804e-04 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9248\n",
            "Epoch 141/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.5029e-04 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9231\n",
            "Epoch 142/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.3876e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9248\n",
            "Epoch 143/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.2923e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9248\n",
            "Epoch 144/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.2225e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9231\n",
            "Epoch 145/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.0935e-04 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9231\n",
            "Epoch 146/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.0139e-04 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9248\n",
            "Epoch 147/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.9317e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9248\n",
            "Epoch 148/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.8346e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9231\n",
            "Epoch 149/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.8050e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9248\n",
            "Epoch 150/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.7515e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9248\n",
            "Epoch 151/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.6127e-04 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9231\n",
            "Epoch 152/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.5205e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9231\n",
            "Epoch 153/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.4535e-04 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9248\n",
            "Epoch 154/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.3643e-04 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9248\n",
            "Epoch 155/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.3046e-04 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9248\n",
            "Epoch 156/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.2425e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9248\n",
            "Epoch 157/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.1597e-04 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9248\n",
            "Epoch 158/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.0882e-04 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9231\n",
            "Epoch 159/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.0093e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9248\n",
            "Epoch 160/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.9514e-04 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9231\n",
            "Epoch 161/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.9134e-04 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9248\n",
            "Epoch 162/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.8365e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9248\n",
            "Epoch 163/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.8145e-04 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9248\n",
            "Epoch 164/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.7159e-04 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9231\n",
            "Epoch 165/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 3.6418e-04 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9248\n",
            "Epoch 166/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.5982e-04 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9248\n",
            "Epoch 167/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.5880e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9248\n",
            "Epoch 168/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.4812e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9248\n",
            "Epoch 169/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 3.4549e-04 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9248\n",
            "Epoch 170/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.4003e-04 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9248\n",
            "Epoch 171/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.3331e-04 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9248\n",
            "Epoch 172/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.2829e-04 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9248\n",
            "Epoch 173/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 3.2442e-04 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9248\n",
            "Epoch 174/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.1790e-04 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9248\n",
            "Epoch 175/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 3.1255e-04 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9248\n",
            "Epoch 176/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.0935e-04 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9248\n",
            "Epoch 177/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.0424e-04 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9248\n",
            "Epoch 178/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.0070e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9248\n",
            "Epoch 179/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9820e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9248\n",
            "Epoch 180/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9346e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9248\n",
            "Epoch 181/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8740e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9248\n",
            "Epoch 182/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.8251e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9265\n",
            "Epoch 183/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.7830e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9248\n",
            "Epoch 184/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7820e-04 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9248\n",
            "Epoch 185/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7009e-04 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9248\n",
            "Epoch 186/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.6838e-04 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9231\n",
            "Epoch 187/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.6390e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9248\n",
            "Epoch 188/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.5925e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9248\n",
            "Epoch 189/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.5593e-04 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9248\n",
            "Epoch 190/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2.5413e-04 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9231\n",
            "Epoch 191/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.4914e-04 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9248\n",
            "Epoch 192/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2.4534e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9248\n",
            "Epoch 193/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2.4299e-04 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9248\n",
            "Epoch 194/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.3927e-04 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9231\n",
            "Epoch 195/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.3617e-04 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9248\n",
            "Epoch 196/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.3199e-04 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.9248\n",
            "Epoch 197/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.2962e-04 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9248\n",
            "Epoch 198/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.2557e-04 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9248\n",
            "Epoch 199/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.2357e-04 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9265\n",
            "Epoch 200/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.2047e-04 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9248\n",
            "Epoch 201/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.1763e-04 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9248\n",
            "Epoch 202/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.1335e-04 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9248\n",
            "Epoch 203/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.1067e-04 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9248\n",
            "Epoch 204/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0820e-04 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9265\n",
            "Epoch 205/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0519e-04 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9248\n",
            "Epoch 206/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2.0238e-04 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9248\n",
            "Epoch 207/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.9999e-04 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9248\n",
            "Epoch 208/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.9725e-04 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9265\n",
            "Epoch 209/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.9484e-04 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9248\n",
            "Epoch 210/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.9256e-04 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9248\n",
            "Epoch 211/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.9205e-04 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9248\n",
            "Epoch 212/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.8716e-04 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.9248\n",
            "Epoch 213/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.8546e-04 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9265\n",
            "Epoch 214/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.8247e-04 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9248\n",
            "Epoch 215/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.8001e-04 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9248\n",
            "Epoch 216/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.7869e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9248\n",
            "Epoch 217/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.7553e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9265\n",
            "Epoch 218/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.7369e-04 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9265\n",
            "Epoch 219/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.7170e-04 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9265\n",
            "Epoch 220/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.6910e-04 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9265\n",
            "Epoch 221/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.6710e-04 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9265\n",
            "Epoch 222/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 1.6497e-04 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.9248\n",
            "Epoch 223/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.6340e-04 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.9265\n",
            "Epoch 224/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.6149e-04 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9248\n",
            "Epoch 225/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.5912e-04 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9265\n",
            "Epoch 226/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5743e-04 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9248\n",
            "Epoch 227/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.5498e-04 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9265\n",
            "Epoch 228/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5297e-04 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9265\n",
            "Epoch 229/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.5121e-04 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9265\n",
            "Epoch 230/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.5005e-04 - accuracy: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9265\n",
            "Epoch 231/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.4802e-04 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9265\n",
            "Epoch 232/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.4618e-04 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9265\n",
            "Epoch 233/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.4481e-04 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9248\n",
            "Epoch 234/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4416e-04 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.9265\n",
            "Epoch 235/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4289e-04 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9265\n",
            "Epoch 236/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.3915e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9265\n",
            "Epoch 237/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.3763e-04 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9265\n",
            "Epoch 238/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.3671e-04 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9265\n",
            "Epoch 239/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.3473e-04 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9265\n",
            "Epoch 240/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.3321e-04 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9248\n",
            "Epoch 241/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.3144e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9265\n",
            "Epoch 242/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2904e-04 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9265\n",
            "Epoch 243/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2795e-04 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9265\n",
            "Epoch 244/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2602e-04 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9265\n",
            "Epoch 245/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2521e-04 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.9265\n",
            "Epoch 246/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2342e-04 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9265\n",
            "Epoch 247/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2165e-04 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9265\n",
            "Epoch 248/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2029e-04 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9265\n",
            "Epoch 249/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.1992e-04 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9265\n",
            "Epoch 250/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1774e-04 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9265\n",
            "Epoch 251/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1693e-04 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9265\n",
            "Epoch 252/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1551e-04 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9248\n",
            "Epoch 253/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1365e-04 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9265\n",
            "Epoch 254/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1303e-04 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9265\n",
            "Epoch 255/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1113e-04 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.9265\n",
            "Epoch 256/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0993e-04 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9265\n",
            "Epoch 257/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0845e-04 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9248\n",
            "Epoch 258/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0715e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9265\n",
            "Epoch 259/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0626e-04 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9265\n",
            "Epoch 260/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0512e-04 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9265\n",
            "Epoch 261/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0372e-04 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9248\n",
            "Epoch 262/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0246e-04 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9265\n",
            "Epoch 263/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0142e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9265\n",
            "Epoch 264/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0019e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9248\n",
            "Epoch 265/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 9.9055e-05 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9265\n",
            "Epoch 266/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 9.9647e-05 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9248\n",
            "Epoch 267/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 9.6765e-05 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9265\n",
            "Epoch 268/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 9.5896e-05 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9265\n",
            "Epoch 269/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 9.4498e-05 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.9248\n",
            "Epoch 270/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 9.4083e-05 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9248\n",
            "Epoch 271/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 9.2718e-05 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9265\n",
            "Epoch 272/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 9.1852e-05 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9265\n",
            "Epoch 273/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 9.0689e-05 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.9248\n",
            "Epoch 274/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.9648e-05 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9248\n",
            "Epoch 275/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.8630e-05 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9265\n",
            "Epoch 276/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.7892e-05 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9265\n",
            "Epoch 277/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.7544e-05 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9265\n",
            "Epoch 278/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 8.5718e-05 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9248\n",
            "Epoch 279/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 8.4751e-05 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.9265\n",
            "Epoch 280/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 8.4077e-05 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9265\n",
            "Epoch 281/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 8.3149e-05 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9265\n",
            "Epoch 282/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.2054e-05 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9248\n",
            "Epoch 283/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.1432e-05 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9265\n",
            "Epoch 284/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 8.0929e-05 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9265\n",
            "Epoch 285/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 7.9670e-05 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9248\n",
            "Epoch 286/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.8680e-05 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9265\n",
            "Epoch 287/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.7632e-05 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.9265\n",
            "Epoch 288/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 7.6984e-05 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9265\n",
            "Epoch 289/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.5953e-05 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9265\n",
            "Epoch 290/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 7.5298e-05 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9265\n",
            "Epoch 291/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.4845e-05 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9265\n",
            "Epoch 292/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.3786e-05 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9265\n",
            "Epoch 293/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 7.2993e-05 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9265\n",
            "Epoch 294/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.2169e-05 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9248\n",
            "Epoch 295/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.1612e-05 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9265\n",
            "Epoch 296/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 7.0571e-05 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9265\n",
            "Epoch 297/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 7.0093e-05 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9265\n",
            "Epoch 298/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.9267e-05 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9248\n",
            "Epoch 299/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.8532e-05 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9248\n",
            "Epoch 300/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.7543e-05 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9265\n",
            "Epoch 301/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 6.7435e-05 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9265\n",
            "Epoch 302/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.6331e-05 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9248\n",
            "Epoch 303/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.6170e-05 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.9265\n",
            "Epoch 304/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.4891e-05 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9265\n",
            "Epoch 305/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.4131e-05 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9265\n",
            "Epoch 306/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.3951e-05 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.9265\n",
            "Epoch 307/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.2943e-05 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9265\n",
            "Epoch 308/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.2425e-05 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9265\n",
            "Epoch 309/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 6.1651e-05 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9265\n",
            "Epoch 310/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 6.0822e-05 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9265\n",
            "Epoch 311/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 6.0419e-05 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.9248\n",
            "Epoch 312/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.9999e-05 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9265\n",
            "Epoch 313/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.9310e-05 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9265\n",
            "Epoch 314/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.8431e-05 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.9248\n",
            "Epoch 315/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.8352e-05 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9248\n",
            "Epoch 316/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.7105e-05 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9265\n",
            "Epoch 317/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.6839e-05 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9265\n",
            "Epoch 318/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 5.6212e-05 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9248\n",
            "Epoch 319/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 5.5666e-05 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9265\n",
            "Epoch 320/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.5531e-05 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9265\n",
            "Epoch 321/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.4837e-05 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9265\n",
            "Epoch 322/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.3773e-05 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9265\n",
            "Epoch 323/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.3403e-05 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9265\n",
            "Epoch 324/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.2781e-05 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.9248\n",
            "Epoch 325/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.2281e-05 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9265\n",
            "Epoch 326/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 5.1836e-05 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9248\n",
            "Epoch 327/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.1760e-05 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.9265\n",
            "Epoch 328/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 5.1353e-05 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9265\n",
            "Epoch 329/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 5.0283e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9265\n",
            "Epoch 330/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.9799e-05 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9248\n",
            "Epoch 331/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.9256e-05 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9265\n",
            "Epoch 332/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 4.8825e-05 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9265\n",
            "Epoch 333/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.8303e-05 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9265\n",
            "Epoch 334/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 4.7652e-05 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9265\n",
            "Epoch 335/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 4.7413e-05 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9248\n",
            "Epoch 336/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.6872e-05 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9265\n",
            "Epoch 337/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.6404e-05 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.9265\n",
            "Epoch 338/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.5951e-05 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9248\n",
            "Epoch 339/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.5434e-05 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9265\n",
            "Epoch 340/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.5015e-05 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9265\n",
            "Epoch 341/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.4714e-05 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9265\n",
            "Epoch 342/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.4105e-05 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9265\n",
            "Epoch 343/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.3703e-05 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9265\n",
            "Epoch 344/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 4.3301e-05 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9265\n",
            "Epoch 345/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 4.2792e-05 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9265\n",
            "Epoch 346/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 4.2491e-05 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9248\n",
            "Epoch 347/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.2027e-05 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9265\n",
            "Epoch 348/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.1444e-05 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9248\n",
            "Epoch 349/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.1156e-05 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9248\n",
            "Epoch 350/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.0858e-05 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9265\n",
            "Epoch 351/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.0498e-05 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9265\n",
            "Epoch 352/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 4.0001e-05 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9265\n",
            "Epoch 353/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.9545e-05 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9265\n",
            "Epoch 354/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.9146e-05 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9265\n",
            "Epoch 355/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.8728e-05 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9265\n",
            "Epoch 356/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.8355e-05 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9265\n",
            "Epoch 357/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.7962e-05 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9265\n",
            "Epoch 358/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.7640e-05 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9265\n",
            "Epoch 359/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.7290e-05 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9265\n",
            "Epoch 360/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.7053e-05 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9248\n",
            "Epoch 361/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.6573e-05 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9265\n",
            "Epoch 362/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.6430e-05 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9265\n",
            "Epoch 363/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.5773e-05 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9248\n",
            "Epoch 364/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.5717e-05 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9265\n",
            "Epoch 365/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.5283e-05 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9265\n",
            "Epoch 366/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.4768e-05 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9248\n",
            "Epoch 367/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.4594e-05 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9265\n",
            "Epoch 368/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.4146e-05 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.9265\n",
            "Epoch 369/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 3.3959e-05 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.9265\n",
            "Epoch 370/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 3.3552e-05 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9248\n",
            "Epoch 371/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.3103e-05 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9265\n",
            "Epoch 372/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 3.3076e-05 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9248\n",
            "Epoch 373/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.2597e-05 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9265\n",
            "Epoch 374/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 3.2400e-05 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9265\n",
            "Epoch 375/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 3.2143e-05 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9265\n",
            "Epoch 376/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.1995e-05 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9265\n",
            "Epoch 377/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 3.1609e-05 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9265\n",
            "Epoch 378/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.1044e-05 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9265\n",
            "Epoch 379/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.0796e-05 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9265\n",
            "Epoch 380/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.0511e-05 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9265\n",
            "Epoch 381/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 3.0393e-05 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9265\n",
            "Epoch 382/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.9804e-05 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9265\n",
            "Epoch 383/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.9638e-05 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.9265\n",
            "Epoch 384/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.9346e-05 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9265\n",
            "Epoch 385/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8978e-05 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9265\n",
            "Epoch 386/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8895e-05 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9265\n",
            "Epoch 387/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8538e-05 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9248\n",
            "Epoch 388/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.8316e-05 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9265\n",
            "Epoch 389/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7955e-05 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9248\n",
            "Epoch 390/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7879e-05 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9265\n",
            "Epoch 391/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7478e-05 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9282\n",
            "Epoch 392/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.7197e-05 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9265\n",
            "Epoch 393/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.6909e-05 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9248\n",
            "Epoch 394/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.6784e-05 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9248\n",
            "Epoch 395/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.6465e-05 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9265\n",
            "Epoch 396/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.6275e-05 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9248\n",
            "Epoch 397/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.6139e-05 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.9248\n",
            "Epoch 398/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.5736e-05 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9248\n",
            "Epoch 399/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2.5585e-05 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9248\n",
            "Epoch 400/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2.5346e-05 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9265\n",
            "Epoch 401/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.5048e-05 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9265\n",
            "Epoch 402/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.4922e-05 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9248\n",
            "Epoch 403/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.4502e-05 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9265\n",
            "Epoch 404/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.4379e-05 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9282\n",
            "Epoch 405/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.4137e-05 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9248\n",
            "Epoch 406/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.3901e-05 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9265\n",
            "Epoch 407/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.3665e-05 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9265\n",
            "Epoch 408/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.3425e-05 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9265\n",
            "Epoch 409/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.3381e-05 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9248\n",
            "Epoch 410/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.2994e-05 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9265\n",
            "Epoch 411/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.2740e-05 - accuracy: 1.0000 - val_loss: 0.4622 - val_accuracy: 0.9265\n",
            "Epoch 412/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.2742e-05 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9282\n",
            "Epoch 413/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.2420e-05 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9248\n",
            "Epoch 414/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.2149e-05 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9265\n",
            "Epoch 415/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.1991e-05 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 0.9248\n",
            "Epoch 416/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.1737e-05 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9265\n",
            "Epoch 417/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.1580e-05 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9265\n",
            "Epoch 418/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.1328e-05 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9248\n",
            "Epoch 419/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.1268e-05 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9248\n",
            "Epoch 420/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0947e-05 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9265\n",
            "Epoch 421/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0806e-05 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9265\n",
            "Epoch 422/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0612e-05 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9248\n",
            "Epoch 423/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0476e-05 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9282\n",
            "Epoch 424/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0240e-05 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.9248\n",
            "Epoch 425/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 2.0043e-05 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.9265\n",
            "Epoch 426/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.9854e-05 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9248\n",
            "Epoch 427/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.9712e-05 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9265\n",
            "Epoch 428/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.9507e-05 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9248\n",
            "Epoch 429/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.9314e-05 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9265\n",
            "Epoch 430/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.9130e-05 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9248\n",
            "Epoch 431/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.8955e-05 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9248\n",
            "Epoch 432/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.8837e-05 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.9265\n",
            "Epoch 433/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.8770e-05 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9265\n",
            "Epoch 434/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.8594e-05 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9265\n",
            "Epoch 435/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.8352e-05 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9248\n",
            "Epoch 436/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.8153e-05 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9265\n",
            "Epoch 437/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.7962e-05 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9248\n",
            "Epoch 438/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.7878e-05 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9282\n",
            "Epoch 439/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.7605e-05 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9248\n",
            "Epoch 440/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.7466e-05 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9248\n",
            "Epoch 441/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.7315e-05 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9282\n",
            "Epoch 442/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.7204e-05 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9265\n",
            "Epoch 443/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.6982e-05 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9265\n",
            "Epoch 444/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.6833e-05 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.9265\n",
            "Epoch 445/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.6680e-05 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9282\n",
            "Epoch 446/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.6577e-05 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9248\n",
            "Epoch 447/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.6454e-05 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9282\n",
            "Epoch 448/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.6236e-05 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9248\n",
            "Epoch 449/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.6156e-05 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9265\n",
            "Epoch 450/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5981e-05 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9265\n",
            "Epoch 451/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.5848e-05 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9248\n",
            "Epoch 452/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5662e-05 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9282\n",
            "Epoch 453/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5564e-05 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9265\n",
            "Epoch 454/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5420e-05 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9248\n",
            "Epoch 455/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5376e-05 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9265\n",
            "Epoch 456/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5155e-05 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9282\n",
            "Epoch 457/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.5004e-05 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9248\n",
            "Epoch 458/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4862e-05 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.9248\n",
            "Epoch 459/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4711e-05 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9248\n",
            "Epoch 460/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4607e-05 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9282\n",
            "Epoch 461/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4497e-05 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9265\n",
            "Epoch 462/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4378e-05 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9265\n",
            "Epoch 463/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4273e-05 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9265\n",
            "Epoch 464/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.4095e-05 - accuracy: 1.0000 - val_loss: 0.4789 - val_accuracy: 0.9265\n",
            "Epoch 465/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.3977e-05 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9282\n",
            "Epoch 466/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.3812e-05 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9248\n",
            "Epoch 467/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.3707e-05 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.9248\n",
            "Epoch 468/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.3591e-05 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9282\n",
            "Epoch 469/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.3551e-05 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.9265\n",
            "Epoch 470/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.3349e-05 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.9282\n",
            "Epoch 471/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.3196e-05 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9248\n",
            "Epoch 472/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.3107e-05 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9282\n",
            "Epoch 473/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.3016e-05 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9248\n",
            "Epoch 474/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.2919e-05 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9282\n",
            "Epoch 475/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.2772e-05 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9248\n",
            "Epoch 476/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.2650e-05 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9282\n",
            "Epoch 477/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 1.2532e-05 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9265\n",
            "Epoch 478/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.2419e-05 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9265\n",
            "Epoch 479/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.2287e-05 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9265\n",
            "Epoch 480/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.2229e-05 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9248\n",
            "Epoch 481/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.2112e-05 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9282\n",
            "Epoch 482/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.2018e-05 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9265\n",
            "Epoch 483/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.1903e-05 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.9282\n",
            "Epoch 484/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.1793e-05 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.9265\n",
            "Epoch 485/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1680e-05 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9282\n",
            "Epoch 486/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1564e-05 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9265\n",
            "Epoch 487/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1451e-05 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.9265\n",
            "Epoch 488/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.1394e-05 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9282\n",
            "Epoch 489/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1306e-05 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9265\n",
            "Epoch 490/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.1179e-05 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9282\n",
            "Epoch 491/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.1067e-05 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9265\n",
            "Epoch 492/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0991e-05 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9265\n",
            "Epoch 493/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0873e-05 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9282\n",
            "Epoch 494/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0809e-05 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9265\n",
            "Epoch 495/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0685e-05 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9248\n",
            "Epoch 496/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0594e-05 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9265\n",
            "Epoch 497/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0559e-05 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9265\n",
            "Epoch 498/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1.0519e-05 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9248\n",
            "Epoch 499/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0323e-05 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9282\n",
            "Epoch 500/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.0243e-05 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXZlrf50ScfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0306d74e-8573-42af-c433-2a7f5ca03748"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=(X_train2.shape[1],)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 256)               7168      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 48,970\n",
            "Trainable params: 48,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShQiMRLQRgNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e078774-ca09-4af9-deb3-c37977e88c84"
      },
      "source": [
        "classifier2 = model.fit(X_train2, y_train2,batch_size=128, epochs=500, validation_data=(X_test2,y_test2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1125 samples, validate on 375 samples\n",
            "Epoch 1/500\n",
            "1125/1125 [==============================] - 0s 159us/step - loss: 2.2330 - accuracy: 0.2160 - val_loss: 2.1395 - val_accuracy: 0.3333\n",
            "Epoch 2/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.0072 - accuracy: 0.4329 - val_loss: 1.9663 - val_accuracy: 0.3840\n",
            "Epoch 3/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.7661 - accuracy: 0.4871 - val_loss: 1.7484 - val_accuracy: 0.4800\n",
            "Epoch 4/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.4844 - accuracy: 0.5884 - val_loss: 1.4712 - val_accuracy: 0.5733\n",
            "Epoch 5/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.2073 - accuracy: 0.6658 - val_loss: 1.2367 - val_accuracy: 0.6213\n",
            "Epoch 6/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.9637 - accuracy: 0.7342 - val_loss: 1.0315 - val_accuracy: 0.6907\n",
            "Epoch 7/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.7717 - accuracy: 0.8000 - val_loss: 0.8824 - val_accuracy: 0.6987\n",
            "Epoch 8/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.6256 - accuracy: 0.8436 - val_loss: 0.7635 - val_accuracy: 0.7573\n",
            "Epoch 9/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 0.5118 - accuracy: 0.8791 - val_loss: 0.6634 - val_accuracy: 0.7867\n",
            "Epoch 10/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.4210 - accuracy: 0.9049 - val_loss: 0.6081 - val_accuracy: 0.8107\n",
            "Epoch 11/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.3472 - accuracy: 0.9307 - val_loss: 0.5200 - val_accuracy: 0.8507\n",
            "Epoch 12/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.2931 - accuracy: 0.9440 - val_loss: 0.4896 - val_accuracy: 0.8480\n",
            "Epoch 13/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.2449 - accuracy: 0.9582 - val_loss: 0.4285 - val_accuracy: 0.8667\n",
            "Epoch 14/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.2087 - accuracy: 0.9742 - val_loss: 0.4228 - val_accuracy: 0.8587\n",
            "Epoch 15/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.1823 - accuracy: 0.9733 - val_loss: 0.3809 - val_accuracy: 0.8827\n",
            "Epoch 16/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 0.1584 - accuracy: 0.9796 - val_loss: 0.3549 - val_accuracy: 0.8827\n",
            "Epoch 17/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 0.1409 - accuracy: 0.9804 - val_loss: 0.3330 - val_accuracy: 0.9040\n",
            "Epoch 18/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 0.1158 - accuracy: 0.9929 - val_loss: 0.3256 - val_accuracy: 0.8933\n",
            "Epoch 19/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 0.0994 - accuracy: 0.9938 - val_loss: 0.2959 - val_accuracy: 0.9093\n",
            "Epoch 20/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0866 - accuracy: 0.9964 - val_loss: 0.2932 - val_accuracy: 0.9013\n",
            "Epoch 21/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0776 - accuracy: 0.9956 - val_loss: 0.2772 - val_accuracy: 0.9200\n",
            "Epoch 22/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0721 - accuracy: 0.9964 - val_loss: 0.2850 - val_accuracy: 0.9147\n",
            "Epoch 23/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0599 - accuracy: 0.9982 - val_loss: 0.2559 - val_accuracy: 0.9147\n",
            "Epoch 24/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 0.0527 - accuracy: 0.9991 - val_loss: 0.2597 - val_accuracy: 0.9120\n",
            "Epoch 25/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9227\n",
            "Epoch 26/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0417 - accuracy: 0.9991 - val_loss: 0.2378 - val_accuracy: 0.9280\n",
            "Epoch 27/500\n",
            "1125/1125 [==============================] - 0s 82us/step - loss: 0.0385 - accuracy: 0.9991 - val_loss: 0.2432 - val_accuracy: 0.9227\n",
            "Epoch 28/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9280\n",
            "Epoch 29/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9280\n",
            "Epoch 30/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9280\n",
            "Epoch 31/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9333\n",
            "Epoch 32/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9280\n",
            "Epoch 33/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9360\n",
            "Epoch 34/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9280\n",
            "Epoch 35/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9360\n",
            "Epoch 36/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9333\n",
            "Epoch 37/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9413\n",
            "Epoch 38/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9333\n",
            "Epoch 39/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9413\n",
            "Epoch 40/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9413\n",
            "Epoch 41/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9360\n",
            "Epoch 42/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9360\n",
            "Epoch 43/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9440\n",
            "Epoch 44/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9333\n",
            "Epoch 45/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9413\n",
            "Epoch 46/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9280\n",
            "Epoch 47/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9360\n",
            "Epoch 48/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9387\n",
            "Epoch 49/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9307\n",
            "Epoch 50/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9413\n",
            "Epoch 51/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9360\n",
            "Epoch 52/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9387\n",
            "Epoch 53/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9333\n",
            "Epoch 54/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9413\n",
            "Epoch 55/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9360\n",
            "Epoch 56/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9333\n",
            "Epoch 57/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9387\n",
            "Epoch 58/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9333\n",
            "Epoch 59/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9387\n",
            "Epoch 60/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9333\n",
            "Epoch 61/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9413\n",
            "Epoch 62/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9387\n",
            "Epoch 63/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9387\n",
            "Epoch 64/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9387\n",
            "Epoch 65/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9387\n",
            "Epoch 66/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9333\n",
            "Epoch 67/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9387\n",
            "Epoch 68/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9280\n",
            "Epoch 69/500\n",
            "1125/1125 [==============================] - 0s 79us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9413\n",
            "Epoch 70/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9360\n",
            "Epoch 71/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9387\n",
            "Epoch 72/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9360\n",
            "Epoch 73/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9387\n",
            "Epoch 74/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9387\n",
            "Epoch 75/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9360\n",
            "Epoch 76/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9387\n",
            "Epoch 77/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9413\n",
            "Epoch 78/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9387\n",
            "Epoch 79/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9360\n",
            "Epoch 80/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9387\n",
            "Epoch 81/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9387\n",
            "Epoch 82/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9413\n",
            "Epoch 83/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9413\n",
            "Epoch 84/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9387\n",
            "Epoch 85/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9387\n",
            "Epoch 86/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9413\n",
            "Epoch 87/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9387\n",
            "Epoch 88/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9413\n",
            "Epoch 89/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9413\n",
            "Epoch 90/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9387\n",
            "Epoch 91/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9387\n",
            "Epoch 92/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9413\n",
            "Epoch 93/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9413\n",
            "Epoch 94/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9413\n",
            "Epoch 95/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9413\n",
            "Epoch 96/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9413\n",
            "Epoch 97/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9413\n",
            "Epoch 98/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9413\n",
            "Epoch 99/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9413\n",
            "Epoch 100/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9387\n",
            "Epoch 101/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9387\n",
            "Epoch 102/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9360\n",
            "Epoch 103/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9413\n",
            "Epoch 104/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9387\n",
            "Epoch 105/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9413\n",
            "Epoch 106/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9413\n",
            "Epoch 107/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9413\n",
            "Epoch 108/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9387\n",
            "Epoch 109/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9387\n",
            "Epoch 110/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9413\n",
            "Epoch 111/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9387\n",
            "Epoch 112/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9413\n",
            "Epoch 113/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9387\n",
            "Epoch 114/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9413\n",
            "Epoch 115/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 9.8323e-04 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9387\n",
            "Epoch 116/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 9.8445e-04 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9360\n",
            "Epoch 117/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 9.6618e-04 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9413\n",
            "Epoch 118/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 9.3512e-04 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9387\n",
            "Epoch 119/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 9.1693e-04 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9387\n",
            "Epoch 120/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 9.0177e-04 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9387\n",
            "Epoch 121/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 8.8148e-04 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9387\n",
            "Epoch 122/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 8.6428e-04 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9387\n",
            "Epoch 123/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 8.5292e-04 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9387\n",
            "Epoch 124/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 8.4229e-04 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9387\n",
            "Epoch 125/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 8.2012e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9387\n",
            "Epoch 126/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 8.0239e-04 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9387\n",
            "Epoch 127/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 7.8759e-04 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9387\n",
            "Epoch 128/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 7.7440e-04 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9387\n",
            "Epoch 129/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 7.6062e-04 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9387\n",
            "Epoch 130/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 7.4562e-04 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9387\n",
            "Epoch 131/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 7.3888e-04 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9387\n",
            "Epoch 132/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 7.1864e-04 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9387\n",
            "Epoch 133/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 7.0853e-04 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9387\n",
            "Epoch 134/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 6.9500e-04 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9387\n",
            "Epoch 135/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 6.8991e-04 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9387\n",
            "Epoch 136/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 6.7083e-04 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9387\n",
            "Epoch 137/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 6.6546e-04 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9387\n",
            "Epoch 138/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 6.5089e-04 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9387\n",
            "Epoch 139/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 6.4020e-04 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9387\n",
            "Epoch 140/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 6.3337e-04 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9387\n",
            "Epoch 141/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 6.1964e-04 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9387\n",
            "Epoch 142/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 6.1204e-04 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9387\n",
            "Epoch 143/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 6.0022e-04 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9387\n",
            "Epoch 144/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 5.8927e-04 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9387\n",
            "Epoch 145/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 5.8279e-04 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9387\n",
            "Epoch 146/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 5.7052e-04 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9387\n",
            "Epoch 147/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 5.6379e-04 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9387\n",
            "Epoch 148/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 5.5431e-04 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9387\n",
            "Epoch 149/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 5.4535e-04 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9387\n",
            "Epoch 150/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 5.3808e-04 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9387\n",
            "Epoch 151/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 5.2746e-04 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9387\n",
            "Epoch 152/500\n",
            "1125/1125 [==============================] - 0s 82us/step - loss: 5.1954e-04 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9387\n",
            "Epoch 153/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 5.1227e-04 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9387\n",
            "Epoch 154/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 5.0429e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9387\n",
            "Epoch 155/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 4.9624e-04 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9387\n",
            "Epoch 156/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.9003e-04 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9387\n",
            "Epoch 157/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 4.8159e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9387\n",
            "Epoch 158/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 4.7445e-04 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9387\n",
            "Epoch 159/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.6797e-04 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9387\n",
            "Epoch 160/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.6588e-04 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9387\n",
            "Epoch 161/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.5383e-04 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9360\n",
            "Epoch 162/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.4903e-04 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9387\n",
            "Epoch 163/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 4.4358e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9387\n",
            "Epoch 164/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 4.3573e-04 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9387\n",
            "Epoch 165/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 4.3121e-04 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9387\n",
            "Epoch 166/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 4.2287e-04 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9387\n",
            "Epoch 167/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 4.1761e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9387\n",
            "Epoch 168/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 4.1115e-04 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9387\n",
            "Epoch 169/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.0563e-04 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9387\n",
            "Epoch 170/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.0137e-04 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9387\n",
            "Epoch 171/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 3.9506e-04 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9360\n",
            "Epoch 172/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 3.9060e-04 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9387\n",
            "Epoch 173/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.8354e-04 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9387\n",
            "Epoch 174/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 3.8028e-04 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9387\n",
            "Epoch 175/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.7593e-04 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9387\n",
            "Epoch 176/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.6949e-04 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9387\n",
            "Epoch 177/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 3.6561e-04 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9387\n",
            "Epoch 178/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.6129e-04 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9360\n",
            "Epoch 179/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 3.5434e-04 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9387\n",
            "Epoch 180/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 3.5218e-04 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9387\n",
            "Epoch 181/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.4644e-04 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9387\n",
            "Epoch 182/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.4301e-04 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9360\n",
            "Epoch 183/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.3758e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9360\n",
            "Epoch 184/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 3.3389e-04 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9387\n",
            "Epoch 185/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 3.2859e-04 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9387\n",
            "Epoch 186/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.2465e-04 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9387\n",
            "Epoch 187/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.2058e-04 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9360\n",
            "Epoch 188/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.1649e-04 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9387\n",
            "Epoch 189/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.1176e-04 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9360\n",
            "Epoch 190/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 3.0856e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9360\n",
            "Epoch 191/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.0479e-04 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9360\n",
            "Epoch 192/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.0153e-04 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9360\n",
            "Epoch 193/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.9734e-04 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9387\n",
            "Epoch 194/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.9374e-04 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9387\n",
            "Epoch 195/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.9171e-04 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9360\n",
            "Epoch 196/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 2.8718e-04 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9387\n",
            "Epoch 197/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 2.8370e-04 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9387\n",
            "Epoch 198/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 2.8084e-04 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9360\n",
            "Epoch 199/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 2.7611e-04 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9360\n",
            "Epoch 200/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 2.7388e-04 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9387\n",
            "Epoch 201/500\n",
            "1125/1125 [==============================] - 0s 79us/step - loss: 2.7155e-04 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9360\n",
            "Epoch 202/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.6676e-04 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9387\n",
            "Epoch 203/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.6394e-04 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9360\n",
            "Epoch 204/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 2.6064e-04 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9360\n",
            "Epoch 205/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.5830e-04 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9360\n",
            "Epoch 206/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.5500e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9387\n",
            "Epoch 207/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.5198e-04 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9360\n",
            "Epoch 208/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.5011e-04 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9360\n",
            "Epoch 209/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 2.4676e-04 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9360\n",
            "Epoch 210/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 2.4372e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9360\n",
            "Epoch 211/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 2.4145e-04 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9387\n",
            "Epoch 212/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 2.3920e-04 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9360\n",
            "Epoch 213/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 2.3484e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9360\n",
            "Epoch 214/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.3324e-04 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9387\n",
            "Epoch 215/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.3045e-04 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9360\n",
            "Epoch 216/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.2770e-04 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9360\n",
            "Epoch 217/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.2423e-04 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9360\n",
            "Epoch 218/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.2221e-04 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9360\n",
            "Epoch 219/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.1993e-04 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9360\n",
            "Epoch 220/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 2.1992e-04 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9360\n",
            "Epoch 221/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.1539e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9360\n",
            "Epoch 222/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 2.1260e-04 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9360\n",
            "Epoch 223/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.1027e-04 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9360\n",
            "Epoch 224/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.0776e-04 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9360\n",
            "Epoch 225/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.0561e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9360\n",
            "Epoch 226/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 2.0332e-04 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9360\n",
            "Epoch 227/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 2.0197e-04 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9360\n",
            "Epoch 228/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.9895e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9360\n",
            "Epoch 229/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.9782e-04 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9360\n",
            "Epoch 230/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 1.9544e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9360\n",
            "Epoch 231/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 1.9316e-04 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9360\n",
            "Epoch 232/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.9091e-04 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9360\n",
            "Epoch 233/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.8959e-04 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9360\n",
            "Epoch 234/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 1.8712e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9360\n",
            "Epoch 235/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.8480e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9360\n",
            "Epoch 236/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.8330e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9360\n",
            "Epoch 237/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.8149e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9360\n",
            "Epoch 238/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 1.7921e-04 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9360\n",
            "Epoch 239/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.7804e-04 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9360\n",
            "Epoch 240/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 1.7594e-04 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9360\n",
            "Epoch 241/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.7515e-04 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9360\n",
            "Epoch 242/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 1.7219e-04 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9360\n",
            "Epoch 243/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.7061e-04 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9360\n",
            "Epoch 244/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.6888e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9360\n",
            "Epoch 245/500\n",
            "1125/1125 [==============================] - 0s 81us/step - loss: 1.6799e-04 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9360\n",
            "Epoch 246/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.6546e-04 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9360\n",
            "Epoch 247/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.6379e-04 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9360\n",
            "Epoch 248/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 1.6212e-04 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9360\n",
            "Epoch 249/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.6107e-04 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9360\n",
            "Epoch 250/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.5897e-04 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9360\n",
            "Epoch 251/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.5731e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9360\n",
            "Epoch 252/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.5573e-04 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9360\n",
            "Epoch 253/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 1.5467e-04 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9360\n",
            "Epoch 254/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.5261e-04 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9360\n",
            "Epoch 255/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.5160e-04 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9360\n",
            "Epoch 256/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 1.5015e-04 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9360\n",
            "Epoch 257/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 1.4813e-04 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9360\n",
            "Epoch 258/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 1.4700e-04 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9360\n",
            "Epoch 259/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.4568e-04 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9360\n",
            "Epoch 260/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.4396e-04 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9360\n",
            "Epoch 261/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 1.4327e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9360\n",
            "Epoch 262/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.4127e-04 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9360\n",
            "Epoch 263/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.4025e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9360\n",
            "Epoch 264/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 1.3873e-04 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9360\n",
            "Epoch 265/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.3753e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9360\n",
            "Epoch 266/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.3614e-04 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9360\n",
            "Epoch 267/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.3489e-04 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9360\n",
            "Epoch 268/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 1.3346e-04 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9360\n",
            "Epoch 269/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.3238e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9360\n",
            "Epoch 270/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.3142e-04 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9360\n",
            "Epoch 271/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.2959e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9360\n",
            "Epoch 272/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 1.2834e-04 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9360\n",
            "Epoch 273/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 1.2724e-04 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9360\n",
            "Epoch 274/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.2633e-04 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9360\n",
            "Epoch 275/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.2501e-04 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9360\n",
            "Epoch 276/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.2428e-04 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9360\n",
            "Epoch 277/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.2297e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9360\n",
            "Epoch 278/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 1.2182e-04 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9360\n",
            "Epoch 279/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 1.2092e-04 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9360\n",
            "Epoch 280/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 1.1963e-04 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9360\n",
            "Epoch 281/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.1830e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9360\n",
            "Epoch 282/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.1748e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9360\n",
            "Epoch 283/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.1621e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9360\n",
            "Epoch 284/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.1530e-04 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9360\n",
            "Epoch 285/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 1.1408e-04 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9360\n",
            "Epoch 286/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 1.1321e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9360\n",
            "Epoch 287/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.1238e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9360\n",
            "Epoch 288/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.1134e-04 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9360\n",
            "Epoch 289/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 1.1088e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9360\n",
            "Epoch 290/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.0922e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9360\n",
            "Epoch 291/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 1.0855e-04 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9360\n",
            "Epoch 292/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.0721e-04 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9360\n",
            "Epoch 293/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.0654e-04 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9360\n",
            "Epoch 294/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 1.0542e-04 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9360\n",
            "Epoch 295/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 1.0437e-04 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9360\n",
            "Epoch 296/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 1.0360e-04 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9360\n",
            "Epoch 297/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 1.0271e-04 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9360\n",
            "Epoch 298/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 1.0187e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9360\n",
            "Epoch 299/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 1.0088e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9360\n",
            "Epoch 300/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 9.9950e-05 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9360\n",
            "Epoch 301/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 9.9281e-05 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9360\n",
            "Epoch 302/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 9.8277e-05 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9360\n",
            "Epoch 303/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 9.7656e-05 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9360\n",
            "Epoch 304/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 9.6614e-05 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9360\n",
            "Epoch 305/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 9.5993e-05 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9360\n",
            "Epoch 306/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 9.4944e-05 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9360\n",
            "Epoch 307/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 9.4108e-05 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9360\n",
            "Epoch 308/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 9.3427e-05 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9360\n",
            "Epoch 309/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 9.2545e-05 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9360\n",
            "Epoch 310/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 9.1829e-05 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9360\n",
            "Epoch 311/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 9.1011e-05 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9360\n",
            "Epoch 312/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 9.0353e-05 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9360\n",
            "Epoch 313/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 8.9778e-05 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9360\n",
            "Epoch 314/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 8.8836e-05 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9360\n",
            "Epoch 315/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 8.8144e-05 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9360\n",
            "Epoch 316/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 8.7320e-05 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9360\n",
            "Epoch 317/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 8.6676e-05 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9360\n",
            "Epoch 318/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 8.5704e-05 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9360\n",
            "Epoch 319/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 8.5446e-05 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9360\n",
            "Epoch 320/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 8.4458e-05 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9360\n",
            "Epoch 321/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 8.3736e-05 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9360\n",
            "Epoch 322/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 8.3123e-05 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9360\n",
            "Epoch 323/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 8.2491e-05 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9360\n",
            "Epoch 324/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 8.1695e-05 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9360\n",
            "Epoch 325/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 8.1144e-05 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9360\n",
            "Epoch 326/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 8.0479e-05 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9360\n",
            "Epoch 327/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 7.9849e-05 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9360\n",
            "Epoch 328/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 7.9307e-05 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9360\n",
            "Epoch 329/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 7.8699e-05 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9360\n",
            "Epoch 330/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 7.7834e-05 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9360\n",
            "Epoch 331/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 7.7234e-05 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9360\n",
            "Epoch 332/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 7.6588e-05 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9360\n",
            "Epoch 333/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 7.5856e-05 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9360\n",
            "Epoch 334/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 7.5475e-05 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9360\n",
            "Epoch 335/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 7.4757e-05 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9360\n",
            "Epoch 336/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 7.4092e-05 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9360\n",
            "Epoch 337/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 7.3857e-05 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9360\n",
            "Epoch 338/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 7.2876e-05 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9360\n",
            "Epoch 339/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 7.2423e-05 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9360\n",
            "Epoch 340/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 7.1790e-05 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9360\n",
            "Epoch 341/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 7.1200e-05 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9360\n",
            "Epoch 342/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 7.0673e-05 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9360\n",
            "Epoch 343/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 7.0251e-05 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9360\n",
            "Epoch 344/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 6.9683e-05 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9360\n",
            "Epoch 345/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 6.9171e-05 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9360\n",
            "Epoch 346/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 6.8470e-05 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9360\n",
            "Epoch 347/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 6.7886e-05 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9360\n",
            "Epoch 348/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 6.7442e-05 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9360\n",
            "Epoch 349/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 6.6792e-05 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9360\n",
            "Epoch 350/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 6.6340e-05 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9360\n",
            "Epoch 351/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 6.5879e-05 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9360\n",
            "Epoch 352/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 6.5288e-05 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9387\n",
            "Epoch 353/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 6.4766e-05 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9360\n",
            "Epoch 354/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 6.4308e-05 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9360\n",
            "Epoch 355/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 6.3741e-05 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9360\n",
            "Epoch 356/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 6.3283e-05 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9360\n",
            "Epoch 357/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 6.2952e-05 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9360\n",
            "Epoch 358/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 6.2365e-05 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9360\n",
            "Epoch 359/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 6.1950e-05 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9387\n",
            "Epoch 360/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 6.1407e-05 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9360\n",
            "Epoch 361/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 6.0843e-05 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9360\n",
            "Epoch 362/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 6.0564e-05 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9360\n",
            "Epoch 363/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 6.0269e-05 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9387\n",
            "Epoch 364/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 5.9548e-05 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9360\n",
            "Epoch 365/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 5.9070e-05 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9360\n",
            "Epoch 366/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 5.8609e-05 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9360\n",
            "Epoch 367/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 5.8141e-05 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9387\n",
            "Epoch 368/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 5.7832e-05 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9360\n",
            "Epoch 369/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 5.7359e-05 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9360\n",
            "Epoch 370/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 5.6948e-05 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9387\n",
            "Epoch 371/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 5.6441e-05 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9387\n",
            "Epoch 372/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 5.6054e-05 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9387\n",
            "Epoch 373/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 5.5613e-05 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9360\n",
            "Epoch 374/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 5.5303e-05 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9387\n",
            "Epoch 375/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 5.4826e-05 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9360\n",
            "Epoch 376/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 5.4440e-05 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9360\n",
            "Epoch 377/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 5.3981e-05 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9360\n",
            "Epoch 378/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 5.3597e-05 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9387\n",
            "Epoch 379/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 5.3363e-05 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9387\n",
            "Epoch 380/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 5.2885e-05 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9360\n",
            "Epoch 381/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 5.2514e-05 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9387\n",
            "Epoch 382/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 5.1980e-05 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9387\n",
            "Epoch 383/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 5.1739e-05 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9387\n",
            "Epoch 384/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 5.1299e-05 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9387\n",
            "Epoch 385/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 5.1020e-05 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9360\n",
            "Epoch 386/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 5.0497e-05 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9360\n",
            "Epoch 387/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 5.0120e-05 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9387\n",
            "Epoch 388/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 4.9950e-05 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9387\n",
            "Epoch 389/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.9339e-05 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9387\n",
            "Epoch 390/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.8997e-05 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9387\n",
            "Epoch 391/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 4.8807e-05 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9387\n",
            "Epoch 392/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 4.8302e-05 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9387\n",
            "Epoch 393/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.8024e-05 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9387\n",
            "Epoch 394/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 4.7576e-05 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9387\n",
            "Epoch 395/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.7329e-05 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9387\n",
            "Epoch 396/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 4.7106e-05 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9387\n",
            "Epoch 397/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.6544e-05 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9387\n",
            "Epoch 398/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 4.6278e-05 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9387\n",
            "Epoch 399/500\n",
            "1125/1125 [==============================] - 0s 74us/step - loss: 4.5988e-05 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9387\n",
            "Epoch 400/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 4.5655e-05 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9387\n",
            "Epoch 401/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.5268e-05 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9387\n",
            "Epoch 402/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 4.4899e-05 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9387\n",
            "Epoch 403/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.4646e-05 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9387\n",
            "Epoch 404/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.4326e-05 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9387\n",
            "Epoch 405/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 4.3978e-05 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9387\n",
            "Epoch 406/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 4.3815e-05 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9387\n",
            "Epoch 407/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 4.3364e-05 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9387\n",
            "Epoch 408/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 4.3089e-05 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9387\n",
            "Epoch 409/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 4.2729e-05 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9387\n",
            "Epoch 410/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 4.2416e-05 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9387\n",
            "Epoch 411/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 4.2144e-05 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9387\n",
            "Epoch 412/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 4.1831e-05 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9387\n",
            "Epoch 413/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 4.1534e-05 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9387\n",
            "Epoch 414/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 4.1287e-05 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9387\n",
            "Epoch 415/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 4.0952e-05 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9387\n",
            "Epoch 416/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 4.0702e-05 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9387\n",
            "Epoch 417/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 4.0299e-05 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9387\n",
            "Epoch 418/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 4.0116e-05 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9387\n",
            "Epoch 419/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.9833e-05 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9387\n",
            "Epoch 420/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.9562e-05 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9387\n",
            "Epoch 421/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 3.9264e-05 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9387\n",
            "Epoch 422/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.9038e-05 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9387\n",
            "Epoch 423/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 3.8717e-05 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9387\n",
            "Epoch 424/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.8445e-05 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9387\n",
            "Epoch 425/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.8182e-05 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9387\n",
            "Epoch 426/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.7935e-05 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9387\n",
            "Epoch 427/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.7724e-05 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9387\n",
            "Epoch 428/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 3.7512e-05 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9387\n",
            "Epoch 429/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.7125e-05 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9387\n",
            "Epoch 430/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.6879e-05 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9387\n",
            "Epoch 431/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 3.6620e-05 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9387\n",
            "Epoch 432/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 3.6393e-05 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9387\n",
            "Epoch 433/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.6168e-05 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9387\n",
            "Epoch 434/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.5917e-05 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9387\n",
            "Epoch 435/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 3.5693e-05 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9387\n",
            "Epoch 436/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 3.5458e-05 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9387\n",
            "Epoch 437/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.5162e-05 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9387\n",
            "Epoch 438/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 3.4901e-05 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9387\n",
            "Epoch 439/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.4680e-05 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9387\n",
            "Epoch 440/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.4424e-05 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9387\n",
            "Epoch 441/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.4175e-05 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9387\n",
            "Epoch 442/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 3.4001e-05 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9387\n",
            "Epoch 443/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 3.3761e-05 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9387\n",
            "Epoch 444/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.3470e-05 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9387\n",
            "Epoch 445/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.3431e-05 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9387\n",
            "Epoch 446/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.3109e-05 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9387\n",
            "Epoch 447/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.2907e-05 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9387\n",
            "Epoch 448/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 3.2591e-05 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9387\n",
            "Epoch 449/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 3.2382e-05 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9387\n",
            "Epoch 450/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 3.2239e-05 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9387\n",
            "Epoch 451/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 3.1957e-05 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9387\n",
            "Epoch 452/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.1801e-05 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9387\n",
            "Epoch 453/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.1510e-05 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9387\n",
            "Epoch 454/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 3.1358e-05 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9387\n",
            "Epoch 455/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 3.1106e-05 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9387\n",
            "Epoch 456/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.0929e-05 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9387\n",
            "Epoch 457/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.0699e-05 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9387\n",
            "Epoch 458/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 3.0570e-05 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9387\n",
            "Epoch 459/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 3.0271e-05 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9387\n",
            "Epoch 460/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 3.0090e-05 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9387\n",
            "Epoch 461/500\n",
            "1125/1125 [==============================] - 0s 82us/step - loss: 2.9903e-05 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9387\n",
            "Epoch 462/500\n",
            "1125/1125 [==============================] - 0s 65us/step - loss: 2.9659e-05 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9387\n",
            "Epoch 463/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.9466e-05 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9387\n",
            "Epoch 464/500\n",
            "1125/1125 [==============================] - 0s 63us/step - loss: 2.9267e-05 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9387\n",
            "Epoch 465/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.9058e-05 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9387\n",
            "Epoch 466/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.8881e-05 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9387\n",
            "Epoch 467/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 2.8708e-05 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9387\n",
            "Epoch 468/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 2.8483e-05 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9387\n",
            "Epoch 469/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 2.8338e-05 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9387\n",
            "Epoch 470/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 2.8194e-05 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9387\n",
            "Epoch 471/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 2.7956e-05 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9387\n",
            "Epoch 472/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.7733e-05 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9387\n",
            "Epoch 473/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 2.7571e-05 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9387\n",
            "Epoch 474/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 2.7386e-05 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9387\n",
            "Epoch 475/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.7173e-05 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9387\n",
            "Epoch 476/500\n",
            "1125/1125 [==============================] - 0s 76us/step - loss: 2.7063e-05 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9387\n",
            "Epoch 477/500\n",
            "1125/1125 [==============================] - 0s 79us/step - loss: 2.6890e-05 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9387\n",
            "Epoch 478/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.6712e-05 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9387\n",
            "Epoch 479/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 2.6515e-05 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9387\n",
            "Epoch 480/500\n",
            "1125/1125 [==============================] - 0s 82us/step - loss: 2.6334e-05 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9387\n",
            "Epoch 481/500\n",
            "1125/1125 [==============================] - 0s 80us/step - loss: 2.6166e-05 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9387\n",
            "Epoch 482/500\n",
            "1125/1125 [==============================] - 0s 75us/step - loss: 2.5970e-05 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9387\n",
            "Epoch 483/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.5843e-05 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9387\n",
            "Epoch 484/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.5638e-05 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9387\n",
            "Epoch 485/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.5455e-05 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9387\n",
            "Epoch 486/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.5326e-05 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9387\n",
            "Epoch 487/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 2.5153e-05 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9387\n",
            "Epoch 488/500\n",
            "1125/1125 [==============================] - 0s 66us/step - loss: 2.5042e-05 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9387\n",
            "Epoch 489/500\n",
            "1125/1125 [==============================] - 0s 68us/step - loss: 2.4853e-05 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9387\n",
            "Epoch 490/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.4658e-05 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9387\n",
            "Epoch 491/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.4478e-05 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9387\n",
            "Epoch 492/500\n",
            "1125/1125 [==============================] - 0s 67us/step - loss: 2.4411e-05 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9387\n",
            "Epoch 493/500\n",
            "1125/1125 [==============================] - 0s 71us/step - loss: 2.4201e-05 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9387\n",
            "Epoch 494/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.4093e-05 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9387\n",
            "Epoch 495/500\n",
            "1125/1125 [==============================] - 0s 69us/step - loss: 2.3879e-05 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9387\n",
            "Epoch 496/500\n",
            "1125/1125 [==============================] - 0s 73us/step - loss: 2.3729e-05 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9387\n",
            "Epoch 497/500\n",
            "1125/1125 [==============================] - 0s 79us/step - loss: 2.3581e-05 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9387\n",
            "Epoch 498/500\n",
            "1125/1125 [==============================] - 0s 64us/step - loss: 2.3413e-05 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9387\n",
            "Epoch 499/500\n",
            "1125/1125 [==============================] - 0s 70us/step - loss: 2.3262e-05 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9387\n",
            "Epoch 500/500\n",
            "1125/1125 [==============================] - 0s 72us/step - loss: 2.3142e-05 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMzJg_ejN5Rl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a83ffc65-695e-4dee-cb0e-c52459fc6c1d"
      },
      "source": [
        "plt.plot(classifier.history['loss'])\n",
        "plt.plot(classifier.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stn1Q5GyOPii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d960126c-f0dc-4add-fcda-8a1ab6e99366"
      },
      "source": [
        "plt.plot(classifier.history['accuracy'])\n",
        "plt.plot(classifier.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Noik-v11RmjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8bf6b8b3-9a1b-45da-f032-396133b876a8"
      },
      "source": [
        "plt.plot(classifier2.history['loss'])\n",
        "plt.plot(classifier2.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNytGgaSRmjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7ffcd981-22d9-45df-f311-e7acd19e7a2e"
      },
      "source": [
        "plt.plot(classifier2.history['accuracy'])\n",
        "plt.plot(classifier2.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAES3SHuLfne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "3ec49045-519a-4f16-baa2-568a1deb8fe4"
      },
      "source": [
        "import librosa\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset_pred=pd.DataFrame(columns=columns)\n",
        "songname='/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3'\n",
        "y, sr = librosa.load(songname, mono=True)\n",
        "dur = librosa.get_duration(y=y, sr=sr)\n",
        "off=0\n",
        "if dur > 300:\n",
        "    for i in range(10):\n",
        "                      x, sr = librosa.load(songname, mono=True,offset=off,duration=30)\n",
        "                      rmse = librosa.feature.rmse(y=x)[0]\n",
        "                      chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "                      spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "                      spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "                      rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "                      zcr = librosa.feature.zero_crossing_rate(x)\n",
        "                      mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "                      filename = songname+'-'+str(i+1)\n",
        "                      data=[i,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "                      dataseries = pd.Series(data, index = dataset_pred.columns)\n",
        "                      dataset_pred = dataset_pred.append(dataseries, ignore_index=True)\n",
        "                      print(filename+\" added\" + 'dur '+str(dur))\n",
        "                      if i in range(0,3):\n",
        "                        off=off+30\n",
        "                      if i in range(3,7):\n",
        "                        off=(dur/10)*i\n",
        "                      if i in range(7,10):\n",
        "                        off= dur - ((10-i)*30)\n",
        "\n",
        "else:\n",
        "    for i in range(10):\n",
        "                      x, sr = librosa.load(songname, mono=True,offset=off,duration=(dur/10))\n",
        "                      rmse = librosa.feature.rmse(y=x)[0]\n",
        "                      chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "                      spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "                      spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "                      rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "                      zcr = librosa.feature.zero_crossing_rate(x)\n",
        "                      mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "                      filename = songname+'-'+str(i+1)\n",
        "                      data=[i,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "                      dataseries = pd.Series(data, index = dataset_pred.columns)\n",
        "                      dataset_pred = dataset_pred.append(dataseries, ignore_index=True)\n",
        "                      print(filename+\" added(small)\"+'dur '+str(dur))\n",
        "                      off=(dur/10)*(i)\n",
        "print(dataset_pred)\n",
        "\n",
        "\n",
        "example = scaler.transform(np.array(dataset_pred.iloc[:,:], dtype = float))\n",
        "\n",
        "preds = model.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],Y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(best_preds)\n",
        "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-1 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-2 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-3 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-4 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-5 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-6 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-7 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-8 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-9 addeddur 387.3175510204082\n",
            "/content/Aruna Sairam - Anathaselvam - Kurai Onrumillai.mp3-10 addeddur 387.3175510204082\n",
            "   ind      rmse  chroma_stft  ...    mfcc17    mfcc18     mfcc19\n",
            "0  0.0  0.075252     0.252327  ... -1.575397  8.036333  18.756075\n",
            "1  1.0  0.084969     0.210277  ... -3.980458  0.588751   5.053682\n",
            "2  2.0  0.069041     0.218277  ...  3.724056  8.958132  15.038593\n",
            "3  3.0  0.074601     0.237034  ... -2.390664 -1.050247   5.708027\n",
            "4  4.0  0.085669     0.228166  ... -4.177791 -0.363623   4.100052\n",
            "5  5.0  0.082826     0.216860  ... -3.656489 -0.033895   9.707301\n",
            "6  6.0  0.083428     0.216925  ... -0.676747 -0.452509   9.296269\n",
            "7  7.0  0.095408     0.222304  ... -0.423412  1.321810  13.866022\n",
            "8  8.0  0.090458     0.228894  ... -5.009334 -5.558858   4.435272\n",
            "9  9.0  0.104717     0.228406  ... -3.002876 -1.527103   9.005722\n",
            "\n",
            "[10 rows x 27 columns]\n",
            "[0 0 6 0 0 0 0 0 0 0]\n",
            "Raga for this song is : darbar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JyGofcpMnUz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a3c0fa61-92ae-4c39-8a9d-199ddff61c1b"
      },
      "source": [
        "print(raganame)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('darbar', 0), ('jaganmohini', 1), ('jaunpuri', 2), ('mayamalava gaula', 3), ('ragamalika', 4), ('shanmukhapriya', 5), ('varali', 6), ('vasanta', 7), ('yadukula kambhoji', 8), ('yamuna kalyani', 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C505xrRMWUfW",
        "colab_type": "text"
      },
      "source": [
        "#LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPwFtmYGkizj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "4db8c97f-f1a5-4f59-a834-7edba0a59ec2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model = Sequential()\n",
        "adam1 = Adam(learning_rate=0.0009)\n",
        "model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.25, return_sequences=True,input_shape=input_shape))\n",
        "model.add(LSTM(units=64,  dropout=0.05, recurrent_dropout=0.25, return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=10, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam1, metrics=[\"accuracy\"],)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 1, 128)            79872     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 1, 64)             49408     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 129,930\n",
            "Trainable params: 129,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q0ZmYeQeTFuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74139164-0086-4776-a72d-2c2d5514265e"
      },
      "source": [
        "batch_size = 35 # num of training examples per minibatch\n",
        "num_epochs =300\n",
        "classify2 = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(X_test,y_test),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            " 1/51 [..............................] - ETA: 31s - loss: 2.3003 - accuracy: 0.1143WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0117s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0117s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "47/51 [==========================>...] - ETA: 0s - loss: 2.2762 - accuracy: 0.2128WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_test_batch_end` time: 0.0035s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_test_batch_end` time: 0.0035s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 2s 36ms/step - loss: 2.2727 - accuracy: 0.2228 - val_loss: 2.2266 - val_accuracy: 0.3179\n",
            "Epoch 2/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.1021 - accuracy: 0.3556 - val_loss: 1.9451 - val_accuracy: 0.3692\n",
            "Epoch 3/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 1.7337 - accuracy: 0.3698 - val_loss: 1.5861 - val_accuracy: 0.3966\n",
            "Epoch 4/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 1.4225 - accuracy: 0.4627 - val_loss: 1.2914 - val_accuracy: 0.5385\n",
            "Epoch 5/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 1.1489 - accuracy: 0.5909 - val_loss: 1.0280 - val_accuracy: 0.6718\n",
            "Epoch 6/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.9672 - accuracy: 0.6707 - val_loss: 0.8671 - val_accuracy: 0.7077\n",
            "Epoch 7/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.8505 - accuracy: 0.7197 - val_loss: 0.7636 - val_accuracy: 0.7470\n",
            "Epoch 8/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.7676 - accuracy: 0.7590 - val_loss: 0.6933 - val_accuracy: 0.7675\n",
            "Epoch 9/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.7179 - accuracy: 0.7869 - val_loss: 0.6533 - val_accuracy: 0.7658\n",
            "Epoch 10/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.7024 - accuracy: 0.7949 - val_loss: 0.6147 - val_accuracy: 0.7966\n",
            "Epoch 11/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.6394 - accuracy: 0.8131 - val_loss: 0.5786 - val_accuracy: 0.7983\n",
            "Epoch 12/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.6033 - accuracy: 0.8302 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
            "Epoch 13/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.5787 - accuracy: 0.8422 - val_loss: 0.5133 - val_accuracy: 0.8222\n",
            "Epoch 14/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.5674 - accuracy: 0.8484 - val_loss: 0.5083 - val_accuracy: 0.8222\n",
            "Epoch 15/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.5467 - accuracy: 0.8553 - val_loss: 0.4858 - val_accuracy: 0.8410\n",
            "Epoch 16/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.5084 - accuracy: 0.8610 - val_loss: 0.4673 - val_accuracy: 0.8547\n",
            "Epoch 17/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.4607 - accuracy: 0.8826 - val_loss: 0.4536 - val_accuracy: 0.8530\n",
            "Epoch 18/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.4783 - accuracy: 0.8843 - val_loss: 0.4269 - val_accuracy: 0.8684\n",
            "Epoch 19/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.4058 - accuracy: 0.8923 - val_loss: 0.4161 - val_accuracy: 0.8650\n",
            "Epoch 20/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.4065 - accuracy: 0.9077 - val_loss: 0.3948 - val_accuracy: 0.8855\n",
            "Epoch 21/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.3893 - accuracy: 0.8991 - val_loss: 0.3977 - val_accuracy: 0.8821\n",
            "Epoch 22/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.4104 - accuracy: 0.8974 - val_loss: 0.3883 - val_accuracy: 0.8786\n",
            "Epoch 23/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.4187 - accuracy: 0.8986 - val_loss: 0.3770 - val_accuracy: 0.8855\n",
            "Epoch 24/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.3729 - accuracy: 0.9031 - val_loss: 0.3935 - val_accuracy: 0.8701\n",
            "Epoch 25/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.3344 - accuracy: 0.9168 - val_loss: 0.3670 - val_accuracy: 0.8872\n",
            "Epoch 26/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.3169 - accuracy: 0.9179 - val_loss: 0.3731 - val_accuracy: 0.8701\n",
            "Epoch 27/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.3152 - accuracy: 0.9174 - val_loss: 0.3427 - val_accuracy: 0.8872\n",
            "Epoch 28/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.3040 - accuracy: 0.9265 - val_loss: 0.3435 - val_accuracy: 0.8855\n",
            "Epoch 29/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.2871 - accuracy: 0.9316 - val_loss: 0.3370 - val_accuracy: 0.8872\n",
            "Epoch 30/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.2701 - accuracy: 0.9333 - val_loss: 0.3252 - val_accuracy: 0.8940\n",
            "Epoch 31/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.2728 - accuracy: 0.9236 - val_loss: 0.3255 - val_accuracy: 0.8803\n",
            "Epoch 32/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.2571 - accuracy: 0.9430 - val_loss: 0.2976 - val_accuracy: 0.8974\n",
            "Epoch 33/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.2580 - accuracy: 0.9362 - val_loss: 0.3009 - val_accuracy: 0.8991\n",
            "Epoch 34/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.2754 - accuracy: 0.9299 - val_loss: 0.3052 - val_accuracy: 0.8957\n",
            "Epoch 35/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.2281 - accuracy: 0.9493 - val_loss: 0.2966 - val_accuracy: 0.8957\n",
            "Epoch 36/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.2292 - accuracy: 0.9487 - val_loss: 0.2953 - val_accuracy: 0.9026\n",
            "Epoch 37/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.2329 - accuracy: 0.9362 - val_loss: 0.3014 - val_accuracy: 0.8803\n",
            "Epoch 38/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.2017 - accuracy: 0.9504 - val_loss: 0.2781 - val_accuracy: 0.9077\n",
            "Epoch 39/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1941 - accuracy: 0.9493 - val_loss: 0.2699 - val_accuracy: 0.9111\n",
            "Epoch 40/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.1988 - accuracy: 0.9481 - val_loss: 0.2728 - val_accuracy: 0.9094\n",
            "Epoch 41/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1903 - accuracy: 0.9521 - val_loss: 0.2739 - val_accuracy: 0.9026\n",
            "Epoch 42/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1907 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.9111\n",
            "Epoch 43/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.1981 - accuracy: 0.9510 - val_loss: 0.2673 - val_accuracy: 0.9094\n",
            "Epoch 44/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.1706 - accuracy: 0.9533 - val_loss: 0.2681 - val_accuracy: 0.9094\n",
            "Epoch 45/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1742 - accuracy: 0.9601 - val_loss: 0.2616 - val_accuracy: 0.9128\n",
            "Epoch 46/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1678 - accuracy: 0.9567 - val_loss: 0.2622 - val_accuracy: 0.9094\n",
            "Epoch 47/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.1409 - accuracy: 0.9635 - val_loss: 0.2560 - val_accuracy: 0.9145\n",
            "Epoch 48/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1464 - accuracy: 0.9613 - val_loss: 0.2508 - val_accuracy: 0.9145\n",
            "Epoch 49/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1605 - accuracy: 0.9573 - val_loss: 0.2567 - val_accuracy: 0.9111\n",
            "Epoch 50/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.1403 - accuracy: 0.9624 - val_loss: 0.2437 - val_accuracy: 0.9197\n",
            "Epoch 51/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1414 - accuracy: 0.9630 - val_loss: 0.2440 - val_accuracy: 0.9111\n",
            "Epoch 52/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1326 - accuracy: 0.9630 - val_loss: 0.2422 - val_accuracy: 0.9077\n",
            "Epoch 53/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1267 - accuracy: 0.9664 - val_loss: 0.2501 - val_accuracy: 0.9111\n",
            "Epoch 54/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.1218 - accuracy: 0.9681 - val_loss: 0.2424 - val_accuracy: 0.9299\n",
            "Epoch 55/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1019 - accuracy: 0.9709 - val_loss: 0.2309 - val_accuracy: 0.9248\n",
            "Epoch 56/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1120 - accuracy: 0.9692 - val_loss: 0.2348 - val_accuracy: 0.9197\n",
            "Epoch 57/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1138 - accuracy: 0.9687 - val_loss: 0.2475 - val_accuracy: 0.9145\n",
            "Epoch 58/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0990 - accuracy: 0.9744 - val_loss: 0.2360 - val_accuracy: 0.9197\n",
            "Epoch 59/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1113 - accuracy: 0.9709 - val_loss: 0.2414 - val_accuracy: 0.9179\n",
            "Epoch 60/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.1111 - accuracy: 0.9687 - val_loss: 0.2464 - val_accuracy: 0.9162\n",
            "Epoch 61/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.1099 - accuracy: 0.9658 - val_loss: 0.2316 - val_accuracy: 0.9197\n",
            "Epoch 62/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0938 - accuracy: 0.9738 - val_loss: 0.2253 - val_accuracy: 0.9299\n",
            "Epoch 63/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0838 - accuracy: 0.9801 - val_loss: 0.2269 - val_accuracy: 0.9265\n",
            "Epoch 64/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0878 - accuracy: 0.9778 - val_loss: 0.2313 - val_accuracy: 0.9179\n",
            "Epoch 65/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.1033 - accuracy: 0.9704 - val_loss: 0.2120 - val_accuracy: 0.9333\n",
            "Epoch 66/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0955 - accuracy: 0.9681 - val_loss: 0.2099 - val_accuracy: 0.9282\n",
            "Epoch 67/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0977 - accuracy: 0.9698 - val_loss: 0.2096 - val_accuracy: 0.9333\n",
            "Epoch 68/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0993 - accuracy: 0.9721 - val_loss: 0.2262 - val_accuracy: 0.9248\n",
            "Epoch 69/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0775 - accuracy: 0.9818 - val_loss: 0.2121 - val_accuracy: 0.9299\n",
            "Epoch 70/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0886 - accuracy: 0.9715 - val_loss: 0.2055 - val_accuracy: 0.9299\n",
            "Epoch 71/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0869 - accuracy: 0.9721 - val_loss: 0.1988 - val_accuracy: 0.9333\n",
            "Epoch 72/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0728 - accuracy: 0.9789 - val_loss: 0.2008 - val_accuracy: 0.9316\n",
            "Epoch 73/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0683 - accuracy: 0.9829 - val_loss: 0.2001 - val_accuracy: 0.9350\n",
            "Epoch 74/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0879 - accuracy: 0.9755 - val_loss: 0.2115 - val_accuracy: 0.9402\n",
            "Epoch 75/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0770 - accuracy: 0.9789 - val_loss: 0.2115 - val_accuracy: 0.9419\n",
            "Epoch 76/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0616 - accuracy: 0.9852 - val_loss: 0.2133 - val_accuracy: 0.9368\n",
            "Epoch 77/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.2173 - val_accuracy: 0.9385\n",
            "Epoch 78/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0696 - accuracy: 0.9818 - val_loss: 0.2034 - val_accuracy: 0.9368\n",
            "Epoch 79/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0624 - accuracy: 0.9818 - val_loss: 0.2114 - val_accuracy: 0.9316\n",
            "Epoch 80/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0682 - accuracy: 0.9801 - val_loss: 0.2070 - val_accuracy: 0.9350\n",
            "Epoch 81/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0596 - accuracy: 0.9840 - val_loss: 0.1962 - val_accuracy: 0.9385\n",
            "Epoch 82/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0727 - accuracy: 0.9789 - val_loss: 0.1877 - val_accuracy: 0.9402\n",
            "Epoch 83/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0603 - accuracy: 0.9840 - val_loss: 0.2015 - val_accuracy: 0.9385\n",
            "Epoch 84/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.1984 - val_accuracy: 0.9385\n",
            "Epoch 85/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0601 - accuracy: 0.9823 - val_loss: 0.1862 - val_accuracy: 0.9385\n",
            "Epoch 86/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0581 - accuracy: 0.9823 - val_loss: 0.1930 - val_accuracy: 0.9333\n",
            "Epoch 87/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0444 - accuracy: 0.9892 - val_loss: 0.1809 - val_accuracy: 0.9368\n",
            "Epoch 88/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0498 - accuracy: 0.9875 - val_loss: 0.1940 - val_accuracy: 0.9333\n",
            "Epoch 89/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.1987 - val_accuracy: 0.9333\n",
            "Epoch 90/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0567 - accuracy: 0.9829 - val_loss: 0.2125 - val_accuracy: 0.9299\n",
            "Epoch 91/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 0.2280 - val_accuracy: 0.9231\n",
            "Epoch 92/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0585 - accuracy: 0.9858 - val_loss: 0.2188 - val_accuracy: 0.9316\n",
            "Epoch 93/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.2055 - val_accuracy: 0.9333\n",
            "Epoch 94/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0539 - accuracy: 0.9852 - val_loss: 0.2016 - val_accuracy: 0.9402\n",
            "Epoch 95/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 0.2006 - val_accuracy: 0.9265\n",
            "Epoch 96/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0386 - accuracy: 0.9915 - val_loss: 0.1844 - val_accuracy: 0.9436\n",
            "Epoch 97/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0560 - accuracy: 0.9840 - val_loss: 0.2139 - val_accuracy: 0.9299\n",
            "Epoch 98/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0460 - accuracy: 0.9886 - val_loss: 0.2058 - val_accuracy: 0.9350\n",
            "Epoch 99/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0405 - accuracy: 0.9886 - val_loss: 0.2035 - val_accuracy: 0.9385\n",
            "Epoch 100/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0498 - accuracy: 0.9858 - val_loss: 0.2124 - val_accuracy: 0.9333\n",
            "Epoch 101/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0402 - accuracy: 0.9903 - val_loss: 0.1962 - val_accuracy: 0.9402\n",
            "Epoch 102/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9892 - val_loss: 0.2001 - val_accuracy: 0.9368\n",
            "Epoch 103/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0463 - accuracy: 0.9892 - val_loss: 0.2032 - val_accuracy: 0.9402\n",
            "Epoch 104/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0392 - accuracy: 0.9892 - val_loss: 0.2107 - val_accuracy: 0.9419\n",
            "Epoch 105/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0475 - accuracy: 0.9875 - val_loss: 0.2194 - val_accuracy: 0.9350\n",
            "Epoch 106/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0416 - accuracy: 0.9880 - val_loss: 0.1989 - val_accuracy: 0.9436\n",
            "Epoch 107/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 0.2110 - val_accuracy: 0.9316\n",
            "Epoch 108/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.1974 - val_accuracy: 0.9453\n",
            "Epoch 109/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0445 - accuracy: 0.9869 - val_loss: 0.2086 - val_accuracy: 0.9385\n",
            "Epoch 110/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0567 - accuracy: 0.9840 - val_loss: 0.1990 - val_accuracy: 0.9436\n",
            "Epoch 111/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0375 - accuracy: 0.9903 - val_loss: 0.1984 - val_accuracy: 0.9368\n",
            "Epoch 112/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 0.1909 - val_accuracy: 0.9402\n",
            "Epoch 113/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0353 - accuracy: 0.9892 - val_loss: 0.1964 - val_accuracy: 0.9385\n",
            "Epoch 114/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0393 - accuracy: 0.9886 - val_loss: 0.2035 - val_accuracy: 0.9350\n",
            "Epoch 115/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.2029 - val_accuracy: 0.9385\n",
            "Epoch 116/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0378 - accuracy: 0.9852 - val_loss: 0.2143 - val_accuracy: 0.9316\n",
            "Epoch 117/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0358 - accuracy: 0.9909 - val_loss: 0.2089 - val_accuracy: 0.9368\n",
            "Epoch 118/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0390 - accuracy: 0.9880 - val_loss: 0.2164 - val_accuracy: 0.9333\n",
            "Epoch 119/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0394 - accuracy: 0.9869 - val_loss: 0.2130 - val_accuracy: 0.9299\n",
            "Epoch 120/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0415 - accuracy: 0.9886 - val_loss: 0.2187 - val_accuracy: 0.9316\n",
            "Epoch 121/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0591 - accuracy: 0.9818 - val_loss: 0.2033 - val_accuracy: 0.9368\n",
            "Epoch 122/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0501 - accuracy: 0.9852 - val_loss: 0.2003 - val_accuracy: 0.9368\n",
            "Epoch 123/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0386 - accuracy: 0.9880 - val_loss: 0.1923 - val_accuracy: 0.9436\n",
            "Epoch 124/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0403 - accuracy: 0.9880 - val_loss: 0.1954 - val_accuracy: 0.9419\n",
            "Epoch 125/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.2032 - val_accuracy: 0.9453\n",
            "Epoch 126/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0407 - accuracy: 0.9880 - val_loss: 0.2054 - val_accuracy: 0.9368\n",
            "Epoch 127/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0373 - accuracy: 0.9920 - val_loss: 0.2237 - val_accuracy: 0.9350\n",
            "Epoch 128/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.2004 - val_accuracy: 0.9402\n",
            "Epoch 129/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.2023 - val_accuracy: 0.9385\n",
            "Epoch 130/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0353 - accuracy: 0.9903 - val_loss: 0.1951 - val_accuracy: 0.9385\n",
            "Epoch 131/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0249 - accuracy: 0.9943 - val_loss: 0.2085 - val_accuracy: 0.9316\n",
            "Epoch 132/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.1901 - val_accuracy: 0.9436\n",
            "Epoch 133/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.2051 - val_accuracy: 0.9419\n",
            "Epoch 134/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0337 - accuracy: 0.9880 - val_loss: 0.2028 - val_accuracy: 0.9350\n",
            "Epoch 135/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0372 - accuracy: 0.9880 - val_loss: 0.1928 - val_accuracy: 0.9504\n",
            "Epoch 136/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.1832 - val_accuracy: 0.9436\n",
            "Epoch 137/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.2107 - val_accuracy: 0.9316\n",
            "Epoch 138/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.1974 - val_accuracy: 0.9350\n",
            "Epoch 139/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0376 - accuracy: 0.9897 - val_loss: 0.1915 - val_accuracy: 0.9385\n",
            "Epoch 140/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 0.2067 - val_accuracy: 0.9385\n",
            "Epoch 141/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.1755 - val_accuracy: 0.9470\n",
            "Epoch 142/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.1805 - val_accuracy: 0.9453\n",
            "Epoch 143/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.1809 - val_accuracy: 0.9436\n",
            "Epoch 144/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 0.1858 - val_accuracy: 0.9368\n",
            "Epoch 145/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0365 - accuracy: 0.9892 - val_loss: 0.1855 - val_accuracy: 0.9402\n",
            "Epoch 146/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.1953 - val_accuracy: 0.9436\n",
            "Epoch 147/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0331 - accuracy: 0.9880 - val_loss: 0.2036 - val_accuracy: 0.9333\n",
            "Epoch 148/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0439 - accuracy: 0.9886 - val_loss: 0.2073 - val_accuracy: 0.9385\n",
            "Epoch 149/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.2023 - val_accuracy: 0.9385\n",
            "Epoch 150/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.1894 - val_accuracy: 0.9470\n",
            "Epoch 151/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0288 - accuracy: 0.9920 - val_loss: 0.1837 - val_accuracy: 0.9453\n",
            "Epoch 152/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0226 - accuracy: 0.9943 - val_loss: 0.1663 - val_accuracy: 0.9487\n",
            "Epoch 153/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.1783 - val_accuracy: 0.9453\n",
            "Epoch 154/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.1776 - val_accuracy: 0.9453\n",
            "Epoch 155/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.1946 - val_accuracy: 0.9419\n",
            "Epoch 156/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0306 - accuracy: 0.9886 - val_loss: 0.1781 - val_accuracy: 0.9470\n",
            "Epoch 157/300\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.0241 - accuracy: 0.9966 - val_loss: 0.1815 - val_accuracy: 0.9402\n",
            "Epoch 158/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0168 - accuracy: 0.9966 - val_loss: 0.1788 - val_accuracy: 0.9419\n",
            "Epoch 159/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.1794 - val_accuracy: 0.9419\n",
            "Epoch 160/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.1783 - val_accuracy: 0.9436\n",
            "Epoch 161/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.1803 - val_accuracy: 0.9470\n",
            "Epoch 162/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0169 - accuracy: 0.9972 - val_loss: 0.1708 - val_accuracy: 0.9487\n",
            "Epoch 163/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.1768 - val_accuracy: 0.9453\n",
            "Epoch 164/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.2001 - val_accuracy: 0.9385\n",
            "Epoch 165/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.1993 - val_accuracy: 0.9453\n",
            "Epoch 166/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.1986 - val_accuracy: 0.9470\n",
            "Epoch 167/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 0.2133 - val_accuracy: 0.9385\n",
            "Epoch 168/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.1831 - val_accuracy: 0.9453\n",
            "Epoch 169/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.1881 - val_accuracy: 0.9419\n",
            "Epoch 170/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.1914 - val_accuracy: 0.9402\n",
            "Epoch 171/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.1945 - val_accuracy: 0.9419\n",
            "Epoch 172/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.1753 - val_accuracy: 0.9419\n",
            "Epoch 173/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.2000 - val_accuracy: 0.9453\n",
            "Epoch 174/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.1901 - val_accuracy: 0.9504\n",
            "Epoch 175/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.1938 - val_accuracy: 0.9487\n",
            "Epoch 176/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.2240 - val_accuracy: 0.9402\n",
            "Epoch 177/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.2105 - val_accuracy: 0.9419\n",
            "Epoch 178/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.2029 - val_accuracy: 0.9350\n",
            "Epoch 179/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.1923 - val_accuracy: 0.9470\n",
            "Epoch 180/300\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.1982 - val_accuracy: 0.9436\n",
            "Epoch 181/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.2064 - val_accuracy: 0.9385\n",
            "Epoch 182/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.1917 - val_accuracy: 0.9487\n",
            "Epoch 183/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.2003 - val_accuracy: 0.9419\n",
            "Epoch 184/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0233 - accuracy: 0.9943 - val_loss: 0.2313 - val_accuracy: 0.9350\n",
            "Epoch 185/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.2168 - val_accuracy: 0.9333\n",
            "Epoch 186/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.2012 - val_accuracy: 0.9402\n",
            "Epoch 187/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.1959 - val_accuracy: 0.9453\n",
            "Epoch 188/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0209 - accuracy: 0.9915 - val_loss: 0.1975 - val_accuracy: 0.9402\n",
            "Epoch 189/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 0.2016 - val_accuracy: 0.9470\n",
            "Epoch 190/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.2260 - val_accuracy: 0.9368\n",
            "Epoch 191/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.1928 - val_accuracy: 0.9504\n",
            "Epoch 192/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.1778 - val_accuracy: 0.9436\n",
            "Epoch 193/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.1758 - val_accuracy: 0.9436\n",
            "Epoch 194/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.1874 - val_accuracy: 0.9453\n",
            "Epoch 195/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.2018 - val_accuracy: 0.9453\n",
            "Epoch 196/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.2019 - val_accuracy: 0.9453\n",
            "Epoch 197/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.1794 - val_accuracy: 0.9470\n",
            "Epoch 198/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.1849 - val_accuracy: 0.9487\n",
            "Epoch 199/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0156 - accuracy: 0.9960 - val_loss: 0.1855 - val_accuracy: 0.9521\n",
            "Epoch 200/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.2051 - val_accuracy: 0.9470\n",
            "Epoch 201/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.2243 - val_accuracy: 0.9333\n",
            "Epoch 202/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.2217 - val_accuracy: 0.9436\n",
            "Epoch 203/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.1940 - val_accuracy: 0.9470\n",
            "Epoch 204/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.1843 - val_accuracy: 0.9538\n",
            "Epoch 205/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.2231 - val_accuracy: 0.9385\n",
            "Epoch 206/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.2080 - val_accuracy: 0.9368\n",
            "Epoch 207/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0176 - accuracy: 0.9966 - val_loss: 0.2169 - val_accuracy: 0.9368\n",
            "Epoch 208/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.2167 - val_accuracy: 0.9368\n",
            "Epoch 209/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.2213 - val_accuracy: 0.9419\n",
            "Epoch 210/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.2353 - val_accuracy: 0.9385\n",
            "Epoch 211/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.2593 - val_accuracy: 0.9316\n",
            "Epoch 212/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 0.2195 - val_accuracy: 0.9350\n",
            "Epoch 213/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.2292 - val_accuracy: 0.9453\n",
            "Epoch 214/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0147 - accuracy: 0.9977 - val_loss: 0.2261 - val_accuracy: 0.9385\n",
            "Epoch 215/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0308 - accuracy: 0.9892 - val_loss: 0.2106 - val_accuracy: 0.9368\n",
            "Epoch 216/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 0.2024 - val_accuracy: 0.9385\n",
            "Epoch 217/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.2038 - val_accuracy: 0.9436\n",
            "Epoch 218/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.1871 - val_accuracy: 0.9402\n",
            "Epoch 219/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.1842 - val_accuracy: 0.9521\n",
            "Epoch 220/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.2053 - val_accuracy: 0.9470\n",
            "Epoch 221/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.2023 - val_accuracy: 0.9436\n",
            "Epoch 222/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.2149 - val_accuracy: 0.9368\n",
            "Epoch 223/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.2080 - val_accuracy: 0.9385\n",
            "Epoch 224/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0230 - accuracy: 0.9949 - val_loss: 0.1951 - val_accuracy: 0.9487\n",
            "Epoch 225/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.1936 - val_accuracy: 0.9453\n",
            "Epoch 226/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.2204 - val_accuracy: 0.9368\n",
            "Epoch 227/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.2034 - val_accuracy: 0.9368\n",
            "Epoch 228/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.1837 - val_accuracy: 0.9504\n",
            "Epoch 229/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.1981 - val_accuracy: 0.9368\n",
            "Epoch 230/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.2044 - val_accuracy: 0.9419\n",
            "Epoch 231/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0160 - accuracy: 0.9926 - val_loss: 0.1728 - val_accuracy: 0.9487\n",
            "Epoch 232/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.1874 - val_accuracy: 0.9385\n",
            "Epoch 233/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0100 - accuracy: 0.9994 - val_loss: 0.1718 - val_accuracy: 0.9504\n",
            "Epoch 234/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.1915 - val_accuracy: 0.9385\n",
            "Epoch 235/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.1871 - val_accuracy: 0.9487\n",
            "Epoch 236/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.2080 - val_accuracy: 0.9487\n",
            "Epoch 237/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.2046 - val_accuracy: 0.9402\n",
            "Epoch 238/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.1943 - val_accuracy: 0.9385\n",
            "Epoch 239/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.1955 - val_accuracy: 0.9470\n",
            "Epoch 240/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0290 - accuracy: 0.9892 - val_loss: 0.2198 - val_accuracy: 0.9402\n",
            "Epoch 241/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.2254 - val_accuracy: 0.9350\n",
            "Epoch 242/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.2026 - val_accuracy: 0.9453\n",
            "Epoch 243/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.2076 - val_accuracy: 0.9419\n",
            "Epoch 244/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.2260 - val_accuracy: 0.9402\n",
            "Epoch 245/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.2060 - val_accuracy: 0.9368\n",
            "Epoch 246/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.2041 - val_accuracy: 0.9402\n",
            "Epoch 247/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0116 - accuracy: 0.9989 - val_loss: 0.2044 - val_accuracy: 0.9436\n",
            "Epoch 248/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.2092 - val_accuracy: 0.9385\n",
            "Epoch 249/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0287 - accuracy: 0.9937 - val_loss: 0.1999 - val_accuracy: 0.9436\n",
            "Epoch 250/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.2268 - val_accuracy: 0.9419\n",
            "Epoch 251/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.2140 - val_accuracy: 0.9350\n",
            "Epoch 252/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.1954 - val_accuracy: 0.9436\n",
            "Epoch 253/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.1983 - val_accuracy: 0.9419\n",
            "Epoch 254/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.1801 - val_accuracy: 0.9385\n",
            "Epoch 255/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.1667 - val_accuracy: 0.9419\n",
            "Epoch 256/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.1630 - val_accuracy: 0.9487\n",
            "Epoch 257/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.1816 - val_accuracy: 0.9419\n",
            "Epoch 258/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1770 - val_accuracy: 0.9419\n",
            "Epoch 259/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.1868 - val_accuracy: 0.9436\n",
            "Epoch 260/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.2181 - val_accuracy: 0.9265\n",
            "Epoch 261/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0202 - accuracy: 0.9915 - val_loss: 0.2083 - val_accuracy: 0.9350\n",
            "Epoch 262/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.1853 - val_accuracy: 0.9419\n",
            "Epoch 263/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.1829 - val_accuracy: 0.9436\n",
            "Epoch 264/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.1854 - val_accuracy: 0.9436\n",
            "Epoch 265/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.1787 - val_accuracy: 0.9470\n",
            "Epoch 266/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.2063 - val_accuracy: 0.9470\n",
            "Epoch 267/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.2355 - val_accuracy: 0.9385\n",
            "Epoch 268/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.1884 - val_accuracy: 0.9453\n",
            "Epoch 269/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.1816 - val_accuracy: 0.9470\n",
            "Epoch 270/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.1657 - val_accuracy: 0.9521\n",
            "Epoch 271/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1786 - val_accuracy: 0.9453\n",
            "Epoch 272/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.1880 - val_accuracy: 0.9419\n",
            "Epoch 273/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.2206 - val_accuracy: 0.9350\n",
            "Epoch 274/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.1776 - val_accuracy: 0.9453\n",
            "Epoch 275/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0206 - accuracy: 0.9920 - val_loss: 0.1990 - val_accuracy: 0.9521\n",
            "Epoch 276/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.2028 - val_accuracy: 0.9419\n",
            "Epoch 277/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.2057 - val_accuracy: 0.9487\n",
            "Epoch 278/300\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.2022 - val_accuracy: 0.9385\n",
            "Epoch 279/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.2355 - val_accuracy: 0.9385\n",
            "Epoch 280/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.1933 - val_accuracy: 0.9402\n",
            "Epoch 281/300\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.2146 - val_accuracy: 0.9316\n",
            "Epoch 282/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0114 - accuracy: 0.9954 - val_loss: 0.1904 - val_accuracy: 0.9487\n",
            "Epoch 283/300\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.2107 - val_accuracy: 0.9402\n",
            "Epoch 284/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.2067 - val_accuracy: 0.9487\n",
            "Epoch 285/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.2294 - val_accuracy: 0.9402\n",
            "Epoch 286/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.2143 - val_accuracy: 0.9436\n",
            "Epoch 287/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.2095 - val_accuracy: 0.9385\n",
            "Epoch 288/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.2338 - val_accuracy: 0.9333\n",
            "Epoch 289/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.2046 - val_accuracy: 0.9453\n",
            "Epoch 290/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.2145 - val_accuracy: 0.9419\n",
            "Epoch 291/300\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.2126 - val_accuracy: 0.9419\n",
            "Epoch 292/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.1985 - val_accuracy: 0.9504\n",
            "Epoch 293/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.2007 - val_accuracy: 0.9453\n",
            "Epoch 294/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.2147 - val_accuracy: 0.9385\n",
            "Epoch 295/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.2183 - val_accuracy: 0.9333\n",
            "Epoch 296/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.2335 - val_accuracy: 0.9350\n",
            "Epoch 297/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.2010 - val_accuracy: 0.9470\n",
            "Epoch 298/300\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.2526 - val_accuracy: 0.9333\n",
            "Epoch 299/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.2015 - val_accuracy: 0.9436\n",
            "Epoch 300/300\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.2398 - val_accuracy: 0.9402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ur8jfQoQRtLj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "139d7634-01ad-4c20-fd4e-8101b65be250"
      },
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size=0.25)\n",
        "X_train2 = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
        "X_test2 = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
        "input_shape = (X_train2.shape[1], X_train2.shape[2])\n",
        "model = Sequential()\n",
        "adam1 = Adam(learning_rate=0.0009)\n",
        "model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.25, return_sequences=True,input_shape=input_shape))\n",
        "model.add(LSTM(units=64,  dropout=0.05, recurrent_dropout=0.25, return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=10, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam1, metrics=[\"accuracy\"],)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_15 (LSTM)               (None, 1, 128)            79872     \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 1, 64)             49408     \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 129,930\n",
            "Trainable params: 129,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAY3gvg2IAYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64ce8b0d-42b3-4401-dca7-73a74893e229"
      },
      "source": [
        "batch_size = 35 # num of training examples per minibatch\n",
        "num_epochs =300\n",
        "classify2 = model.fit(\n",
        "    X_train2,\n",
        "    y_train2,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(X_test2,y_test2),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1125 samples, validate on 375 samples\n",
            "Epoch 1/300\n",
            "1125/1125 [==============================] - 1s 887us/step - loss: 2.2802 - accuracy: 0.2356 - val_loss: 2.2493 - val_accuracy: 0.3360\n",
            "Epoch 2/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 2.1964 - accuracy: 0.3671 - val_loss: 2.1444 - val_accuracy: 0.3360\n",
            "Epoch 3/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 2.0208 - accuracy: 0.3751 - val_loss: 1.9315 - val_accuracy: 0.3760\n",
            "Epoch 4/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 1.7543 - accuracy: 0.4267 - val_loss: 1.6811 - val_accuracy: 0.3547\n",
            "Epoch 5/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 1.5058 - accuracy: 0.4924 - val_loss: 1.4590 - val_accuracy: 0.4640\n",
            "Epoch 6/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 1.3049 - accuracy: 0.5716 - val_loss: 1.2620 - val_accuracy: 0.6000\n",
            "Epoch 7/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 1.1199 - accuracy: 0.6427 - val_loss: 1.0939 - val_accuracy: 0.6560\n",
            "Epoch 8/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.9528 - accuracy: 0.6907 - val_loss: 0.9438 - val_accuracy: 0.7040\n",
            "Epoch 9/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.8397 - accuracy: 0.7458 - val_loss: 0.8189 - val_accuracy: 0.7413\n",
            "Epoch 10/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.7414 - accuracy: 0.7680 - val_loss: 0.7280 - val_accuracy: 0.7760\n",
            "Epoch 11/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.6744 - accuracy: 0.8044 - val_loss: 0.6492 - val_accuracy: 0.8107\n",
            "Epoch 12/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.5874 - accuracy: 0.8187 - val_loss: 0.5853 - val_accuracy: 0.8293\n",
            "Epoch 13/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.5525 - accuracy: 0.8524 - val_loss: 0.5356 - val_accuracy: 0.8427\n",
            "Epoch 14/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.5228 - accuracy: 0.8551 - val_loss: 0.4970 - val_accuracy: 0.8560\n",
            "Epoch 15/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.4625 - accuracy: 0.8782 - val_loss: 0.4498 - val_accuracy: 0.8853\n",
            "Epoch 16/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.4416 - accuracy: 0.8844 - val_loss: 0.4129 - val_accuracy: 0.8907\n",
            "Epoch 17/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.4226 - accuracy: 0.8933 - val_loss: 0.3683 - val_accuracy: 0.9120\n",
            "Epoch 18/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.3615 - accuracy: 0.9093 - val_loss: 0.3533 - val_accuracy: 0.9307\n",
            "Epoch 19/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.3548 - accuracy: 0.9129 - val_loss: 0.3278 - val_accuracy: 0.9173\n",
            "Epoch 20/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.3371 - accuracy: 0.9244 - val_loss: 0.3020 - val_accuracy: 0.9280\n",
            "Epoch 21/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.3379 - accuracy: 0.9191 - val_loss: 0.2827 - val_accuracy: 0.9333\n",
            "Epoch 22/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.3219 - accuracy: 0.9244 - val_loss: 0.2640 - val_accuracy: 0.9360\n",
            "Epoch 23/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.2917 - accuracy: 0.9333 - val_loss: 0.2564 - val_accuracy: 0.9280\n",
            "Epoch 24/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.2759 - accuracy: 0.9369 - val_loss: 0.2434 - val_accuracy: 0.9440\n",
            "Epoch 25/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.2343 - accuracy: 0.9493 - val_loss: 0.2292 - val_accuracy: 0.9440\n",
            "Epoch 26/300\n",
            "1125/1125 [==============================] - 0s 276us/step - loss: 0.2514 - accuracy: 0.9458 - val_loss: 0.2227 - val_accuracy: 0.9467\n",
            "Epoch 27/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.2496 - accuracy: 0.9476 - val_loss: 0.2132 - val_accuracy: 0.9547\n",
            "Epoch 28/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.2521 - accuracy: 0.9440 - val_loss: 0.1978 - val_accuracy: 0.9627\n",
            "Epoch 29/300\n",
            "1125/1125 [==============================] - 0s 279us/step - loss: 0.2570 - accuracy: 0.9324 - val_loss: 0.1882 - val_accuracy: 0.9547\n",
            "Epoch 30/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.1966 - accuracy: 0.9547 - val_loss: 0.1848 - val_accuracy: 0.9573\n",
            "Epoch 31/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.2173 - accuracy: 0.9502 - val_loss: 0.1819 - val_accuracy: 0.9547\n",
            "Epoch 32/300\n",
            "1125/1125 [==============================] - 0s 290us/step - loss: 0.2322 - accuracy: 0.9449 - val_loss: 0.1799 - val_accuracy: 0.9600\n",
            "Epoch 33/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.2191 - accuracy: 0.9440 - val_loss: 0.1694 - val_accuracy: 0.9627\n",
            "Epoch 34/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.2313 - accuracy: 0.9378 - val_loss: 0.1715 - val_accuracy: 0.9573\n",
            "Epoch 35/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.1832 - accuracy: 0.9520 - val_loss: 0.1671 - val_accuracy: 0.9547\n",
            "Epoch 36/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.1857 - accuracy: 0.9618 - val_loss: 0.1599 - val_accuracy: 0.9653\n",
            "Epoch 37/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.1694 - accuracy: 0.9564 - val_loss: 0.1570 - val_accuracy: 0.9653\n",
            "Epoch 38/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.2107 - accuracy: 0.9502 - val_loss: 0.1658 - val_accuracy: 0.9600\n",
            "Epoch 39/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.1793 - accuracy: 0.9556 - val_loss: 0.1535 - val_accuracy: 0.9680\n",
            "Epoch 40/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.1690 - accuracy: 0.9627 - val_loss: 0.1458 - val_accuracy: 0.9680\n",
            "Epoch 41/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.1510 - accuracy: 0.9662 - val_loss: 0.1436 - val_accuracy: 0.9707\n",
            "Epoch 42/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.1572 - accuracy: 0.9671 - val_loss: 0.1449 - val_accuracy: 0.9680\n",
            "Epoch 43/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.1378 - accuracy: 0.9644 - val_loss: 0.1396 - val_accuracy: 0.9733\n",
            "Epoch 44/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.1533 - accuracy: 0.9600 - val_loss: 0.1353 - val_accuracy: 0.9680\n",
            "Epoch 45/300\n",
            "1125/1125 [==============================] - 0s 290us/step - loss: 0.1420 - accuracy: 0.9662 - val_loss: 0.1281 - val_accuracy: 0.9653\n",
            "Epoch 46/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.1281 - accuracy: 0.9671 - val_loss: 0.1211 - val_accuracy: 0.9707\n",
            "Epoch 47/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.1381 - accuracy: 0.9644 - val_loss: 0.1250 - val_accuracy: 0.9680\n",
            "Epoch 48/300\n",
            "1125/1125 [==============================] - 0s 290us/step - loss: 0.1290 - accuracy: 0.9707 - val_loss: 0.1212 - val_accuracy: 0.9707\n",
            "Epoch 49/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.1683 - accuracy: 0.9529 - val_loss: 0.1254 - val_accuracy: 0.9627\n",
            "Epoch 50/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.1226 - accuracy: 0.9724 - val_loss: 0.1198 - val_accuracy: 0.9707\n",
            "Epoch 51/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.1360 - accuracy: 0.9644 - val_loss: 0.1309 - val_accuracy: 0.9520\n",
            "Epoch 52/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.1256 - accuracy: 0.9671 - val_loss: 0.1089 - val_accuracy: 0.9680\n",
            "Epoch 53/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.1211 - accuracy: 0.9671 - val_loss: 0.1146 - val_accuracy: 0.9707\n",
            "Epoch 54/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.1129 - accuracy: 0.9724 - val_loss: 0.1165 - val_accuracy: 0.9760\n",
            "Epoch 55/300\n",
            "1125/1125 [==============================] - 0s 274us/step - loss: 0.1171 - accuracy: 0.9671 - val_loss: 0.1014 - val_accuracy: 0.9760\n",
            "Epoch 56/300\n",
            "1125/1125 [==============================] - 0s 274us/step - loss: 0.1148 - accuracy: 0.9716 - val_loss: 0.0993 - val_accuracy: 0.9733\n",
            "Epoch 57/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.1007 - accuracy: 0.9760 - val_loss: 0.0968 - val_accuracy: 0.9760\n",
            "Epoch 58/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.1188 - accuracy: 0.9662 - val_loss: 0.1058 - val_accuracy: 0.9627\n",
            "Epoch 59/300\n",
            "1125/1125 [==============================] - 0s 290us/step - loss: 0.0967 - accuracy: 0.9733 - val_loss: 0.1083 - val_accuracy: 0.9627\n",
            "Epoch 60/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0980 - accuracy: 0.9724 - val_loss: 0.1067 - val_accuracy: 0.9653\n",
            "Epoch 61/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.1139 - accuracy: 0.9698 - val_loss: 0.1075 - val_accuracy: 0.9653\n",
            "Epoch 62/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.1276 - accuracy: 0.9680 - val_loss: 0.1237 - val_accuracy: 0.9600\n",
            "Epoch 63/300\n",
            "1125/1125 [==============================] - 0s 277us/step - loss: 0.0939 - accuracy: 0.9742 - val_loss: 0.1105 - val_accuracy: 0.9680\n",
            "Epoch 64/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0998 - accuracy: 0.9680 - val_loss: 0.1086 - val_accuracy: 0.9707\n",
            "Epoch 65/300\n",
            "1125/1125 [==============================] - 0s 300us/step - loss: 0.1041 - accuracy: 0.9733 - val_loss: 0.1180 - val_accuracy: 0.9653\n",
            "Epoch 66/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.0950 - accuracy: 0.9698 - val_loss: 0.0994 - val_accuracy: 0.9760\n",
            "Epoch 67/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0958 - accuracy: 0.9716 - val_loss: 0.0937 - val_accuracy: 0.9760\n",
            "Epoch 68/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0905 - accuracy: 0.9733 - val_loss: 0.0968 - val_accuracy: 0.9707\n",
            "Epoch 69/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.1059 - accuracy: 0.9733 - val_loss: 0.0937 - val_accuracy: 0.9813\n",
            "Epoch 70/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0679 - accuracy: 0.9813 - val_loss: 0.0915 - val_accuracy: 0.9733\n",
            "Epoch 71/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.1109 - accuracy: 0.9698 - val_loss: 0.0912 - val_accuracy: 0.9813\n",
            "Epoch 72/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0642 - accuracy: 0.9858 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "Epoch 73/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0721 - accuracy: 0.9822 - val_loss: 0.0925 - val_accuracy: 0.9813\n",
            "Epoch 74/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.0808 - accuracy: 0.9769 - val_loss: 0.0838 - val_accuracy: 0.9787\n",
            "Epoch 75/300\n",
            "1125/1125 [==============================] - 0s 279us/step - loss: 0.0862 - accuracy: 0.9760 - val_loss: 0.0869 - val_accuracy: 0.9707\n",
            "Epoch 76/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0817 - accuracy: 0.9796 - val_loss: 0.0837 - val_accuracy: 0.9760\n",
            "Epoch 77/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0874 - accuracy: 0.9787 - val_loss: 0.0918 - val_accuracy: 0.9680\n",
            "Epoch 78/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0768 - accuracy: 0.9796 - val_loss: 0.0740 - val_accuracy: 0.9867\n",
            "Epoch 79/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0895 - accuracy: 0.9733 - val_loss: 0.0780 - val_accuracy: 0.9813\n",
            "Epoch 80/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0647 - accuracy: 0.9822 - val_loss: 0.0865 - val_accuracy: 0.9733\n",
            "Epoch 81/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0702 - accuracy: 0.9804 - val_loss: 0.0869 - val_accuracy: 0.9733\n",
            "Epoch 82/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0669 - accuracy: 0.9813 - val_loss: 0.0865 - val_accuracy: 0.9680\n",
            "Epoch 83/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0673 - accuracy: 0.9804 - val_loss: 0.0794 - val_accuracy: 0.9787\n",
            "Epoch 84/300\n",
            "1125/1125 [==============================] - 0s 279us/step - loss: 0.0604 - accuracy: 0.9840 - val_loss: 0.0880 - val_accuracy: 0.9707\n",
            "Epoch 85/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0592 - accuracy: 0.9840 - val_loss: 0.0821 - val_accuracy: 0.9680\n",
            "Epoch 86/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0671 - accuracy: 0.9796 - val_loss: 0.0752 - val_accuracy: 0.9787\n",
            "Epoch 87/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0746 - accuracy: 0.9796 - val_loss: 0.0903 - val_accuracy: 0.9707\n",
            "Epoch 88/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.0839 - accuracy: 0.9751 - val_loss: 0.0805 - val_accuracy: 0.9733\n",
            "Epoch 89/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.0840 - accuracy: 0.9760 - val_loss: 0.0908 - val_accuracy: 0.9760\n",
            "Epoch 90/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0951 - accuracy: 0.9733 - val_loss: 0.0912 - val_accuracy: 0.9787\n",
            "Epoch 91/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.0798 - accuracy: 0.9724 - val_loss: 0.0814 - val_accuracy: 0.9733\n",
            "Epoch 92/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0581 - accuracy: 0.9813 - val_loss: 0.0770 - val_accuracy: 0.9707\n",
            "Epoch 93/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0646 - accuracy: 0.9831 - val_loss: 0.0790 - val_accuracy: 0.9733\n",
            "Epoch 94/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0512 - accuracy: 0.9893 - val_loss: 0.0829 - val_accuracy: 0.9707\n",
            "Epoch 95/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0730 - accuracy: 0.9840 - val_loss: 0.0778 - val_accuracy: 0.9787\n",
            "Epoch 96/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0539 - accuracy: 0.9840 - val_loss: 0.0810 - val_accuracy: 0.9760\n",
            "Epoch 97/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0555 - accuracy: 0.9831 - val_loss: 0.0775 - val_accuracy: 0.9733\n",
            "Epoch 98/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.0514 - accuracy: 0.9902 - val_loss: 0.0709 - val_accuracy: 0.9787\n",
            "Epoch 99/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0565 - accuracy: 0.9840 - val_loss: 0.0740 - val_accuracy: 0.9733\n",
            "Epoch 100/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0595 - accuracy: 0.9813 - val_loss: 0.0749 - val_accuracy: 0.9760\n",
            "Epoch 101/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0633 - accuracy: 0.9840 - val_loss: 0.0765 - val_accuracy: 0.9680\n",
            "Epoch 102/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0612 - accuracy: 0.9822 - val_loss: 0.0745 - val_accuracy: 0.9760\n",
            "Epoch 103/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.0803 - accuracy: 0.9769 - val_loss: 0.0914 - val_accuracy: 0.9653\n",
            "Epoch 104/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.0458 - accuracy: 0.9902 - val_loss: 0.0697 - val_accuracy: 0.9787\n",
            "Epoch 105/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0536 - accuracy: 0.9840 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
            "Epoch 106/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0647 - accuracy: 0.9813 - val_loss: 0.0742 - val_accuracy: 0.9733\n",
            "Epoch 107/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 0.0623 - val_accuracy: 0.9760\n",
            "Epoch 108/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0528 - accuracy: 0.9840 - val_loss: 0.0794 - val_accuracy: 0.9787\n",
            "Epoch 109/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.0642 - accuracy: 0.9778 - val_loss: 0.0849 - val_accuracy: 0.9787\n",
            "Epoch 110/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0607 - accuracy: 0.9840 - val_loss: 0.0898 - val_accuracy: 0.9707\n",
            "Epoch 111/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0481 - accuracy: 0.9822 - val_loss: 0.0884 - val_accuracy: 0.9733\n",
            "Epoch 112/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0679 - accuracy: 0.9769 - val_loss: 0.0948 - val_accuracy: 0.9653\n",
            "Epoch 113/300\n",
            "1125/1125 [==============================] - 0s 277us/step - loss: 0.0642 - accuracy: 0.9804 - val_loss: 0.0856 - val_accuracy: 0.9600\n",
            "Epoch 114/300\n",
            "1125/1125 [==============================] - 0s 274us/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 0.0780 - val_accuracy: 0.9760\n",
            "Epoch 115/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0617 - accuracy: 0.9804 - val_loss: 0.0821 - val_accuracy: 0.9787\n",
            "Epoch 116/300\n",
            "1125/1125 [==============================] - 0s 271us/step - loss: 0.0430 - accuracy: 0.9902 - val_loss: 0.0643 - val_accuracy: 0.9760\n",
            "Epoch 117/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0375 - accuracy: 0.9920 - val_loss: 0.0720 - val_accuracy: 0.9733\n",
            "Epoch 118/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.0835 - val_accuracy: 0.9733\n",
            "Epoch 119/300\n",
            "1125/1125 [==============================] - 0s 278us/step - loss: 0.0423 - accuracy: 0.9849 - val_loss: 0.0774 - val_accuracy: 0.9813\n",
            "Epoch 120/300\n",
            "1125/1125 [==============================] - 0s 273us/step - loss: 0.0449 - accuracy: 0.9902 - val_loss: 0.0775 - val_accuracy: 0.9760\n",
            "Epoch 121/300\n",
            "1125/1125 [==============================] - 0s 263us/step - loss: 0.0446 - accuracy: 0.9831 - val_loss: 0.0737 - val_accuracy: 0.9787\n",
            "Epoch 122/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0298 - accuracy: 0.9956 - val_loss: 0.0658 - val_accuracy: 0.9787\n",
            "Epoch 123/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0496 - accuracy: 0.9876 - val_loss: 0.0723 - val_accuracy: 0.9813\n",
            "Epoch 124/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.0602 - val_accuracy: 0.9813\n",
            "Epoch 125/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0500 - val_accuracy: 0.9893\n",
            "Epoch 126/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.0452 - accuracy: 0.9884 - val_loss: 0.0603 - val_accuracy: 0.9867\n",
            "Epoch 127/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0322 - accuracy: 0.9911 - val_loss: 0.0636 - val_accuracy: 0.9893\n",
            "Epoch 128/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0345 - accuracy: 0.9929 - val_loss: 0.0638 - val_accuracy: 0.9787\n",
            "Epoch 129/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0401 - accuracy: 0.9902 - val_loss: 0.0593 - val_accuracy: 0.9813\n",
            "Epoch 130/300\n",
            "1125/1125 [==============================] - 0s 278us/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.0644 - val_accuracy: 0.9813\n",
            "Epoch 131/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 0.0754 - val_accuracy: 0.9760\n",
            "Epoch 132/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0629 - accuracy: 0.9796 - val_loss: 0.0533 - val_accuracy: 0.9867\n",
            "Epoch 133/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0416 - accuracy: 0.9867 - val_loss: 0.0603 - val_accuracy: 0.9813\n",
            "Epoch 134/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.0686 - val_accuracy: 0.9813\n",
            "Epoch 135/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0365 - accuracy: 0.9911 - val_loss: 0.0616 - val_accuracy: 0.9760\n",
            "Epoch 136/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
            "Epoch 137/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 0.0587 - val_accuracy: 0.9813\n",
            "Epoch 138/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.0522 - accuracy: 0.9876 - val_loss: 0.0640 - val_accuracy: 0.9840\n",
            "Epoch 139/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0409 - accuracy: 0.9893 - val_loss: 0.0540 - val_accuracy: 0.9893\n",
            "Epoch 140/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0542 - accuracy: 0.9840 - val_loss: 0.0770 - val_accuracy: 0.9787\n",
            "Epoch 141/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0453 - accuracy: 0.9840 - val_loss: 0.0694 - val_accuracy: 0.9787\n",
            "Epoch 142/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0376 - accuracy: 0.9876 - val_loss: 0.0523 - val_accuracy: 0.9867\n",
            "Epoch 143/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 144/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.0700 - val_accuracy: 0.9733\n",
            "Epoch 145/300\n",
            "1125/1125 [==============================] - 0s 277us/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.9733\n",
            "Epoch 146/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0448 - accuracy: 0.9884 - val_loss: 0.0617 - val_accuracy: 0.9760\n",
            "Epoch 147/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0471 - accuracy: 0.9858 - val_loss: 0.0692 - val_accuracy: 0.9707\n",
            "Epoch 148/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0521 - accuracy: 0.9858 - val_loss: 0.0700 - val_accuracy: 0.9760\n",
            "Epoch 149/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0637 - val_accuracy: 0.9813\n",
            "Epoch 150/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0343 - accuracy: 0.9902 - val_loss: 0.0719 - val_accuracy: 0.9707\n",
            "Epoch 151/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.0595 - val_accuracy: 0.9867\n",
            "Epoch 152/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0449 - accuracy: 0.9884 - val_loss: 0.0605 - val_accuracy: 0.9840\n",
            "Epoch 153/300\n",
            "1125/1125 [==============================] - 0s 290us/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.0590 - val_accuracy: 0.9813\n",
            "Epoch 154/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.0708 - val_accuracy: 0.9760\n",
            "Epoch 155/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.0651 - val_accuracy: 0.9733\n",
            "Epoch 156/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0264 - accuracy: 0.9956 - val_loss: 0.0720 - val_accuracy: 0.9733\n",
            "Epoch 157/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: 0.0708 - val_accuracy: 0.9760\n",
            "Epoch 158/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0439 - accuracy: 0.9884 - val_loss: 0.0711 - val_accuracy: 0.9760\n",
            "Epoch 159/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0651 - val_accuracy: 0.9813\n",
            "Epoch 160/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0579 - accuracy: 0.9787 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
            "Epoch 161/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.0685 - val_accuracy: 0.9733\n",
            "Epoch 162/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.0656 - val_accuracy: 0.9813\n",
            "Epoch 163/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0252 - accuracy: 0.9947 - val_loss: 0.0661 - val_accuracy: 0.9760\n",
            "Epoch 164/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 0.0653 - val_accuracy: 0.9760\n",
            "Epoch 165/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0462 - accuracy: 0.9876 - val_loss: 0.0636 - val_accuracy: 0.9813\n",
            "Epoch 166/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0718 - val_accuracy: 0.9787\n",
            "Epoch 167/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0419 - accuracy: 0.9884 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 168/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0517 - accuracy: 0.9876 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
            "Epoch 169/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0640 - val_accuracy: 0.9760\n",
            "Epoch 170/300\n",
            "1125/1125 [==============================] - 0s 290us/step - loss: 0.0380 - accuracy: 0.9911 - val_loss: 0.0558 - val_accuracy: 0.9813\n",
            "Epoch 171/300\n",
            "1125/1125 [==============================] - 0s 278us/step - loss: 0.0327 - accuracy: 0.9920 - val_loss: 0.0565 - val_accuracy: 0.9813\n",
            "Epoch 172/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 0.0570 - val_accuracy: 0.9787\n",
            "Epoch 173/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
            "Epoch 174/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0265 - accuracy: 0.9929 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
            "Epoch 175/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0605 - val_accuracy: 0.9813\n",
            "Epoch 176/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0301 - accuracy: 0.9929 - val_loss: 0.0485 - val_accuracy: 0.9867\n",
            "Epoch 177/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.0388 - accuracy: 0.9893 - val_loss: 0.0491 - val_accuracy: 0.9840\n",
            "Epoch 178/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.0332 - accuracy: 0.9920 - val_loss: 0.0614 - val_accuracy: 0.9813\n",
            "Epoch 179/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.0800 - val_accuracy: 0.9787\n",
            "Epoch 180/300\n",
            "1125/1125 [==============================] - 0s 278us/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0586 - val_accuracy: 0.9760\n",
            "Epoch 181/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 0.0550 - val_accuracy: 0.9813\n",
            "Epoch 182/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.0785 - val_accuracy: 0.9760\n",
            "Epoch 183/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.0594 - val_accuracy: 0.9787\n",
            "Epoch 184/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0257 - accuracy: 0.9938 - val_loss: 0.0619 - val_accuracy: 0.9760\n",
            "Epoch 185/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.0302 - accuracy: 0.9876 - val_loss: 0.0682 - val_accuracy: 0.9733\n",
            "Epoch 186/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0189 - accuracy: 0.9973 - val_loss: 0.0562 - val_accuracy: 0.9813\n",
            "Epoch 187/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0256 - accuracy: 0.9947 - val_loss: 0.0661 - val_accuracy: 0.9760\n",
            "Epoch 188/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.0626 - val_accuracy: 0.9760\n",
            "Epoch 189/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0265 - accuracy: 0.9884 - val_loss: 0.0838 - val_accuracy: 0.9733\n",
            "Epoch 190/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0553 - val_accuracy: 0.9813\n",
            "Epoch 191/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 0.0724 - val_accuracy: 0.9733\n",
            "Epoch 192/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0194 - accuracy: 0.9964 - val_loss: 0.0830 - val_accuracy: 0.9707\n",
            "Epoch 193/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0223 - accuracy: 0.9911 - val_loss: 0.0684 - val_accuracy: 0.9813\n",
            "Epoch 194/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.0777 - val_accuracy: 0.9760\n",
            "Epoch 195/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0303 - accuracy: 0.9867 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 196/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
            "Epoch 197/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0274 - accuracy: 0.9893 - val_loss: 0.0577 - val_accuracy: 0.9813\n",
            "Epoch 198/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0340 - accuracy: 0.9876 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 199/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0426 - accuracy: 0.9876 - val_loss: 0.0719 - val_accuracy: 0.9733\n",
            "Epoch 200/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.0724 - val_accuracy: 0.9760\n",
            "Epoch 201/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0288 - accuracy: 0.9929 - val_loss: 0.0870 - val_accuracy: 0.9813\n",
            "Epoch 202/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0523 - val_accuracy: 0.9867\n",
            "Epoch 203/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0262 - accuracy: 0.9938 - val_loss: 0.0563 - val_accuracy: 0.9840\n",
            "Epoch 204/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0289 - accuracy: 0.9938 - val_loss: 0.0574 - val_accuracy: 0.9813\n",
            "Epoch 205/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.0657 - val_accuracy: 0.9867\n",
            "Epoch 206/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0180 - accuracy: 0.9973 - val_loss: 0.0687 - val_accuracy: 0.9813\n",
            "Epoch 207/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0588 - val_accuracy: 0.9760\n",
            "Epoch 208/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.0491 - val_accuracy: 0.9840\n",
            "Epoch 209/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0520 - val_accuracy: 0.9840\n",
            "Epoch 210/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0255 - accuracy: 0.9893 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
            "Epoch 211/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.0635 - val_accuracy: 0.9840\n",
            "Epoch 212/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 0.0579 - val_accuracy: 0.9867\n",
            "Epoch 213/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0565 - val_accuracy: 0.9867\n",
            "Epoch 214/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0177 - accuracy: 0.9920 - val_loss: 0.0450 - val_accuracy: 0.9840\n",
            "Epoch 215/300\n",
            "1125/1125 [==============================] - 0s 291us/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 0.0557 - val_accuracy: 0.9787\n",
            "Epoch 216/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0194 - accuracy: 0.9964 - val_loss: 0.0557 - val_accuracy: 0.9840\n",
            "Epoch 217/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0569 - val_accuracy: 0.9867\n",
            "Epoch 218/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.0511 - val_accuracy: 0.9867\n",
            "Epoch 219/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 0.0493 - val_accuracy: 0.9893\n",
            "Epoch 220/300\n",
            "1125/1125 [==============================] - 0s 277us/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0589 - val_accuracy: 0.9760\n",
            "Epoch 221/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0333 - accuracy: 0.9876 - val_loss: 0.0714 - val_accuracy: 0.9813\n",
            "Epoch 222/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 0.0624 - val_accuracy: 0.9813\n",
            "Epoch 223/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.0734 - val_accuracy: 0.9787\n",
            "Epoch 224/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0794 - val_accuracy: 0.9733\n",
            "Epoch 225/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0320 - accuracy: 0.9876 - val_loss: 0.0759 - val_accuracy: 0.9760\n",
            "Epoch 226/300\n",
            "1125/1125 [==============================] - 0s 289us/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0599 - val_accuracy: 0.9813\n",
            "Epoch 227/300\n",
            "1125/1125 [==============================] - 0s 293us/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.0690 - val_accuracy: 0.9707\n",
            "Epoch 228/300\n",
            "1125/1125 [==============================] - 0s 278us/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.0790 - val_accuracy: 0.9733\n",
            "Epoch 229/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.0208 - accuracy: 0.9956 - val_loss: 0.0872 - val_accuracy: 0.9653\n",
            "Epoch 230/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.0262 - accuracy: 0.9929 - val_loss: 0.0843 - val_accuracy: 0.9707\n",
            "Epoch 231/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0335 - accuracy: 0.9867 - val_loss: 0.0844 - val_accuracy: 0.9680\n",
            "Epoch 232/300\n",
            "1125/1125 [==============================] - 0s 285us/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.0775 - val_accuracy: 0.9653\n",
            "Epoch 233/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.0186 - accuracy: 0.9956 - val_loss: 0.0868 - val_accuracy: 0.9627\n",
            "Epoch 234/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0897 - val_accuracy: 0.9653\n",
            "Epoch 235/300\n",
            "1125/1125 [==============================] - 0s 272us/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.0540 - val_accuracy: 0.9840\n",
            "Epoch 236/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0595 - val_accuracy: 0.9707\n",
            "Epoch 237/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 0.0619 - val_accuracy: 0.9733\n",
            "Epoch 238/300\n",
            "1125/1125 [==============================] - 0s 276us/step - loss: 0.0245 - accuracy: 0.9902 - val_loss: 0.0603 - val_accuracy: 0.9813\n",
            "Epoch 239/300\n",
            "1125/1125 [==============================] - 0s 272us/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.0561 - val_accuracy: 0.9787\n",
            "Epoch 240/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0333 - accuracy: 0.9920 - val_loss: 0.0602 - val_accuracy: 0.9787\n",
            "Epoch 241/300\n",
            "1125/1125 [==============================] - 0s 269us/step - loss: 0.0370 - accuracy: 0.9911 - val_loss: 0.0625 - val_accuracy: 0.9760\n",
            "Epoch 242/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0552 - val_accuracy: 0.9733\n",
            "Epoch 243/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.0445 - val_accuracy: 0.9840\n",
            "Epoch 244/300\n",
            "1125/1125 [==============================] - 0s 276us/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0485 - val_accuracy: 0.9867\n",
            "Epoch 245/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0277 - accuracy: 0.9938 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
            "Epoch 246/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
            "Epoch 247/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0214 - accuracy: 0.9956 - val_loss: 0.1011 - val_accuracy: 0.9680\n",
            "Epoch 248/300\n",
            "1125/1125 [==============================] - 0s 269us/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0965 - val_accuracy: 0.9760\n",
            "Epoch 249/300\n",
            "1125/1125 [==============================] - 0s 271us/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.0714 - val_accuracy: 0.9813\n",
            "Epoch 250/300\n",
            "1125/1125 [==============================] - 0s 276us/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
            "Epoch 251/300\n",
            "1125/1125 [==============================] - 0s 272us/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.0703 - val_accuracy: 0.9760\n",
            "Epoch 252/300\n",
            "1125/1125 [==============================] - 0s 271us/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 0.0639 - val_accuracy: 0.9707\n",
            "Epoch 253/300\n",
            "1125/1125 [==============================] - 0s 278us/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0603 - val_accuracy: 0.9707\n",
            "Epoch 254/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0546 - val_accuracy: 0.9707\n",
            "Epoch 255/300\n",
            "1125/1125 [==============================] - 0s 272us/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.0455 - val_accuracy: 0.9840\n",
            "Epoch 256/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.0450 - val_accuracy: 0.9813\n",
            "Epoch 257/300\n",
            "1125/1125 [==============================] - 0s 265us/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0520 - val_accuracy: 0.9840\n",
            "Epoch 258/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0252 - accuracy: 0.9938 - val_loss: 0.0689 - val_accuracy: 0.9733\n",
            "Epoch 259/300\n",
            "1125/1125 [==============================] - 0s 274us/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0631 - val_accuracy: 0.9787\n",
            "Epoch 260/300\n",
            "1125/1125 [==============================] - 0s 269us/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.0570 - val_accuracy: 0.9760\n",
            "Epoch 261/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0262 - accuracy: 0.9876 - val_loss: 0.0818 - val_accuracy: 0.9653\n",
            "Epoch 262/300\n",
            "1125/1125 [==============================] - 0s 269us/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0659 - val_accuracy: 0.9653\n",
            "Epoch 263/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0563 - val_accuracy: 0.9760\n",
            "Epoch 264/300\n",
            "1125/1125 [==============================] - 0s 270us/step - loss: 0.0247 - accuracy: 0.9929 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 265/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.0787 - val_accuracy: 0.9707\n",
            "Epoch 266/300\n",
            "1125/1125 [==============================] - 0s 274us/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0732 - val_accuracy: 0.9733\n",
            "Epoch 267/300\n",
            "1125/1125 [==============================] - 0s 266us/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0611 - val_accuracy: 0.9787\n",
            "Epoch 268/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.0765 - val_accuracy: 0.9680\n",
            "Epoch 269/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 0.0755 - val_accuracy: 0.9680\n",
            "Epoch 270/300\n",
            "1125/1125 [==============================] - 0s 273us/step - loss: 0.0296 - accuracy: 0.9938 - val_loss: 0.0601 - val_accuracy: 0.9707\n",
            "Epoch 271/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0234 - accuracy: 0.9947 - val_loss: 0.0482 - val_accuracy: 0.9840\n",
            "Epoch 272/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.0496 - val_accuracy: 0.9813\n",
            "Epoch 273/300\n",
            "1125/1125 [==============================] - 0s 279us/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.0513 - val_accuracy: 0.9813\n",
            "Epoch 274/300\n",
            "1125/1125 [==============================] - 0s 273us/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.0436 - val_accuracy: 0.9840\n",
            "Epoch 275/300\n",
            "1125/1125 [==============================] - 0s 288us/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.0389 - val_accuracy: 0.9867\n",
            "Epoch 276/300\n",
            "1125/1125 [==============================] - 0s 274us/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.0402 - val_accuracy: 0.9867\n",
            "Epoch 277/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0452 - val_accuracy: 0.9920\n",
            "Epoch 278/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0500 - val_accuracy: 0.9867\n",
            "Epoch 279/300\n",
            "1125/1125 [==============================] - 0s 273us/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0514 - val_accuracy: 0.9813\n",
            "Epoch 280/300\n",
            "1125/1125 [==============================] - 0s 280us/step - loss: 0.0195 - accuracy: 0.9911 - val_loss: 0.0561 - val_accuracy: 0.9733\n",
            "Epoch 281/300\n",
            "1125/1125 [==============================] - 0s 283us/step - loss: 0.0277 - accuracy: 0.9867 - val_loss: 0.0554 - val_accuracy: 0.9733\n",
            "Epoch 282/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.0582 - val_accuracy: 0.9733\n",
            "Epoch 283/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 0.0574 - val_accuracy: 0.9707\n",
            "Epoch 284/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 0.0535 - val_accuracy: 0.9760\n",
            "Epoch 285/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.0604 - val_accuracy: 0.9733\n",
            "Epoch 286/300\n",
            "1125/1125 [==============================] - 0s 281us/step - loss: 0.0251 - accuracy: 0.9893 - val_loss: 0.0524 - val_accuracy: 0.9733\n",
            "Epoch 287/300\n",
            "1125/1125 [==============================] - 0s 274us/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.0643 - val_accuracy: 0.9707\n",
            "Epoch 288/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.0498 - val_accuracy: 0.9787\n",
            "Epoch 289/300\n",
            "1125/1125 [==============================] - 0s 276us/step - loss: 0.0201 - accuracy: 0.9920 - val_loss: 0.0519 - val_accuracy: 0.9760\n",
            "Epoch 290/300\n",
            "1125/1125 [==============================] - 0s 279us/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 291/300\n",
            "1125/1125 [==============================] - 0s 287us/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0583 - val_accuracy: 0.9760\n",
            "Epoch 292/300\n",
            "1125/1125 [==============================] - 0s 282us/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.0738 - val_accuracy: 0.9813\n",
            "Epoch 293/300\n",
            "1125/1125 [==============================] - 0s 286us/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0702 - val_accuracy: 0.9813\n",
            "Epoch 294/300\n",
            "1125/1125 [==============================] - 0s 272us/step - loss: 0.0308 - accuracy: 0.9947 - val_loss: 0.0753 - val_accuracy: 0.9787\n",
            "Epoch 295/300\n",
            "1125/1125 [==============================] - 0s 275us/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0776 - val_accuracy: 0.9707\n",
            "Epoch 296/300\n",
            "1125/1125 [==============================] - 0s 272us/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.0769 - val_accuracy: 0.9787\n",
            "Epoch 297/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0734 - val_accuracy: 0.9733\n",
            "Epoch 298/300\n",
            "1125/1125 [==============================] - 0s 284us/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0746 - val_accuracy: 0.9680\n",
            "Epoch 299/300\n",
            "1125/1125 [==============================] - 0s 276us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0731 - val_accuracy: 0.9680\n",
            "Epoch 300/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0239 - accuracy: 0.9938 - val_loss: 0.0800 - val_accuracy: 0.9680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY7Tc2t5516M",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kd845FNQYp-R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "7e3b6761-3c0a-44b3-c148-24b446a521fe"
      },
      "source": [
        "plt.plot(classify.history['loss'])\n",
        "plt.plot(classify.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-631605b81252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'classify' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "28lU7n_dYp-U",
        "colab": {}
      },
      "source": [
        "plt.plot(classify.history['accuracy'])\n",
        "plt.plot(classify.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N2LXWxh0R-Za",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f25b987a-db5e-411b-f538-4e90e2b7fc00"
      },
      "source": [
        "plt.plot(classify2.history['loss'])\n",
        "plt.plot(classify2.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KRcUi-AiR-Zd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "61512929-d06d-4e2c-b6c0-be1448f2b89c"
      },
      "source": [
        "plt.plot(classify2.history['accuracy'])\n",
        "plt.plot(classify2.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee2tiasjcrjQ",
        "colab_type": "text"
      },
      "source": [
        "#BiLSTM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li7ZZzqjcxIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IDiLOFkZcxWd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "c7da97db-b171-4242-83d9-f592cf80fbd0"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model = Sequential()\n",
        "adam1 = Adam(learning_rate=0.0009)\n",
        "model.add(Bidirectional(LSTM(units=128, dropout=0.05, recurrent_dropout=0.25, return_sequences=True),input_shape=input_shape))\n",
        "model.add(Bidirectional(LSTM(units=64,  dropout=0.05, recurrent_dropout=0.25, return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=20, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam1, metrics=[\"accuracy\"],)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_7 (Bidirection (None, 1, 256)            159744    \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 1, 128)            164352    \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 326,676\n",
            "Trainable params: 326,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bUOj4_MzcxWh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f4bdc38-0571-4f91-b762-a472ebf9596d"
      },
      "source": [
        "batch_size = 35 # num of training examples per minibatch\n",
        "num_epochs =300\n",
        "classify = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(X_test,y_test),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1125 samples, validate on 375 samples\n",
            "Epoch 1/300\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 2.9079 - accuracy: 0.2480 - val_loss: 2.7687 - val_accuracy: 0.3733\n",
            "Epoch 2/300\n",
            "1125/1125 [==============================] - 0s 342us/step - loss: 2.5374 - accuracy: 0.3591 - val_loss: 2.2525 - val_accuracy: 0.3893\n",
            "Epoch 3/300\n",
            "1125/1125 [==============================] - 0s 354us/step - loss: 1.8886 - accuracy: 0.4373 - val_loss: 1.5540 - val_accuracy: 0.5013\n",
            "Epoch 4/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 1.3418 - accuracy: 0.5653 - val_loss: 1.1855 - val_accuracy: 0.5840\n",
            "Epoch 5/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 1.0555 - accuracy: 0.6542 - val_loss: 0.9611 - val_accuracy: 0.6693\n",
            "Epoch 6/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.8650 - accuracy: 0.7209 - val_loss: 0.8032 - val_accuracy: 0.7600\n",
            "Epoch 7/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.7361 - accuracy: 0.7636 - val_loss: 0.7026 - val_accuracy: 0.7893\n",
            "Epoch 8/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.6336 - accuracy: 0.7991 - val_loss: 0.6232 - val_accuracy: 0.8267\n",
            "Epoch 9/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.5374 - accuracy: 0.8462 - val_loss: 0.5318 - val_accuracy: 0.8587\n",
            "Epoch 10/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.4702 - accuracy: 0.8649 - val_loss: 0.4891 - val_accuracy: 0.8507\n",
            "Epoch 11/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.4258 - accuracy: 0.8800 - val_loss: 0.4466 - val_accuracy: 0.8773\n",
            "Epoch 12/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.3651 - accuracy: 0.9013 - val_loss: 0.3973 - val_accuracy: 0.8827\n",
            "Epoch 13/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.3438 - accuracy: 0.9093 - val_loss: 0.3768 - val_accuracy: 0.8907\n",
            "Epoch 14/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.3083 - accuracy: 0.9200 - val_loss: 0.3668 - val_accuracy: 0.8987\n",
            "Epoch 15/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.2842 - accuracy: 0.9253 - val_loss: 0.3326 - val_accuracy: 0.8987\n",
            "Epoch 16/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.2534 - accuracy: 0.9396 - val_loss: 0.3168 - val_accuracy: 0.9147\n",
            "Epoch 17/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.2444 - accuracy: 0.9431 - val_loss: 0.3052 - val_accuracy: 0.9120\n",
            "Epoch 18/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.2104 - accuracy: 0.9502 - val_loss: 0.2860 - val_accuracy: 0.9227\n",
            "Epoch 19/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.2070 - accuracy: 0.9520 - val_loss: 0.2846 - val_accuracy: 0.9067\n",
            "Epoch 20/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.1663 - accuracy: 0.9680 - val_loss: 0.2663 - val_accuracy: 0.9120\n",
            "Epoch 21/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.1696 - accuracy: 0.9618 - val_loss: 0.2692 - val_accuracy: 0.9093\n",
            "Epoch 22/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.1570 - accuracy: 0.9671 - val_loss: 0.2386 - val_accuracy: 0.9200\n",
            "Epoch 23/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.1462 - accuracy: 0.9689 - val_loss: 0.2457 - val_accuracy: 0.9200\n",
            "Epoch 24/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.1443 - accuracy: 0.9707 - val_loss: 0.2450 - val_accuracy: 0.9147\n",
            "Epoch 25/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.1379 - accuracy: 0.9627 - val_loss: 0.2386 - val_accuracy: 0.9200\n",
            "Epoch 26/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.1250 - accuracy: 0.9751 - val_loss: 0.2546 - val_accuracy: 0.9147\n",
            "Epoch 27/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.1148 - accuracy: 0.9751 - val_loss: 0.2240 - val_accuracy: 0.9280\n",
            "Epoch 28/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.1131 - accuracy: 0.9733 - val_loss: 0.2223 - val_accuracy: 0.9333\n",
            "Epoch 29/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.1011 - accuracy: 0.9769 - val_loss: 0.2338 - val_accuracy: 0.9200\n",
            "Epoch 30/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.1129 - accuracy: 0.9813 - val_loss: 0.2300 - val_accuracy: 0.9280\n",
            "Epoch 31/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.1045 - accuracy: 0.9716 - val_loss: 0.2269 - val_accuracy: 0.9200\n",
            "Epoch 32/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.1085 - accuracy: 0.9769 - val_loss: 0.2041 - val_accuracy: 0.9387\n",
            "Epoch 33/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.1021 - accuracy: 0.9742 - val_loss: 0.2377 - val_accuracy: 0.9200\n",
            "Epoch 34/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.0984 - accuracy: 0.9760 - val_loss: 0.2080 - val_accuracy: 0.9333\n",
            "Epoch 35/300\n",
            "1125/1125 [==============================] - 0s 342us/step - loss: 0.0801 - accuracy: 0.9858 - val_loss: 0.2143 - val_accuracy: 0.9200\n",
            "Epoch 36/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0937 - accuracy: 0.9760 - val_loss: 0.2272 - val_accuracy: 0.9227\n",
            "Epoch 37/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0759 - accuracy: 0.9858 - val_loss: 0.1941 - val_accuracy: 0.9253\n",
            "Epoch 38/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0829 - accuracy: 0.9787 - val_loss: 0.2171 - val_accuracy: 0.9200\n",
            "Epoch 39/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0677 - accuracy: 0.9884 - val_loss: 0.2120 - val_accuracy: 0.9280\n",
            "Epoch 40/300\n",
            "1125/1125 [==============================] - 0s 344us/step - loss: 0.0748 - accuracy: 0.9813 - val_loss: 0.2198 - val_accuracy: 0.9093\n",
            "Epoch 41/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0645 - accuracy: 0.9876 - val_loss: 0.2081 - val_accuracy: 0.9333\n",
            "Epoch 42/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0683 - accuracy: 0.9796 - val_loss: 0.2052 - val_accuracy: 0.9253\n",
            "Epoch 43/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0720 - accuracy: 0.9822 - val_loss: 0.2013 - val_accuracy: 0.9253\n",
            "Epoch 44/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0654 - accuracy: 0.9796 - val_loss: 0.2134 - val_accuracy: 0.9333\n",
            "Epoch 45/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0541 - accuracy: 0.9867 - val_loss: 0.2010 - val_accuracy: 0.9360\n",
            "Epoch 46/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0720 - accuracy: 0.9822 - val_loss: 0.2077 - val_accuracy: 0.9307\n",
            "Epoch 47/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0587 - accuracy: 0.9867 - val_loss: 0.2140 - val_accuracy: 0.9333\n",
            "Epoch 48/300\n",
            "1125/1125 [==============================] - 0s 344us/step - loss: 0.0600 - accuracy: 0.9831 - val_loss: 0.2229 - val_accuracy: 0.9200\n",
            "Epoch 49/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0529 - accuracy: 0.9876 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
            "Epoch 50/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0397 - accuracy: 0.9893 - val_loss: 0.1989 - val_accuracy: 0.9333\n",
            "Epoch 51/300\n",
            "1125/1125 [==============================] - 0s 350us/step - loss: 0.0652 - accuracy: 0.9840 - val_loss: 0.2392 - val_accuracy: 0.9227\n",
            "Epoch 52/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0563 - accuracy: 0.9849 - val_loss: 0.2228 - val_accuracy: 0.9227\n",
            "Epoch 53/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.0637 - accuracy: 0.9831 - val_loss: 0.2175 - val_accuracy: 0.9253\n",
            "Epoch 54/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0736 - accuracy: 0.9796 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
            "Epoch 55/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0624 - accuracy: 0.9840 - val_loss: 0.2291 - val_accuracy: 0.9200\n",
            "Epoch 56/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0578 - accuracy: 0.9876 - val_loss: 0.1901 - val_accuracy: 0.9307\n",
            "Epoch 57/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0475 - accuracy: 0.9876 - val_loss: 0.1844 - val_accuracy: 0.9387\n",
            "Epoch 58/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0377 - accuracy: 0.9911 - val_loss: 0.1818 - val_accuracy: 0.9333\n",
            "Epoch 59/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0386 - accuracy: 0.9920 - val_loss: 0.1943 - val_accuracy: 0.9360\n",
            "Epoch 60/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.2099 - val_accuracy: 0.9227\n",
            "Epoch 61/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0621 - accuracy: 0.9858 - val_loss: 0.2172 - val_accuracy: 0.9227\n",
            "Epoch 62/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0414 - accuracy: 0.9938 - val_loss: 0.2155 - val_accuracy: 0.9333\n",
            "Epoch 63/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0494 - accuracy: 0.9876 - val_loss: 0.2184 - val_accuracy: 0.9280\n",
            "Epoch 64/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0445 - accuracy: 0.9893 - val_loss: 0.2253 - val_accuracy: 0.9307\n",
            "Epoch 65/300\n",
            "1125/1125 [==============================] - 0s 341us/step - loss: 0.0465 - accuracy: 0.9938 - val_loss: 0.2319 - val_accuracy: 0.9253\n",
            "Epoch 66/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0447 - accuracy: 0.9867 - val_loss: 0.2204 - val_accuracy: 0.9253\n",
            "Epoch 67/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0507 - accuracy: 0.9884 - val_loss: 0.2355 - val_accuracy: 0.9253\n",
            "Epoch 68/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0430 - accuracy: 0.9893 - val_loss: 0.2165 - val_accuracy: 0.9307\n",
            "Epoch 69/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 0.2262 - val_accuracy: 0.9333\n",
            "Epoch 70/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.2258 - val_accuracy: 0.9280\n",
            "Epoch 71/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.2341 - val_accuracy: 0.9227\n",
            "Epoch 72/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.2432 - val_accuracy: 0.9173\n",
            "Epoch 73/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0322 - accuracy: 0.9929 - val_loss: 0.2359 - val_accuracy: 0.9280\n",
            "Epoch 74/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.2120 - val_accuracy: 0.9333\n",
            "Epoch 75/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0242 - accuracy: 0.9947 - val_loss: 0.2209 - val_accuracy: 0.9280\n",
            "Epoch 76/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.2204 - val_accuracy: 0.9280\n",
            "Epoch 77/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0298 - accuracy: 0.9956 - val_loss: 0.2201 - val_accuracy: 0.9253\n",
            "Epoch 78/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 0.2248 - val_accuracy: 0.9333\n",
            "Epoch 79/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0395 - accuracy: 0.9911 - val_loss: 0.2463 - val_accuracy: 0.9333\n",
            "Epoch 80/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0231 - accuracy: 0.9956 - val_loss: 0.2500 - val_accuracy: 0.9173\n",
            "Epoch 81/300\n",
            "1125/1125 [==============================] - 0s 341us/step - loss: 0.0268 - accuracy: 0.9929 - val_loss: 0.2599 - val_accuracy: 0.9227\n",
            "Epoch 82/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0359 - accuracy: 0.9920 - val_loss: 0.2484 - val_accuracy: 0.9227\n",
            "Epoch 83/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 0.2546 - val_accuracy: 0.9120\n",
            "Epoch 84/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0387 - accuracy: 0.9911 - val_loss: 0.2457 - val_accuracy: 0.9173\n",
            "Epoch 85/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 0.2448 - val_accuracy: 0.9253\n",
            "Epoch 86/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 0.2465 - val_accuracy: 0.9253\n",
            "Epoch 87/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0269 - accuracy: 0.9947 - val_loss: 0.2503 - val_accuracy: 0.9253\n",
            "Epoch 88/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.2570 - val_accuracy: 0.9227\n",
            "Epoch 89/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0526 - accuracy: 0.9876 - val_loss: 0.2425 - val_accuracy: 0.9227\n",
            "Epoch 90/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.2260 - val_accuracy: 0.9280\n",
            "Epoch 91/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0295 - accuracy: 0.9938 - val_loss: 0.2460 - val_accuracy: 0.9253\n",
            "Epoch 92/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0323 - accuracy: 0.9920 - val_loss: 0.2462 - val_accuracy: 0.9280\n",
            "Epoch 93/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.2374 - val_accuracy: 0.9307\n",
            "Epoch 94/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0366 - accuracy: 0.9947 - val_loss: 0.2353 - val_accuracy: 0.9253\n",
            "Epoch 95/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 0.2505 - val_accuracy: 0.9200\n",
            "Epoch 96/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0314 - accuracy: 0.9947 - val_loss: 0.2606 - val_accuracy: 0.9147\n",
            "Epoch 97/300\n",
            "1125/1125 [==============================] - 0s 339us/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 0.2279 - val_accuracy: 0.9227\n",
            "Epoch 98/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0263 - accuracy: 0.9938 - val_loss: 0.2182 - val_accuracy: 0.9360\n",
            "Epoch 99/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.2178 - val_accuracy: 0.9413\n",
            "Epoch 100/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.2600 - val_accuracy: 0.9227\n",
            "Epoch 101/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0364 - accuracy: 0.9920 - val_loss: 0.2320 - val_accuracy: 0.9360\n",
            "Epoch 102/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 0.2457 - val_accuracy: 0.9307\n",
            "Epoch 103/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 0.2364 - val_accuracy: 0.9280\n",
            "Epoch 104/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.2626 - val_accuracy: 0.9280\n",
            "Epoch 105/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2385 - val_accuracy: 0.9280\n",
            "Epoch 106/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.0281 - accuracy: 0.9929 - val_loss: 0.2372 - val_accuracy: 0.9280\n",
            "Epoch 107/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0261 - accuracy: 0.9938 - val_loss: 0.2347 - val_accuracy: 0.9360\n",
            "Epoch 108/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.2429 - val_accuracy: 0.9360\n",
            "Epoch 109/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 0.2429 - val_accuracy: 0.9307\n",
            "Epoch 110/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0284 - accuracy: 0.9964 - val_loss: 0.2495 - val_accuracy: 0.9253\n",
            "Epoch 111/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.2717 - val_accuracy: 0.9227\n",
            "Epoch 112/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.2552 - val_accuracy: 0.9280\n",
            "Epoch 113/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0200 - accuracy: 0.9956 - val_loss: 0.2496 - val_accuracy: 0.9333\n",
            "Epoch 114/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0258 - accuracy: 0.9956 - val_loss: 0.2688 - val_accuracy: 0.9227\n",
            "Epoch 115/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.2741 - val_accuracy: 0.9173\n",
            "Epoch 116/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0237 - accuracy: 0.9938 - val_loss: 0.2810 - val_accuracy: 0.9173\n",
            "Epoch 117/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.0172 - accuracy: 0.9982 - val_loss: 0.2748 - val_accuracy: 0.9147\n",
            "Epoch 118/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.2673 - val_accuracy: 0.9253\n",
            "Epoch 119/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.2878 - val_accuracy: 0.9173\n",
            "Epoch 120/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.0411 - accuracy: 0.9920 - val_loss: 0.3058 - val_accuracy: 0.9120\n",
            "Epoch 121/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.2688 - val_accuracy: 0.9200\n",
            "Epoch 122/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0240 - accuracy: 0.9956 - val_loss: 0.2722 - val_accuracy: 0.9173\n",
            "Epoch 123/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 0.2792 - val_accuracy: 0.9147\n",
            "Epoch 124/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0191 - accuracy: 0.9956 - val_loss: 0.2714 - val_accuracy: 0.9227\n",
            "Epoch 125/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 0.2591 - val_accuracy: 0.9307\n",
            "Epoch 126/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.2255 - val_accuracy: 0.9333\n",
            "Epoch 127/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.2630 - val_accuracy: 0.9280\n",
            "Epoch 128/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.2732 - val_accuracy: 0.9227\n",
            "Epoch 129/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.2727 - val_accuracy: 0.9333\n",
            "Epoch 130/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.2567 - val_accuracy: 0.9280\n",
            "Epoch 131/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.2646 - val_accuracy: 0.9120\n",
            "Epoch 132/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.3069 - val_accuracy: 0.9067\n",
            "Epoch 133/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.2697 - val_accuracy: 0.9200\n",
            "Epoch 134/300\n",
            "1125/1125 [==============================] - 0s 342us/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.2670 - val_accuracy: 0.9227\n",
            "Epoch 135/300\n",
            "1125/1125 [==============================] - 0s 357us/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.2830 - val_accuracy: 0.9227\n",
            "Epoch 136/300\n",
            "1125/1125 [==============================] - 0s 370us/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 0.3069 - val_accuracy: 0.9200\n",
            "Epoch 137/300\n",
            "1125/1125 [==============================] - 0s 348us/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.2969 - val_accuracy: 0.9227\n",
            "Epoch 138/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.2912 - val_accuracy: 0.9280\n",
            "Epoch 139/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.2895 - val_accuracy: 0.9200\n",
            "Epoch 140/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.2781 - val_accuracy: 0.9200\n",
            "Epoch 141/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.2718 - val_accuracy: 0.9200\n",
            "Epoch 142/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.2902 - val_accuracy: 0.9253\n",
            "Epoch 143/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.3172 - val_accuracy: 0.9147\n",
            "Epoch 144/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0177 - accuracy: 0.9920 - val_loss: 0.2812 - val_accuracy: 0.9253\n",
            "Epoch 145/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.2539 - val_accuracy: 0.9227\n",
            "Epoch 146/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.2888 - val_accuracy: 0.9227\n",
            "Epoch 147/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 0.2936 - val_accuracy: 0.9120\n",
            "Epoch 148/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.2831 - val_accuracy: 0.9200\n",
            "Epoch 149/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.2996 - val_accuracy: 0.9227\n",
            "Epoch 150/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.3199 - val_accuracy: 0.9067\n",
            "Epoch 151/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0200 - accuracy: 0.9920 - val_loss: 0.3112 - val_accuracy: 0.9147\n",
            "Epoch 152/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.3111 - val_accuracy: 0.9067\n",
            "Epoch 153/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0181 - accuracy: 0.9973 - val_loss: 0.3308 - val_accuracy: 0.9120\n",
            "Epoch 154/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.3209 - val_accuracy: 0.9147\n",
            "Epoch 155/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.3426 - val_accuracy: 0.9093\n",
            "Epoch 156/300\n",
            "1125/1125 [==============================] - 0s 294us/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.3034 - val_accuracy: 0.9173\n",
            "Epoch 157/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0210 - accuracy: 0.9947 - val_loss: 0.3232 - val_accuracy: 0.9173\n",
            "Epoch 158/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.2931 - val_accuracy: 0.9253\n",
            "Epoch 159/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.2892 - val_accuracy: 0.9227\n",
            "Epoch 160/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9280\n",
            "Epoch 161/300\n",
            "1125/1125 [==============================] - 0s 300us/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.2840 - val_accuracy: 0.9280\n",
            "Epoch 162/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.2655 - val_accuracy: 0.9173\n",
            "Epoch 163/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.3501 - val_accuracy: 0.9093\n",
            "Epoch 164/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.3426 - val_accuracy: 0.9147\n",
            "Epoch 165/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.3068 - val_accuracy: 0.9173\n",
            "Epoch 166/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.3430 - val_accuracy: 0.9040\n",
            "Epoch 167/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9120\n",
            "Epoch 168/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0103 - accuracy: 0.9947 - val_loss: 0.3037 - val_accuracy: 0.9120\n",
            "Epoch 169/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.2795 - val_accuracy: 0.9253\n",
            "Epoch 170/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 0.2965 - val_accuracy: 0.9173\n",
            "Epoch 171/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.3055 - val_accuracy: 0.9227\n",
            "Epoch 172/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0233 - accuracy: 0.9902 - val_loss: 0.3015 - val_accuracy: 0.9120\n",
            "Epoch 173/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.2609 - val_accuracy: 0.9280\n",
            "Epoch 174/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0106 - accuracy: 0.9956 - val_loss: 0.2464 - val_accuracy: 0.9333\n",
            "Epoch 175/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.2571 - val_accuracy: 0.9307\n",
            "Epoch 176/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.2636 - val_accuracy: 0.9280\n",
            "Epoch 177/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.2483 - val_accuracy: 0.9280\n",
            "Epoch 178/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.2587 - val_accuracy: 0.9227\n",
            "Epoch 179/300\n",
            "1125/1125 [==============================] - 0s 292us/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.2697 - val_accuracy: 0.9333\n",
            "Epoch 180/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 0.2913 - val_accuracy: 0.9307\n",
            "Epoch 181/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.2920 - val_accuracy: 0.9173\n",
            "Epoch 182/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.2761 - val_accuracy: 0.9280\n",
            "Epoch 183/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.2735 - val_accuracy: 0.9333\n",
            "Epoch 184/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.2867 - val_accuracy: 0.9280\n",
            "Epoch 185/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.2670 - val_accuracy: 0.9360\n",
            "Epoch 186/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.2838 - val_accuracy: 0.9280\n",
            "Epoch 187/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0094 - accuracy: 0.9956 - val_loss: 0.2741 - val_accuracy: 0.9253\n",
            "Epoch 188/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0135 - accuracy: 0.9982 - val_loss: 0.2654 - val_accuracy: 0.9280\n",
            "Epoch 189/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.2474 - val_accuracy: 0.9307\n",
            "Epoch 190/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0159 - accuracy: 0.9973 - val_loss: 0.2734 - val_accuracy: 0.9280\n",
            "Epoch 191/300\n",
            "1125/1125 [==============================] - 0s 341us/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.2889 - val_accuracy: 0.9253\n",
            "Epoch 192/300\n",
            "1125/1125 [==============================] - 0s 350us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9307\n",
            "Epoch 193/300\n",
            "1125/1125 [==============================] - 0s 350us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9360\n",
            "Epoch 194/300\n",
            "1125/1125 [==============================] - 0s 362us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9307\n",
            "Epoch 195/300\n",
            "1125/1125 [==============================] - 0s 388us/step - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.2333 - val_accuracy: 0.9307\n",
            "Epoch 196/300\n",
            "1125/1125 [==============================] - 0s 407us/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2528 - val_accuracy: 0.9307\n",
            "Epoch 197/300\n",
            "1125/1125 [==============================] - 0s 424us/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.2359 - val_accuracy: 0.9333\n",
            "Epoch 198/300\n",
            "1125/1125 [==============================] - 0s 406us/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.2292 - val_accuracy: 0.9333\n",
            "Epoch 199/300\n",
            "1125/1125 [==============================] - 0s 352us/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.2472 - val_accuracy: 0.9280\n",
            "Epoch 200/300\n",
            "1125/1125 [==============================] - 1s 448us/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.2551 - val_accuracy: 0.9200\n",
            "Epoch 201/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.2550 - val_accuracy: 0.9307\n",
            "Epoch 202/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.2798 - val_accuracy: 0.9280\n",
            "Epoch 203/300\n",
            "1125/1125 [==============================] - 0s 338us/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.2828 - val_accuracy: 0.9147\n",
            "Epoch 204/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0111 - accuracy: 0.9929 - val_loss: 0.3004 - val_accuracy: 0.9093\n",
            "Epoch 205/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.2826 - val_accuracy: 0.9227\n",
            "Epoch 206/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9253\n",
            "Epoch 207/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3102 - val_accuracy: 0.9227\n",
            "Epoch 208/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.2890 - val_accuracy: 0.9253\n",
            "Epoch 209/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.3000 - val_accuracy: 0.9227\n",
            "Epoch 210/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.2936 - val_accuracy: 0.9307\n",
            "Epoch 211/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.2743 - val_accuracy: 0.9333\n",
            "Epoch 212/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.2623 - val_accuracy: 0.9280\n",
            "Epoch 213/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0194 - accuracy: 0.9947 - val_loss: 0.2361 - val_accuracy: 0.9387\n",
            "Epoch 214/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 0.2460 - val_accuracy: 0.9360\n",
            "Epoch 215/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.2354 - val_accuracy: 0.9280\n",
            "Epoch 216/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.3209 - val_accuracy: 0.9147\n",
            "Epoch 217/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.2374 - val_accuracy: 0.9307\n",
            "Epoch 218/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.2620 - val_accuracy: 0.9280\n",
            "Epoch 219/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.2521 - val_accuracy: 0.9333\n",
            "Epoch 220/300\n",
            "1125/1125 [==============================] - 0s 339us/step - loss: 0.0085 - accuracy: 0.9964 - val_loss: 0.2607 - val_accuracy: 0.9307\n",
            "Epoch 221/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.2601 - val_accuracy: 0.9307\n",
            "Epoch 222/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.2676 - val_accuracy: 0.9307\n",
            "Epoch 223/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.2588 - val_accuracy: 0.9253\n",
            "Epoch 224/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9333\n",
            "Epoch 225/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.2533 - val_accuracy: 0.9333\n",
            "Epoch 226/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.3088 - val_accuracy: 0.9200\n",
            "Epoch 227/300\n",
            "1125/1125 [==============================] - 0s 339us/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3001 - val_accuracy: 0.9253\n",
            "Epoch 228/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.3798 - val_accuracy: 0.9067\n",
            "Epoch 229/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0338 - accuracy: 0.9911 - val_loss: 0.3154 - val_accuracy: 0.9173\n",
            "Epoch 230/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0223 - accuracy: 0.9956 - val_loss: 0.3343 - val_accuracy: 0.9147\n",
            "Epoch 231/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.3131 - val_accuracy: 0.9173\n",
            "Epoch 232/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.2928 - val_accuracy: 0.9013\n",
            "Epoch 233/300\n",
            "1125/1125 [==============================] - 0s 345us/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.2773 - val_accuracy: 0.9200\n",
            "Epoch 234/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.3390 - val_accuracy: 0.9200\n",
            "Epoch 235/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9093\n",
            "Epoch 236/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3342 - val_accuracy: 0.9173\n",
            "Epoch 237/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.3181 - val_accuracy: 0.9253\n",
            "Epoch 238/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.3322 - val_accuracy: 0.9093\n",
            "Epoch 239/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.3846 - val_accuracy: 0.8987\n",
            "Epoch 240/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.3538 - val_accuracy: 0.9200\n",
            "Epoch 241/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.3273 - val_accuracy: 0.9227\n",
            "Epoch 242/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.3168 - val_accuracy: 0.9360\n",
            "Epoch 243/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2986 - val_accuracy: 0.9467\n",
            "Epoch 244/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.3004 - val_accuracy: 0.9387\n",
            "Epoch 245/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.2998 - val_accuracy: 0.9253\n",
            "Epoch 246/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.2969 - val_accuracy: 0.9227\n",
            "Epoch 247/300\n",
            "1125/1125 [==============================] - 0s 339us/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.2910 - val_accuracy: 0.9333\n",
            "Epoch 248/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.3048 - val_accuracy: 0.9307\n",
            "Epoch 249/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.2917 - val_accuracy: 0.9307\n",
            "Epoch 250/300\n",
            "1125/1125 [==============================] - 0s 332us/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.2803 - val_accuracy: 0.9333\n",
            "Epoch 251/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2831 - val_accuracy: 0.9360\n",
            "Epoch 252/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9360\n",
            "Epoch 253/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 0.2582 - val_accuracy: 0.9360\n",
            "Epoch 254/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.2767 - val_accuracy: 0.9360\n",
            "Epoch 255/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.2783 - val_accuracy: 0.9360\n",
            "Epoch 256/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.2809 - val_accuracy: 0.9360\n",
            "Epoch 257/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.3190 - val_accuracy: 0.9200\n",
            "Epoch 258/300\n",
            "1125/1125 [==============================] - 0s 346us/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.2456 - val_accuracy: 0.9253\n",
            "Epoch 259/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.2528 - val_accuracy: 0.9360\n",
            "Epoch 260/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.2527 - val_accuracy: 0.9307\n",
            "Epoch 261/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.2550 - val_accuracy: 0.9280\n",
            "Epoch 262/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.2538 - val_accuracy: 0.9280\n",
            "Epoch 263/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.2584 - val_accuracy: 0.9253\n",
            "Epoch 264/300\n",
            "1125/1125 [==============================] - 0s 341us/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2519 - val_accuracy: 0.9227\n",
            "Epoch 265/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9387\n",
            "Epoch 266/300\n",
            "1125/1125 [==============================] - 0s 342us/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.2509 - val_accuracy: 0.9360\n",
            "Epoch 267/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.2510 - val_accuracy: 0.9360\n",
            "Epoch 268/300\n",
            "1125/1125 [==============================] - 0s 339us/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.2488 - val_accuracy: 0.9360\n",
            "Epoch 269/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0047 - accuracy: 0.9973 - val_loss: 0.2638 - val_accuracy: 0.9307\n",
            "Epoch 270/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.2879 - val_accuracy: 0.9227\n",
            "Epoch 271/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.3143 - val_accuracy: 0.9200\n",
            "Epoch 272/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.3305 - val_accuracy: 0.9120\n",
            "Epoch 273/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0098 - accuracy: 0.9956 - val_loss: 0.2942 - val_accuracy: 0.9200\n",
            "Epoch 274/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.2747 - val_accuracy: 0.9280\n",
            "Epoch 275/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.2946 - val_accuracy: 0.9173\n",
            "Epoch 276/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0071 - accuracy: 0.9964 - val_loss: 0.3002 - val_accuracy: 0.9147\n",
            "Epoch 277/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.2753 - val_accuracy: 0.9147\n",
            "Epoch 278/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.2806 - val_accuracy: 0.9200\n",
            "Epoch 279/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.2801 - val_accuracy: 0.9227\n",
            "Epoch 280/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 0.2857 - val_accuracy: 0.9227\n",
            "Epoch 281/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0106 - accuracy: 0.9956 - val_loss: 0.2786 - val_accuracy: 0.9253\n",
            "Epoch 282/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9333\n",
            "Epoch 283/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.2751 - val_accuracy: 0.9280\n",
            "Epoch 284/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.2673 - val_accuracy: 0.9200\n",
            "Epoch 285/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.3027 - val_accuracy: 0.9147\n",
            "Epoch 286/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0260 - accuracy: 0.9902 - val_loss: 0.2554 - val_accuracy: 0.9253\n",
            "Epoch 287/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 0.2753 - val_accuracy: 0.9173\n",
            "Epoch 288/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9227\n",
            "Epoch 289/300\n",
            "1125/1125 [==============================] - 0s 338us/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.2720 - val_accuracy: 0.9253\n",
            "Epoch 290/300\n",
            "1125/1125 [==============================] - 0s 332us/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.2866 - val_accuracy: 0.9173\n",
            "Epoch 291/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.2611 - val_accuracy: 0.9200\n",
            "Epoch 292/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.2616 - val_accuracy: 0.9253\n",
            "Epoch 293/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.2463 - val_accuracy: 0.9387\n",
            "Epoch 294/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 0.2637 - val_accuracy: 0.9307\n",
            "Epoch 295/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.3000 - val_accuracy: 0.9387\n",
            "Epoch 296/300\n",
            "1125/1125 [==============================] - 0s 339us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9387\n",
            "Epoch 297/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.2714 - val_accuracy: 0.9413\n",
            "Epoch 298/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.2843 - val_accuracy: 0.9413\n",
            "Epoch 299/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.3101 - val_accuracy: 0.9333\n",
            "Epoch 300/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.3221 - val_accuracy: 0.9280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtpQTq-7SE90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_o_6NwaiSFK6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "35b9d539-4fe0-4d95-ef49-810bc59c10d6"
      },
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size=0.25)\n",
        "X_train2 = np.reshape(X_train2, (X_train2.shape[0], 1, X_train2.shape[1]))\n",
        "X_test2 = np.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
        "input_shape = (X_train2.shape[1], X_train2.shape[2])\n",
        "model = Sequential()\n",
        "adam1 = Adam(learning_rate=0.0009)\n",
        "model.add(Bidirectional(LSTM(units=128, dropout=0.05, recurrent_dropout=0.25, return_sequences=True),input_shape=input_shape))\n",
        "model.add(Bidirectional(LSTM(units=64,  dropout=0.05, recurrent_dropout=0.25, return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=20, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam1, metrics=[\"accuracy\"],)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_9 (Bidirection (None, 1, 256)            159744    \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 1, 128)            164352    \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 326,676\n",
            "Trainable params: 326,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PXNgN9p6SFK8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cab63fb-bf80-4ed7-b0a9-cb00e485aa3d"
      },
      "source": [
        "batch_size = 35 # num of training examples per minibatch\n",
        "num_epochs =300\n",
        "classify2 = model.fit(\n",
        "    X_train2,\n",
        "    y_train2,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(X_test2,y_test2),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1125 samples, validate on 375 samples\n",
            "Epoch 1/300\n",
            "1125/1125 [==============================] - 2s 1ms/step - loss: 2.9046 - accuracy: 0.2516 - val_loss: 2.7838 - val_accuracy: 0.2427\n",
            "Epoch 2/300\n",
            "1125/1125 [==============================] - 0s 344us/step - loss: 2.5159 - accuracy: 0.3084 - val_loss: 2.2484 - val_accuracy: 0.2773\n",
            "Epoch 3/300\n",
            "1125/1125 [==============================] - 0s 347us/step - loss: 1.8761 - accuracy: 0.3938 - val_loss: 1.6461 - val_accuracy: 0.3920\n",
            "Epoch 4/300\n",
            "1125/1125 [==============================] - 0s 338us/step - loss: 1.3624 - accuracy: 0.5404 - val_loss: 1.2534 - val_accuracy: 0.5760\n",
            "Epoch 5/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 1.0354 - accuracy: 0.6782 - val_loss: 1.0174 - val_accuracy: 0.6533\n",
            "Epoch 6/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.8080 - accuracy: 0.7413 - val_loss: 0.8515 - val_accuracy: 0.7013\n",
            "Epoch 7/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.6622 - accuracy: 0.7973 - val_loss: 0.7284 - val_accuracy: 0.7440\n",
            "Epoch 8/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.5539 - accuracy: 0.8338 - val_loss: 0.6221 - val_accuracy: 0.7893\n",
            "Epoch 9/300\n",
            "1125/1125 [==============================] - 0s 332us/step - loss: 0.4678 - accuracy: 0.8702 - val_loss: 0.5451 - val_accuracy: 0.8213\n",
            "Epoch 10/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.4042 - accuracy: 0.8853 - val_loss: 0.4662 - val_accuracy: 0.8560\n",
            "Epoch 11/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.3667 - accuracy: 0.8951 - val_loss: 0.4369 - val_accuracy: 0.8747\n",
            "Epoch 12/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.3047 - accuracy: 0.9138 - val_loss: 0.3907 - val_accuracy: 0.8933\n",
            "Epoch 13/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.2593 - accuracy: 0.9289 - val_loss: 0.3577 - val_accuracy: 0.9067\n",
            "Epoch 14/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.2635 - accuracy: 0.9298 - val_loss: 0.3228 - val_accuracy: 0.9280\n",
            "Epoch 15/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.2359 - accuracy: 0.9449 - val_loss: 0.2965 - val_accuracy: 0.9280\n",
            "Epoch 16/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.2230 - accuracy: 0.9476 - val_loss: 0.2778 - val_accuracy: 0.9280\n",
            "Epoch 17/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.2042 - accuracy: 0.9529 - val_loss: 0.2715 - val_accuracy: 0.9280\n",
            "Epoch 18/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.1662 - accuracy: 0.9671 - val_loss: 0.2530 - val_accuracy: 0.9360\n",
            "Epoch 19/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.1676 - accuracy: 0.9609 - val_loss: 0.2420 - val_accuracy: 0.9360\n",
            "Epoch 20/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.1387 - accuracy: 0.9707 - val_loss: 0.2340 - val_accuracy: 0.9387\n",
            "Epoch 21/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.1386 - accuracy: 0.9698 - val_loss: 0.2397 - val_accuracy: 0.9333\n",
            "Epoch 22/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.1128 - accuracy: 0.9733 - val_loss: 0.2318 - val_accuracy: 0.9387\n",
            "Epoch 23/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.1232 - accuracy: 0.9662 - val_loss: 0.2263 - val_accuracy: 0.9360\n",
            "Epoch 24/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.1033 - accuracy: 0.9778 - val_loss: 0.2172 - val_accuracy: 0.9413\n",
            "Epoch 25/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.1006 - accuracy: 0.9751 - val_loss: 0.2061 - val_accuracy: 0.9440\n",
            "Epoch 26/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.1092 - accuracy: 0.9804 - val_loss: 0.2142 - val_accuracy: 0.9440\n",
            "Epoch 27/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.1017 - accuracy: 0.9733 - val_loss: 0.2065 - val_accuracy: 0.9467\n",
            "Epoch 28/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.1125 - accuracy: 0.9742 - val_loss: 0.2065 - val_accuracy: 0.9387\n",
            "Epoch 29/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.1047 - accuracy: 0.9724 - val_loss: 0.2080 - val_accuracy: 0.9413\n",
            "Epoch 30/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0733 - accuracy: 0.9822 - val_loss: 0.2091 - val_accuracy: 0.9387\n",
            "Epoch 31/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0783 - accuracy: 0.9831 - val_loss: 0.2165 - val_accuracy: 0.9467\n",
            "Epoch 32/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.0924 - accuracy: 0.9804 - val_loss: 0.2127 - val_accuracy: 0.9493\n",
            "Epoch 33/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0689 - accuracy: 0.9796 - val_loss: 0.2094 - val_accuracy: 0.9520\n",
            "Epoch 34/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0721 - accuracy: 0.9822 - val_loss: 0.2074 - val_accuracy: 0.9547\n",
            "Epoch 35/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0636 - accuracy: 0.9858 - val_loss: 0.1969 - val_accuracy: 0.9520\n",
            "Epoch 36/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0709 - accuracy: 0.9787 - val_loss: 0.1877 - val_accuracy: 0.9493\n",
            "Epoch 37/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0757 - accuracy: 0.9733 - val_loss: 0.1909 - val_accuracy: 0.9520\n",
            "Epoch 38/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0653 - accuracy: 0.9858 - val_loss: 0.1927 - val_accuracy: 0.9493\n",
            "Epoch 39/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0615 - accuracy: 0.9902 - val_loss: 0.1871 - val_accuracy: 0.9467\n",
            "Epoch 40/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0445 - accuracy: 0.9893 - val_loss: 0.1978 - val_accuracy: 0.9467\n",
            "Epoch 41/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0594 - accuracy: 0.9893 - val_loss: 0.2001 - val_accuracy: 0.9440\n",
            "Epoch 42/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0558 - accuracy: 0.9867 - val_loss: 0.1981 - val_accuracy: 0.9440\n",
            "Epoch 43/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0570 - accuracy: 0.9867 - val_loss: 0.2113 - val_accuracy: 0.9493\n",
            "Epoch 44/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0500 - accuracy: 0.9858 - val_loss: 0.2130 - val_accuracy: 0.9413\n",
            "Epoch 45/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0536 - accuracy: 0.9849 - val_loss: 0.1870 - val_accuracy: 0.9520\n",
            "Epoch 46/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0444 - accuracy: 0.9822 - val_loss: 0.2014 - val_accuracy: 0.9547\n",
            "Epoch 47/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0514 - accuracy: 0.9876 - val_loss: 0.1722 - val_accuracy: 0.9547\n",
            "Epoch 48/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0563 - accuracy: 0.9893 - val_loss: 0.1974 - val_accuracy: 0.9520\n",
            "Epoch 49/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.1994 - val_accuracy: 0.9520\n",
            "Epoch 50/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0327 - accuracy: 0.9938 - val_loss: 0.1906 - val_accuracy: 0.9493\n",
            "Epoch 51/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0399 - accuracy: 0.9920 - val_loss: 0.1952 - val_accuracy: 0.9333\n",
            "Epoch 52/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0439 - accuracy: 0.9929 - val_loss: 0.1990 - val_accuracy: 0.9440\n",
            "Epoch 53/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0476 - accuracy: 0.9876 - val_loss: 0.1947 - val_accuracy: 0.9520\n",
            "Epoch 54/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0351 - accuracy: 0.9920 - val_loss: 0.1913 - val_accuracy: 0.9520\n",
            "Epoch 55/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0540 - accuracy: 0.9884 - val_loss: 0.2137 - val_accuracy: 0.9467\n",
            "Epoch 56/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0447 - accuracy: 0.9893 - val_loss: 0.2089 - val_accuracy: 0.9493\n",
            "Epoch 57/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.1938 - val_accuracy: 0.9520\n",
            "Epoch 58/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0362 - accuracy: 0.9929 - val_loss: 0.1942 - val_accuracy: 0.9520\n",
            "Epoch 59/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0273 - accuracy: 0.9938 - val_loss: 0.1989 - val_accuracy: 0.9520\n",
            "Epoch 60/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0267 - accuracy: 0.9964 - val_loss: 0.1932 - val_accuracy: 0.9573\n",
            "Epoch 61/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 0.1913 - val_accuracy: 0.9547\n",
            "Epoch 62/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0302 - accuracy: 0.9911 - val_loss: 0.2277 - val_accuracy: 0.9520\n",
            "Epoch 63/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0295 - accuracy: 0.9929 - val_loss: 0.2217 - val_accuracy: 0.9493\n",
            "Epoch 64/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0205 - accuracy: 0.9964 - val_loss: 0.2051 - val_accuracy: 0.9520\n",
            "Epoch 65/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.2261 - val_accuracy: 0.9493\n",
            "Epoch 66/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.2202 - val_accuracy: 0.9467\n",
            "Epoch 67/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.2169 - val_accuracy: 0.9547\n",
            "Epoch 68/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0440 - accuracy: 0.9911 - val_loss: 0.2396 - val_accuracy: 0.9440\n",
            "Epoch 69/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0264 - accuracy: 0.9947 - val_loss: 0.2138 - val_accuracy: 0.9467\n",
            "Epoch 70/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.2473 - val_accuracy: 0.9467\n",
            "Epoch 71/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0188 - accuracy: 0.9964 - val_loss: 0.2373 - val_accuracy: 0.9493\n",
            "Epoch 72/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0134 - accuracy: 0.9991 - val_loss: 0.2125 - val_accuracy: 0.9547\n",
            "Epoch 73/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.2078 - val_accuracy: 0.9493\n",
            "Epoch 74/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.2109 - val_accuracy: 0.9520\n",
            "Epoch 75/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0363 - accuracy: 0.9911 - val_loss: 0.2120 - val_accuracy: 0.9413\n",
            "Epoch 76/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.2220 - val_accuracy: 0.9467\n",
            "Epoch 77/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0252 - accuracy: 0.9982 - val_loss: 0.1900 - val_accuracy: 0.9493\n",
            "Epoch 78/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.2184 - val_accuracy: 0.9493\n",
            "Epoch 79/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.2004 - val_accuracy: 0.9547\n",
            "Epoch 80/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0270 - accuracy: 0.9964 - val_loss: 0.2178 - val_accuracy: 0.9467\n",
            "Epoch 81/300\n",
            "1125/1125 [==============================] - 0s 332us/step - loss: 0.0203 - accuracy: 0.9964 - val_loss: 0.2146 - val_accuracy: 0.9493\n",
            "Epoch 82/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0206 - accuracy: 0.9964 - val_loss: 0.2310 - val_accuracy: 0.9493\n",
            "Epoch 83/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0174 - accuracy: 0.9973 - val_loss: 0.2363 - val_accuracy: 0.9467\n",
            "Epoch 84/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.2162 - val_accuracy: 0.9520\n",
            "Epoch 85/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 0.2113 - val_accuracy: 0.9573\n",
            "Epoch 86/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.2222 - val_accuracy: 0.9493\n",
            "Epoch 87/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.2279 - val_accuracy: 0.9547\n",
            "Epoch 88/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.2173 - val_accuracy: 0.9520\n",
            "Epoch 89/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.2109 - val_accuracy: 0.9493\n",
            "Epoch 90/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.2302 - val_accuracy: 0.9467\n",
            "Epoch 91/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.2321 - val_accuracy: 0.9467\n",
            "Epoch 92/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.2150 - val_accuracy: 0.9520\n",
            "Epoch 93/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0290 - accuracy: 0.9956 - val_loss: 0.2014 - val_accuracy: 0.9573\n",
            "Epoch 94/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.2075 - val_accuracy: 0.9493\n",
            "Epoch 95/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.2363 - val_accuracy: 0.9413\n",
            "Epoch 96/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0306 - accuracy: 0.9911 - val_loss: 0.2242 - val_accuracy: 0.9547\n",
            "Epoch 97/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0258 - accuracy: 0.9964 - val_loss: 0.2355 - val_accuracy: 0.9520\n",
            "Epoch 98/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.2252 - val_accuracy: 0.9547\n",
            "Epoch 99/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.2612 - val_accuracy: 0.9440\n",
            "Epoch 100/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 0.1930 - val_accuracy: 0.9547\n",
            "Epoch 101/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.0175 - accuracy: 0.9964 - val_loss: 0.2208 - val_accuracy: 0.9627\n",
            "Epoch 102/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0186 - accuracy: 0.9973 - val_loss: 0.2301 - val_accuracy: 0.9573\n",
            "Epoch 103/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.2172 - val_accuracy: 0.9600\n",
            "Epoch 104/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.2171 - val_accuracy: 0.9573\n",
            "Epoch 105/300\n",
            "1125/1125 [==============================] - 0s 300us/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.2343 - val_accuracy: 0.9440\n",
            "Epoch 106/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.2152 - val_accuracy: 0.9520\n",
            "Epoch 107/300\n",
            "1125/1125 [==============================] - 0s 296us/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.2306 - val_accuracy: 0.9493\n",
            "Epoch 108/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9440\n",
            "Epoch 109/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.2009 - val_accuracy: 0.9440\n",
            "Epoch 110/300\n",
            "1125/1125 [==============================] - 0s 298us/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.2196 - val_accuracy: 0.9467\n",
            "Epoch 111/300\n",
            "1125/1125 [==============================] - 0s 295us/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.2293 - val_accuracy: 0.9520\n",
            "Epoch 112/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.2247 - val_accuracy: 0.9520\n",
            "Epoch 113/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.1987 - val_accuracy: 0.9547\n",
            "Epoch 114/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.2397 - val_accuracy: 0.9547\n",
            "Epoch 115/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.0138 - accuracy: 0.9938 - val_loss: 0.2291 - val_accuracy: 0.9547\n",
            "Epoch 116/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.2168 - val_accuracy: 0.9493\n",
            "Epoch 117/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.2114 - val_accuracy: 0.9600\n",
            "Epoch 118/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.2280 - val_accuracy: 0.9493\n",
            "Epoch 119/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.2229 - val_accuracy: 0.9520\n",
            "Epoch 120/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.2475 - val_accuracy: 0.9520\n",
            "Epoch 121/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0199 - accuracy: 0.9964 - val_loss: 0.2474 - val_accuracy: 0.9493\n",
            "Epoch 122/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.2196 - val_accuracy: 0.9547\n",
            "Epoch 123/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0271 - accuracy: 0.9947 - val_loss: 0.2628 - val_accuracy: 0.9413\n",
            "Epoch 124/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.2231 - val_accuracy: 0.9520\n",
            "Epoch 125/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.2397 - val_accuracy: 0.9493\n",
            "Epoch 126/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.2429 - val_accuracy: 0.9467\n",
            "Epoch 127/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.2734 - val_accuracy: 0.9360\n",
            "Epoch 128/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.2376 - val_accuracy: 0.9520\n",
            "Epoch 129/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.2262 - val_accuracy: 0.9467\n",
            "Epoch 130/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.2485 - val_accuracy: 0.9413\n",
            "Epoch 131/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.2009 - val_accuracy: 0.9547\n",
            "Epoch 132/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.2250 - val_accuracy: 0.9413\n",
            "Epoch 133/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.0355 - accuracy: 0.9911 - val_loss: 0.2439 - val_accuracy: 0.9413\n",
            "Epoch 134/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0162 - accuracy: 0.9973 - val_loss: 0.2311 - val_accuracy: 0.9493\n",
            "Epoch 135/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.2150 - val_accuracy: 0.9600\n",
            "Epoch 136/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.2390 - val_accuracy: 0.9493\n",
            "Epoch 137/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.2409 - val_accuracy: 0.9440\n",
            "Epoch 138/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.2477 - val_accuracy: 0.9440\n",
            "Epoch 139/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.2323 - val_accuracy: 0.9493\n",
            "Epoch 140/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.2286 - val_accuracy: 0.9467\n",
            "Epoch 141/300\n",
            "1125/1125 [==============================] - 0s 300us/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.2373 - val_accuracy: 0.9440\n",
            "Epoch 142/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.2651 - val_accuracy: 0.9493\n",
            "Epoch 143/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.2703 - val_accuracy: 0.9467\n",
            "Epoch 144/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9440\n",
            "Epoch 145/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.2616 - val_accuracy: 0.9493\n",
            "Epoch 146/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.2746 - val_accuracy: 0.9493\n",
            "Epoch 147/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.2522 - val_accuracy: 0.9493\n",
            "Epoch 148/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.2430 - val_accuracy: 0.9440\n",
            "Epoch 149/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.2354 - val_accuracy: 0.9387\n",
            "Epoch 150/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.2306 - val_accuracy: 0.9520\n",
            "Epoch 151/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.2076 - val_accuracy: 0.9600\n",
            "Epoch 152/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.2363 - val_accuracy: 0.9493\n",
            "Epoch 153/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1892 - val_accuracy: 0.9600\n",
            "Epoch 154/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.2295 - val_accuracy: 0.9547\n",
            "Epoch 155/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.2316 - val_accuracy: 0.9467\n",
            "Epoch 156/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.2188 - val_accuracy: 0.9520\n",
            "Epoch 157/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.2090 - val_accuracy: 0.9600\n",
            "Epoch 158/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.2157 - val_accuracy: 0.9600\n",
            "Epoch 159/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0182 - accuracy: 0.9956 - val_loss: 0.2164 - val_accuracy: 0.9547\n",
            "Epoch 160/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.2784 - val_accuracy: 0.9333\n",
            "Epoch 161/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.2581 - val_accuracy: 0.9413\n",
            "Epoch 162/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.2555 - val_accuracy: 0.9493\n",
            "Epoch 163/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.2613 - val_accuracy: 0.9387\n",
            "Epoch 164/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0153 - accuracy: 0.9982 - val_loss: 0.2602 - val_accuracy: 0.9387\n",
            "Epoch 165/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.2676 - val_accuracy: 0.9493\n",
            "Epoch 166/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.2179 - val_accuracy: 0.9573\n",
            "Epoch 167/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9520\n",
            "Epoch 168/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9493\n",
            "Epoch 169/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0054 - accuracy: 0.9973 - val_loss: 0.2257 - val_accuracy: 0.9547\n",
            "Epoch 170/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.2157 - val_accuracy: 0.9493\n",
            "Epoch 171/300\n",
            "1125/1125 [==============================] - 0s 332us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2286 - val_accuracy: 0.9493\n",
            "Epoch 172/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9547\n",
            "Epoch 173/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9520\n",
            "Epoch 174/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0060 - accuracy: 0.9973 - val_loss: 0.2754 - val_accuracy: 0.9440\n",
            "Epoch 175/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9493\n",
            "Epoch 176/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.2356 - val_accuracy: 0.9493\n",
            "Epoch 177/300\n",
            "1125/1125 [==============================] - 0s 297us/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.2258 - val_accuracy: 0.9520\n",
            "Epoch 178/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.2147 - val_accuracy: 0.9547\n",
            "Epoch 179/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.2326 - val_accuracy: 0.9493\n",
            "Epoch 180/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.2417 - val_accuracy: 0.9493\n",
            "Epoch 181/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.2301 - val_accuracy: 0.9627\n",
            "Epoch 182/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 0.2288 - val_accuracy: 0.9627\n",
            "Epoch 183/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.2803 - val_accuracy: 0.9440\n",
            "Epoch 184/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0088 - accuracy: 0.9964 - val_loss: 0.2733 - val_accuracy: 0.9493\n",
            "Epoch 185/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.2487 - val_accuracy: 0.9600\n",
            "Epoch 186/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.2734 - val_accuracy: 0.9573\n",
            "Epoch 187/300\n",
            "1125/1125 [==============================] - 0s 304us/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2516 - val_accuracy: 0.9547\n",
            "Epoch 188/300\n",
            "1125/1125 [==============================] - 0s 302us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.2447 - val_accuracy: 0.9467\n",
            "Epoch 189/300\n",
            "1125/1125 [==============================] - 0s 299us/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.2292 - val_accuracy: 0.9547\n",
            "Epoch 190/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9653\n",
            "Epoch 191/300\n",
            "1125/1125 [==============================] - 0s 305us/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.2322 - val_accuracy: 0.9600\n",
            "Epoch 192/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.2134 - val_accuracy: 0.9627\n",
            "Epoch 193/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.2315 - val_accuracy: 0.9573\n",
            "Epoch 194/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0164 - accuracy: 0.9982 - val_loss: 0.2835 - val_accuracy: 0.9493\n",
            "Epoch 195/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.2444 - val_accuracy: 0.9467\n",
            "Epoch 196/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.2217 - val_accuracy: 0.9520\n",
            "Epoch 197/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 0.2432 - val_accuracy: 0.9440\n",
            "Epoch 198/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.2583 - val_accuracy: 0.9413\n",
            "Epoch 199/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0108 - accuracy: 0.9956 - val_loss: 0.2742 - val_accuracy: 0.9440\n",
            "Epoch 200/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.2592 - val_accuracy: 0.9573\n",
            "Epoch 201/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.2525 - val_accuracy: 0.9493\n",
            "Epoch 202/300\n",
            "1125/1125 [==============================] - 0s 314us/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.2689 - val_accuracy: 0.9440\n",
            "Epoch 203/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.2213 - val_accuracy: 0.9467\n",
            "Epoch 204/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0068 - accuracy: 0.9973 - val_loss: 0.2607 - val_accuracy: 0.9440\n",
            "Epoch 205/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.2613 - val_accuracy: 0.9520\n",
            "Epoch 206/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.2660 - val_accuracy: 0.9547\n",
            "Epoch 207/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0179 - accuracy: 0.9973 - val_loss: 0.2631 - val_accuracy: 0.9467\n",
            "Epoch 208/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2573 - val_accuracy: 0.9493\n",
            "Epoch 209/300\n",
            "1125/1125 [==============================] - 0s 332us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2482 - val_accuracy: 0.9467\n",
            "Epoch 210/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0102 - accuracy: 0.9956 - val_loss: 0.2544 - val_accuracy: 0.9440\n",
            "Epoch 211/300\n",
            "1125/1125 [==============================] - 0s 339us/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.2117 - val_accuracy: 0.9573\n",
            "Epoch 212/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.2508 - val_accuracy: 0.9493\n",
            "Epoch 213/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.2779 - val_accuracy: 0.9520\n",
            "Epoch 214/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.2715 - val_accuracy: 0.9520\n",
            "Epoch 215/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0182 - accuracy: 0.9929 - val_loss: 0.2705 - val_accuracy: 0.9467\n",
            "Epoch 216/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.2614 - val_accuracy: 0.9440\n",
            "Epoch 217/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.2578 - val_accuracy: 0.9440\n",
            "Epoch 218/300\n",
            "1125/1125 [==============================] - 0s 312us/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.2548 - val_accuracy: 0.9440\n",
            "Epoch 219/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.2507 - val_accuracy: 0.9440\n",
            "Epoch 220/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.2337 - val_accuracy: 0.9440\n",
            "Epoch 221/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.2332 - val_accuracy: 0.9467\n",
            "Epoch 222/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9467\n",
            "Epoch 223/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.2257 - val_accuracy: 0.9547\n",
            "Epoch 224/300\n",
            "1125/1125 [==============================] - 0s 332us/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.2312 - val_accuracy: 0.9467\n",
            "Epoch 225/300\n",
            "1125/1125 [==============================] - 0s 344us/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.2228 - val_accuracy: 0.9520\n",
            "Epoch 226/300\n",
            "1125/1125 [==============================] - 0s 311us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2366 - val_accuracy: 0.9467\n",
            "Epoch 227/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9440\n",
            "Epoch 228/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9440\n",
            "Epoch 229/300\n",
            "1125/1125 [==============================] - 0s 301us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9440\n",
            "Epoch 230/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.2392 - val_accuracy: 0.9467\n",
            "Epoch 231/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9493\n",
            "Epoch 232/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2379 - val_accuracy: 0.9520\n",
            "Epoch 233/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0071 - accuracy: 0.9964 - val_loss: 0.2233 - val_accuracy: 0.9547\n",
            "Epoch 234/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.2510 - val_accuracy: 0.9440\n",
            "Epoch 235/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2284 - val_accuracy: 0.9573\n",
            "Epoch 236/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.2215 - val_accuracy: 0.9627\n",
            "Epoch 237/300\n",
            "1125/1125 [==============================] - 0s 329us/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.2217 - val_accuracy: 0.9600\n",
            "Epoch 238/300\n",
            "1125/1125 [==============================] - 0s 344us/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.2182 - val_accuracy: 0.9520\n",
            "Epoch 239/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9520\n",
            "Epoch 240/300\n",
            "1125/1125 [==============================] - 0s 316us/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.2119 - val_accuracy: 0.9520\n",
            "Epoch 241/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.2230 - val_accuracy: 0.9627\n",
            "Epoch 242/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.2153 - val_accuracy: 0.9627\n",
            "Epoch 243/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.2627 - val_accuracy: 0.9547\n",
            "Epoch 244/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.2150 - val_accuracy: 0.9600\n",
            "Epoch 245/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.2105 - val_accuracy: 0.9573\n",
            "Epoch 246/300\n",
            "1125/1125 [==============================] - 0s 306us/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.2076 - val_accuracy: 0.9600\n",
            "Epoch 247/300\n",
            "1125/1125 [==============================] - 0s 307us/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 0.2114 - val_accuracy: 0.9547\n",
            "Epoch 248/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.2307 - val_accuracy: 0.9520\n",
            "Epoch 249/300\n",
            "1125/1125 [==============================] - 0s 308us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9520\n",
            "Epoch 250/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.2214 - val_accuracy: 0.9600\n",
            "Epoch 251/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.2219 - val_accuracy: 0.9520\n",
            "Epoch 252/300\n",
            "1125/1125 [==============================] - 0s 309us/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2137 - val_accuracy: 0.9547\n",
            "Epoch 253/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.2178 - val_accuracy: 0.9493\n",
            "Epoch 254/300\n",
            "1125/1125 [==============================] - 0s 335us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9520\n",
            "Epoch 255/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.2134 - val_accuracy: 0.9547\n",
            "Epoch 256/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2203 - val_accuracy: 0.9573\n",
            "Epoch 257/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.2172 - val_accuracy: 0.9547\n",
            "Epoch 258/300\n",
            "1125/1125 [==============================] - 0s 338us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2201 - val_accuracy: 0.9547\n",
            "Epoch 259/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 0.2534 - val_accuracy: 0.9573\n",
            "Epoch 260/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.2757 - val_accuracy: 0.9520\n",
            "Epoch 261/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.2469 - val_accuracy: 0.9547\n",
            "Epoch 262/300\n",
            "1125/1125 [==============================] - 0s 313us/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.2456 - val_accuracy: 0.9520\n",
            "Epoch 263/300\n",
            "1125/1125 [==============================] - 0s 334us/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.2610 - val_accuracy: 0.9520\n",
            "Epoch 264/300\n",
            "1125/1125 [==============================] - 0s 303us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9573\n",
            "Epoch 265/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9573\n",
            "Epoch 266/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.2438 - val_accuracy: 0.9547\n",
            "Epoch 267/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9573\n",
            "Epoch 268/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 8.7650e-04 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9600\n",
            "Epoch 269/300\n",
            "1125/1125 [==============================] - 0s 337us/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.2023 - val_accuracy: 0.9600\n",
            "Epoch 270/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.2137 - val_accuracy: 0.9573\n",
            "Epoch 271/300\n",
            "1125/1125 [==============================] - 0s 319us/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.2205 - val_accuracy: 0.9520\n",
            "Epoch 272/300\n",
            "1125/1125 [==============================] - 0s 310us/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 0.2351 - val_accuracy: 0.9493\n",
            "Epoch 273/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.2235 - val_accuracy: 0.9467\n",
            "Epoch 274/300\n",
            "1125/1125 [==============================] - 0s 318us/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.2368 - val_accuracy: 0.9520\n",
            "Epoch 275/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2365 - val_accuracy: 0.9547\n",
            "Epoch 276/300\n",
            "1125/1125 [==============================] - 0s 328us/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.2275 - val_accuracy: 0.9520\n",
            "Epoch 277/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.2498 - val_accuracy: 0.9493\n",
            "Epoch 278/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9547\n",
            "Epoch 279/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 0.2439 - val_accuracy: 0.9520\n",
            "Epoch 280/300\n",
            "1125/1125 [==============================] - 0s 323us/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.2579 - val_accuracy: 0.9467\n",
            "Epoch 281/300\n",
            "1125/1125 [==============================] - 0s 326us/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.2780 - val_accuracy: 0.9520\n",
            "Epoch 282/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.2736 - val_accuracy: 0.9493\n",
            "Epoch 283/300\n",
            "1125/1125 [==============================] - 0s 325us/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.3017 - val_accuracy: 0.9467\n",
            "Epoch 284/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.2941 - val_accuracy: 0.9520\n",
            "Epoch 285/300\n",
            "1125/1125 [==============================] - 0s 330us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9520\n",
            "Epoch 286/300\n",
            "1125/1125 [==============================] - 0s 320us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9520\n",
            "Epoch 287/300\n",
            "1125/1125 [==============================] - 0s 322us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9547\n",
            "Epoch 288/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9520\n",
            "Epoch 289/300\n",
            "1125/1125 [==============================] - 0s 336us/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.3171 - val_accuracy: 0.9493\n",
            "Epoch 290/300\n",
            "1125/1125 [==============================] - 0s 338us/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.2772 - val_accuracy: 0.9467\n",
            "Epoch 291/300\n",
            "1125/1125 [==============================] - 0s 341us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9520\n",
            "Epoch 292/300\n",
            "1125/1125 [==============================] - 0s 317us/step - loss: 8.4757e-04 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9493\n",
            "Epoch 293/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9493\n",
            "Epoch 294/300\n",
            "1125/1125 [==============================] - 0s 321us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9467\n",
            "Epoch 295/300\n",
            "1125/1125 [==============================] - 0s 331us/step - loss: 9.1349e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9467\n",
            "Epoch 296/300\n",
            "1125/1125 [==============================] - 0s 324us/step - loss: 8.2764e-04 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9467\n",
            "Epoch 297/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0080 - accuracy: 0.9991 - val_loss: 0.2561 - val_accuracy: 0.9467\n",
            "Epoch 298/300\n",
            "1125/1125 [==============================] - 0s 327us/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.2389 - val_accuracy: 0.9520\n",
            "Epoch 299/300\n",
            "1125/1125 [==============================] - 0s 333us/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.2658 - val_accuracy: 0.9440\n",
            "Epoch 300/300\n",
            "1125/1125 [==============================] - 0s 315us/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.3038 - val_accuracy: 0.9333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dGpexZQocxWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bafc8eb2-acfd-4d8a-a998-a1fceb93b861"
      },
      "source": [
        "plt.plot(classify.history['loss'])\n",
        "plt.plot(classify.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scuaSKiTcxWm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3f2d03de-547e-4e7d-b085-0d2993bf2986"
      },
      "source": [
        "plt.plot(classify.history['accuracy'])\n",
        "plt.plot(classify.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e1ds6rGWlmb",
        "colab_type": "text"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLqHm57WH1qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "263b5cca-7545-4642-f3a4-8b887c2240b7"
      },
      "source": [
        "import librosa\n",
        "from collections import Counter\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset_pred=pd.DataFrame(columns=columns)\n",
        "songname='/content/Nithyasree Mahadevan - Sabha Pathiku.mp3'\n",
        "y, sr = librosa.load(songname, mono=True)\n",
        "dur = librosa.get_duration(y=y, sr=sr)\n",
        "off=0\n",
        "if dur > 300:\n",
        "    for i in range(10):\n",
        "                      x, sr = librosa.load(songname, mono=True,offset=off,duration=30)\n",
        "                      rmse = librosa.feature.rmse(y=x)[0]\n",
        "                      chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "                      spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "                      spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "                      rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "                      zcr = librosa.feature.zero_crossing_rate(x)\n",
        "                      mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "                      filename = songname+'-'+str(i+1)\n",
        "                      data=[i,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "                      dataseries = pd.Series(data, index = dataset_pred.columns)\n",
        "                      dataset_pred = dataset_pred.append(dataseries, ignore_index=True)\n",
        "                      print(filename+\" added\" + 'dur '+str(dur))\n",
        "                      if i in range(0,3):\n",
        "                        off=off+30\n",
        "                      if i in range(3,7):\n",
        "                        off=(dur/10)*i\n",
        "                      if i in range(7,10):\n",
        "                        off= dur - ((10-i)*30)\n",
        "\n",
        "else:\n",
        "    for i in range(10):\n",
        "                      x, sr = librosa.load(songname, mono=True,offset=off,duration=(dur/10))\n",
        "                      rmse = librosa.feature.rmse(y=x)[0]\n",
        "                      chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "                      spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "                      spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "                      rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "                      zcr = librosa.feature.zero_crossing_rate(x)\n",
        "                      mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "                      filename = songname+'-'+str(i+1)\n",
        "                      data=[i,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "                      dataseries = pd.Series(data, index = dataset_pred.columns)\n",
        "                      dataset_pred = dataset_pred.append(dataseries, ignore_index=True)\n",
        "                      print(filename+\" added(small)\"+'dur '+str(dur))\n",
        "                      off=(dur/10)*(i)\n",
        "print(dataset_pred)\n",
        "\n",
        "\n",
        "example = scaler.transform(np.array(dataset_pred.iloc[:,:], dtype = float))\n",
        "example = np.reshape(example, (example.shape[0], 1, example.shape[1]))\n",
        "preds = model.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],Y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "\n",
        "print(preds)\n",
        "\n",
        "print(best_preds)\n",
        "b=Counter(best_preds)\n",
        "print(b.most_common(1)[0][0])\n",
        "raga_no=b.most_common(1)[0][0]\n",
        "print(\"Raga for this song is : \"+raganame[raga_no][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-1 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-2 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-3 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-4 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-5 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-6 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-7 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-8 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-9 addeddur 1686.3085714285714\n",
            "/content/Nithyasree Mahadevan - Sabha Pathiku.mp3-10 addeddur 1686.3085714285714\n",
            "   ind      rmse  chroma_stft  ...     mfcc17    mfcc18    mfcc19\n",
            "0  0.0  0.031171     0.261717  ...   7.061930  1.720514  0.832533\n",
            "1  1.0  0.036954     0.226733  ...   7.187535 -5.456522  1.334473\n",
            "2  2.0  0.039831     0.250780  ...   6.532062 -3.385223  0.311007\n",
            "3  3.0  0.046600     0.281109  ...   8.000922  0.245888  5.268905\n",
            "4  4.0  0.056559     0.265544  ...  12.567346  0.107281  4.081874\n",
            "5  5.0  0.034024     0.200534  ...  10.076434  5.502593  2.524945\n",
            "6  6.0  0.078632     0.311926  ...   1.681209 -6.080146  5.253635\n",
            "7  7.0  0.070701     0.302527  ...   5.219564 -2.462157  3.707945\n",
            "8  8.0  0.106073     0.360255  ...   1.936582 -4.493164  1.747500\n",
            "9  9.0  0.080791     0.294870  ...   5.202914 -6.197733  1.056545\n",
            "\n",
            "[10 rows x 27 columns]\n",
            "[[2.4159721e-09 4.0307011e-02 1.1063236e-09 3.7692139e-06 6.9358102e-05\n",
            "  5.8638012e-08 9.5961964e-01 6.2510330e-10 2.6230433e-07 4.0307024e-09]\n",
            " [2.5964904e-09 1.9576924e-01 2.2673616e-09 3.7215698e-06 8.5547792e-05\n",
            "  8.4687393e-08 8.0414099e-01 9.4123886e-10 4.3882915e-07 5.1360178e-09]\n",
            " [2.5895175e-09 5.1591989e-02 1.3710891e-09 2.8805091e-06 7.9427024e-05\n",
            "  4.9555609e-08 9.4832534e-01 5.6287097e-10 2.4461244e-07 3.5942977e-09]\n",
            " [1.0430811e-09 7.3590025e-04 2.6942623e-10 1.5797252e-06 1.1367266e-05\n",
            "  7.4007755e-09 9.9925119e-01 7.2098723e-11 2.9683077e-08 3.9951514e-10]\n",
            " [2.1037665e-09 2.8495783e-02 8.7669605e-10 3.1046013e-06 3.4257853e-05\n",
            "  2.0602339e-08 9.7146666e-01 3.4156211e-10 1.0804722e-07 2.3963571e-09]\n",
            " [3.7929290e-10 9.6296293e-01 7.6688134e-10 6.1206229e-06 5.7382672e-06\n",
            "  3.1070176e-08 3.7024986e-02 3.1714509e-10 1.7952267e-07 1.9879440e-09]\n",
            " [3.5063450e-09 4.4911513e-01 3.4677958e-09 2.8587663e-06 6.5912223e-05\n",
            "  7.6483467e-08 5.5081499e-01 9.0211466e-10 9.5275169e-07 1.0168205e-08]\n",
            " [3.1899603e-09 3.7873992e-01 3.0579927e-09 3.4659615e-06 5.1493691e-05\n",
            "  6.4886329e-08 6.2120420e-01 8.0945795e-10 7.7626675e-07 7.5739912e-09]\n",
            " [7.2924196e-09 1.7703302e-01 1.2506139e-09 1.0307953e-05 3.1523930e-05\n",
            "  2.7535743e-08 8.2292485e-01 4.4597118e-10 3.1560538e-07 1.5330977e-08]\n",
            " [7.0350747e-10 9.4634485e-01 6.1475580e-10 1.5508771e-06 5.0365716e-06\n",
            "  9.3606181e-09 5.3648353e-02 2.3288502e-10 1.6983279e-07 3.1675065e-09]]\n",
            "[6 6 6 6 6 1 6 6 6 1]\n",
            "6\n",
            "Raga for this song is : bhairavi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBx434wO2JPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66f20356-9f2f-45b3-828b-dc44a6720b96"
      },
      "source": [
        "print(raganame)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Purvikalyani', 0), ('abhogi', 1), ('ananda bhairavi', 2), ('atana', 3), ('begada', 4), ('behag', 5), ('bhairavi', 6), ('bilahari', 7), ('hamsadhvani', 8), ('hindolam', 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb5rlMcAQfWM",
        "colab_type": "text"
      },
      "source": [
        "# 20 RAgas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2xSeYJPbQWQI",
        "colab": {}
      },
      "source": [
        "data3 = pd.read_csv('dataset-big.csv')\n",
        "# Dropping unneccesary columns\n",
        "data3 = data3.drop(['filename'],axis=1)\n",
        "#Encoding the Labels\n",
        "raga_list3 = data3.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "Y3 = encoder.fit_transform(raga_list3)\n",
        "#Scaling the Feature columns\n",
        "scaler = StandardScaler()\n",
        "X3 = scaler.fit_transform(np.array(data3.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, Y3, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q0-ESm45Qrit"
      },
      "source": [
        "#ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4ikLUdH6Qriu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "eac69865-41bc-451b-e805-519b32103b5d"
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(layers.Dense(256, activation='relu', input_shape=(X_train3.shape[1],)))\n",
        "model3.add(layers.Dense(128, activation='relu'))\n",
        "model3.add(layers.Dense(64, activation='relu'))\n",
        "model3.add(layers.Dense(20, activation='softmax'))\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 256)               7168      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 20)                1300      \n",
            "=================================================================\n",
            "Total params: 49,620\n",
            "Trainable params: 49,620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0HLHlOVOQriw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c7f0476-1606-45d6-987b-1a52213e9d52"
      },
      "source": [
        "classifier3 = model3.fit(X_train3, y_train3,batch_size=128, epochs=500, validation_data=(X_test3,y_test3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 2.8882 - accuracy: 0.1118 - val_loss: 2.7066 - val_accuracy: 0.1792\n",
            "Epoch 2/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4708 - accuracy: 0.2580 - val_loss: 2.2235 - val_accuracy: 0.3000\n",
            "Epoch 3/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9647 - accuracy: 0.3819 - val_loss: 1.8036 - val_accuracy: 0.4146\n",
            "Epoch 4/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5707 - accuracy: 0.5035 - val_loss: 1.5019 - val_accuracy: 0.5156\n",
            "Epoch 5/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2874 - accuracy: 0.6003 - val_loss: 1.3130 - val_accuracy: 0.5688\n",
            "Epoch 6/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.0923 - accuracy: 0.6507 - val_loss: 1.1373 - val_accuracy: 0.6208\n",
            "Epoch 7/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.7031 - val_loss: 1.0615 - val_accuracy: 0.6375\n",
            "Epoch 8/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8235 - accuracy: 0.7455 - val_loss: 0.9789 - val_accuracy: 0.6812\n",
            "Epoch 9/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 0.7830 - val_loss: 0.8948 - val_accuracy: 0.6854\n",
            "Epoch 10/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.8087 - val_loss: 0.8259 - val_accuracy: 0.7104\n",
            "Epoch 11/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.8292 - val_loss: 0.7565 - val_accuracy: 0.7417\n",
            "Epoch 12/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.8448 - val_loss: 0.7803 - val_accuracy: 0.7177\n",
            "Epoch 13/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.8639 - val_loss: 0.7138 - val_accuracy: 0.7521\n",
            "Epoch 14/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8802 - val_loss: 0.6526 - val_accuracy: 0.7771\n",
            "Epoch 15/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.9003 - val_loss: 0.6415 - val_accuracy: 0.7781\n",
            "Epoch 16/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.9052 - val_loss: 0.6537 - val_accuracy: 0.7760\n",
            "Epoch 17/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.9042 - val_loss: 0.6021 - val_accuracy: 0.7948\n",
            "Epoch 18/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3063 - accuracy: 0.9257 - val_loss: 0.5740 - val_accuracy: 0.7969\n",
            "Epoch 19/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.9333 - val_loss: 0.5469 - val_accuracy: 0.8208\n",
            "Epoch 20/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.9389 - val_loss: 0.5759 - val_accuracy: 0.7990\n",
            "Epoch 21/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.9438 - val_loss: 0.5415 - val_accuracy: 0.8146\n",
            "Epoch 22/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9521 - val_loss: 0.5263 - val_accuracy: 0.8313\n",
            "Epoch 23/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.9479 - val_loss: 0.5237 - val_accuracy: 0.8302\n",
            "Epoch 24/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1895 - accuracy: 0.9615 - val_loss: 0.5166 - val_accuracy: 0.8354\n",
            "Epoch 25/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9705 - val_loss: 0.4773 - val_accuracy: 0.8500\n",
            "Epoch 26/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9708 - val_loss: 0.4869 - val_accuracy: 0.8333\n",
            "Epoch 27/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9753 - val_loss: 0.4749 - val_accuracy: 0.8458\n",
            "Epoch 28/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9806 - val_loss: 0.4539 - val_accuracy: 0.8448\n",
            "Epoch 29/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.9840 - val_loss: 0.4809 - val_accuracy: 0.8427\n",
            "Epoch 30/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9854 - val_loss: 0.4780 - val_accuracy: 0.8583\n",
            "Epoch 31/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9882 - val_loss: 0.4495 - val_accuracy: 0.8531\n",
            "Epoch 32/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9899 - val_loss: 0.4460 - val_accuracy: 0.8594\n",
            "Epoch 33/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9889 - val_loss: 0.4478 - val_accuracy: 0.8531\n",
            "Epoch 34/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9882 - val_loss: 0.4424 - val_accuracy: 0.8594\n",
            "Epoch 35/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9920 - val_loss: 0.4317 - val_accuracy: 0.8646\n",
            "Epoch 36/500\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9906 - val_loss: 0.4474 - val_accuracy: 0.8646\n",
            "Epoch 37/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9948 - val_loss: 0.4367 - val_accuracy: 0.8625\n",
            "Epoch 38/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9934 - val_loss: 0.4508 - val_accuracy: 0.8635\n",
            "Epoch 39/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9941 - val_loss: 0.4284 - val_accuracy: 0.8667\n",
            "Epoch 40/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9965 - val_loss: 0.4369 - val_accuracy: 0.8698\n",
            "Epoch 41/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9969 - val_loss: 0.4422 - val_accuracy: 0.8625\n",
            "Epoch 42/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9955 - val_loss: 0.4298 - val_accuracy: 0.8750\n",
            "Epoch 43/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9990 - val_loss: 0.4382 - val_accuracy: 0.8719\n",
            "Epoch 44/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9972 - val_loss: 0.4123 - val_accuracy: 0.8792\n",
            "Epoch 45/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9986 - val_loss: 0.4229 - val_accuracy: 0.8750\n",
            "Epoch 46/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9993 - val_loss: 0.4273 - val_accuracy: 0.8667\n",
            "Epoch 47/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9986 - val_loss: 0.4173 - val_accuracy: 0.8708\n",
            "Epoch 48/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9993 - val_loss: 0.4250 - val_accuracy: 0.8771\n",
            "Epoch 49/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9993 - val_loss: 0.4262 - val_accuracy: 0.8677\n",
            "Epoch 50/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9993 - val_loss: 0.4348 - val_accuracy: 0.8698\n",
            "Epoch 51/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9990 - val_loss: 0.4288 - val_accuracy: 0.8719\n",
            "Epoch 52/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9983 - val_loss: 0.4515 - val_accuracy: 0.8740\n",
            "Epoch 53/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9993 - val_loss: 0.4233 - val_accuracy: 0.8802\n",
            "Epoch 54/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9986 - val_loss: 0.4385 - val_accuracy: 0.8687\n",
            "Epoch 55/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9986 - val_loss: 0.4638 - val_accuracy: 0.8615\n",
            "Epoch 56/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9986 - val_loss: 0.4293 - val_accuracy: 0.8854\n",
            "Epoch 57/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9986 - val_loss: 0.4526 - val_accuracy: 0.8750\n",
            "Epoch 58/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9948 - val_loss: 0.5654 - val_accuracy: 0.8594\n",
            "Epoch 59/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9847 - val_loss: 0.5229 - val_accuracy: 0.8573\n",
            "Epoch 60/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9892 - val_loss: 0.4959 - val_accuracy: 0.8562\n",
            "Epoch 61/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9969 - val_loss: 0.4649 - val_accuracy: 0.8740\n",
            "Epoch 62/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9969 - val_loss: 0.4734 - val_accuracy: 0.8771\n",
            "Epoch 63/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9997 - val_loss: 0.4427 - val_accuracy: 0.8792\n",
            "Epoch 64/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8813\n",
            "Epoch 65/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9997 - val_loss: 0.4505 - val_accuracy: 0.8802\n",
            "Epoch 66/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9993 - val_loss: 0.4545 - val_accuracy: 0.8750\n",
            "Epoch 67/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.4338 - val_accuracy: 0.8813\n",
            "Epoch 68/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9997 - val_loss: 0.4413 - val_accuracy: 0.8823\n",
            "Epoch 69/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9997 - val_loss: 0.4360 - val_accuracy: 0.8833\n",
            "Epoch 70/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.8833\n",
            "Epoch 71/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9997 - val_loss: 0.4399 - val_accuracy: 0.8833\n",
            "Epoch 72/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.8865\n",
            "Epoch 73/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.8865\n",
            "Epoch 74/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.8833\n",
            "Epoch 75/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.8854\n",
            "Epoch 76/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.8813\n",
            "Epoch 77/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9990 - val_loss: 0.4474 - val_accuracy: 0.8813\n",
            "Epoch 78/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.8833\n",
            "Epoch 79/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.8865\n",
            "Epoch 80/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.8833\n",
            "Epoch 81/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.8885\n",
            "Epoch 82/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.8844\n",
            "Epoch 83/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.8844\n",
            "Epoch 84/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.8854\n",
            "Epoch 85/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.4643 - val_accuracy: 0.8823\n",
            "Epoch 86/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 0.4971 - val_accuracy: 0.8771\n",
            "Epoch 87/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.4871 - val_accuracy: 0.8792\n",
            "Epoch 88/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.8865\n",
            "Epoch 89/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.8854\n",
            "Epoch 90/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8865\n",
            "Epoch 91/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8896\n",
            "Epoch 92/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.8865\n",
            "Epoch 93/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.8844\n",
            "Epoch 94/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.8885\n",
            "Epoch 95/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.8844\n",
            "Epoch 96/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.4676 - val_accuracy: 0.8823\n",
            "Epoch 97/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.8813\n",
            "Epoch 98/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.4802 - val_accuracy: 0.8813\n",
            "Epoch 99/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.4710 - val_accuracy: 0.8844\n",
            "Epoch 100/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.8792\n",
            "Epoch 101/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.8823\n",
            "Epoch 102/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8854\n",
            "Epoch 103/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.8833\n",
            "Epoch 104/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.8906\n",
            "Epoch 105/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8875\n",
            "Epoch 106/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.8844\n",
            "Epoch 107/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.8896\n",
            "Epoch 108/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.8906\n",
            "Epoch 109/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.8865\n",
            "Epoch 110/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.8854\n",
            "Epoch 111/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.8875\n",
            "Epoch 112/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.8865\n",
            "Epoch 113/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.8906\n",
            "Epoch 114/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.8906\n",
            "Epoch 115/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.8885\n",
            "Epoch 116/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.8885\n",
            "Epoch 117/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.8885\n",
            "Epoch 118/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8896\n",
            "Epoch 119/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.8885\n",
            "Epoch 120/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8844\n",
            "Epoch 121/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8854\n",
            "Epoch 122/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8865\n",
            "Epoch 123/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.8833\n",
            "Epoch 124/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.8844\n",
            "Epoch 125/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8875\n",
            "Epoch 126/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8854\n",
            "Epoch 127/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.8885\n",
            "Epoch 128/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8854\n",
            "Epoch 129/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.8844\n",
            "Epoch 130/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.8885\n",
            "Epoch 131/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.8854\n",
            "Epoch 132/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8906\n",
            "Epoch 133/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.8854\n",
            "Epoch 134/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.8906\n",
            "Epoch 135/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.8865\n",
            "Epoch 136/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.8917\n",
            "Epoch 137/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8885\n",
            "Epoch 138/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.8854\n",
            "Epoch 139/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.8875\n",
            "Epoch 140/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.8865\n",
            "Epoch 141/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.8896\n",
            "Epoch 142/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8885\n",
            "Epoch 143/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8865\n",
            "Epoch 144/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8854\n",
            "Epoch 145/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.8885\n",
            "Epoch 146/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.8885\n",
            "Epoch 147/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.8865\n",
            "Epoch 148/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.8865\n",
            "Epoch 149/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8885\n",
            "Epoch 150/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.8885\n",
            "Epoch 151/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8865\n",
            "Epoch 152/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8885\n",
            "Epoch 153/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.8844\n",
            "Epoch 154/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.9252e-04 - accuracy: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.8875\n",
            "Epoch 155/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.6948e-04 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8854\n",
            "Epoch 156/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.4598e-04 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.8844\n",
            "Epoch 157/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.3289e-04 - accuracy: 1.0000 - val_loss: 0.5292 - val_accuracy: 0.8833\n",
            "Epoch 158/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.2648e-04 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.8854\n",
            "Epoch 159/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.0033e-04 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8854\n",
            "Epoch 160/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.7753e-04 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.8875\n",
            "Epoch 161/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.5392e-04 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8865\n",
            "Epoch 162/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.7455e-04 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.8885\n",
            "Epoch 163/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.5188e-04 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.8854\n",
            "Epoch 164/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.2061e-04 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.8875\n",
            "Epoch 165/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0251e-04 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.8865\n",
            "Epoch 166/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.8367e-04 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.8865\n",
            "Epoch 167/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.7676e-04 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.8865\n",
            "Epoch 168/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.4378e-04 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8865\n",
            "Epoch 169/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.4552e-04 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.8854\n",
            "Epoch 170/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.3321e-04 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8865\n",
            "Epoch 171/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 7.0978e-04 - accuracy: 1.0000 - val_loss: 0.5399 - val_accuracy: 0.8854\n",
            "Epoch 172/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.9574e-04 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.8885\n",
            "Epoch 173/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.9291e-04 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8885\n",
            "Epoch 174/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.7759e-04 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8854\n",
            "Epoch 175/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.6092e-04 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.8865\n",
            "Epoch 176/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.5326e-04 - accuracy: 1.0000 - val_loss: 0.5418 - val_accuracy: 0.8833\n",
            "Epoch 177/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.3438e-04 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.8854\n",
            "Epoch 178/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.3853e-04 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.8844\n",
            "Epoch 179/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2040e-04 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.8854\n",
            "Epoch 180/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9954e-04 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.8865\n",
            "Epoch 181/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9311e-04 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.8875\n",
            "Epoch 182/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8235e-04 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.8875\n",
            "Epoch 183/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8915e-04 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8885\n",
            "Epoch 184/500\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.8719e-04 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.8865\n",
            "Epoch 185/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8364e-04 - accuracy: 1.0000 - val_loss: 0.5526 - val_accuracy: 0.8865\n",
            "Epoch 186/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4862e-04 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.8844\n",
            "Epoch 187/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3536e-04 - accuracy: 1.0000 - val_loss: 0.5534 - val_accuracy: 0.8865\n",
            "Epoch 188/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2729e-04 - accuracy: 1.0000 - val_loss: 0.5559 - val_accuracy: 0.8854\n",
            "Epoch 189/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1229e-04 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.8865\n",
            "Epoch 190/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0194e-04 - accuracy: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.8823\n",
            "Epoch 191/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9755e-04 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8854\n",
            "Epoch 192/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9044e-04 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.8865\n",
            "Epoch 193/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8443e-04 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.8875\n",
            "Epoch 194/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.7343e-04 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.8833\n",
            "Epoch 195/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.7414e-04 - accuracy: 1.0000 - val_loss: 0.5624 - val_accuracy: 0.8854\n",
            "Epoch 196/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6338e-04 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.8896\n",
            "Epoch 197/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6009e-04 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.8865\n",
            "Epoch 198/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4859e-04 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.8854\n",
            "Epoch 199/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3755e-04 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.8823\n",
            "Epoch 200/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2437e-04 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.8865\n",
            "Epoch 201/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2458e-04 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.8854\n",
            "Epoch 202/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.1112e-04 - accuracy: 1.0000 - val_loss: 0.5677 - val_accuracy: 0.8854\n",
            "Epoch 203/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0810e-04 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.8865\n",
            "Epoch 204/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0564e-04 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.8844\n",
            "Epoch 205/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9509e-04 - accuracy: 1.0000 - val_loss: 0.5670 - val_accuracy: 0.8865\n",
            "Epoch 206/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8559e-04 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.8875\n",
            "Epoch 207/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9598e-04 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 0.8844\n",
            "Epoch 208/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7535e-04 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.8854\n",
            "Epoch 209/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7394e-04 - accuracy: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.8865\n",
            "Epoch 210/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5902e-04 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.8844\n",
            "Epoch 211/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6144e-04 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.8844\n",
            "Epoch 212/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4967e-04 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.8865\n",
            "Epoch 213/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4764e-04 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.8854\n",
            "Epoch 214/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5387e-04 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8854\n",
            "Epoch 215/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3743e-04 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.8844\n",
            "Epoch 216/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3008e-04 - accuracy: 1.0000 - val_loss: 0.5752 - val_accuracy: 0.8833\n",
            "Epoch 217/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2073e-04 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 0.8865\n",
            "Epoch 218/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1633e-04 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.8844\n",
            "Epoch 219/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0885e-04 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.8854\n",
            "Epoch 220/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0278e-04 - accuracy: 1.0000 - val_loss: 0.5787 - val_accuracy: 0.8833\n",
            "Epoch 221/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9650e-04 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.8865\n",
            "Epoch 222/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9683e-04 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.8865\n",
            "Epoch 223/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9042e-04 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.8844\n",
            "Epoch 224/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8571e-04 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8844\n",
            "Epoch 225/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8080e-04 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.8875\n",
            "Epoch 226/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7764e-04 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.8844\n",
            "Epoch 227/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7185e-04 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.8854\n",
            "Epoch 228/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6692e-04 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.8854\n",
            "Epoch 229/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6548e-04 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8896\n",
            "Epoch 230/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5960e-04 - accuracy: 1.0000 - val_loss: 0.5878 - val_accuracy: 0.8854\n",
            "Epoch 231/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5704e-04 - accuracy: 1.0000 - val_loss: 0.5905 - val_accuracy: 0.8854\n",
            "Epoch 232/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5192e-04 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.8896\n",
            "Epoch 233/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4879e-04 - accuracy: 1.0000 - val_loss: 0.5926 - val_accuracy: 0.8823\n",
            "Epoch 234/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4444e-04 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 0.8844\n",
            "Epoch 235/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4033e-04 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.8833\n",
            "Epoch 236/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3406e-04 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.8844\n",
            "Epoch 237/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3174e-04 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.8833\n",
            "Epoch 238/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2826e-04 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.8844\n",
            "Epoch 239/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2366e-04 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8854\n",
            "Epoch 240/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1970e-04 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8844\n",
            "Epoch 241/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1553e-04 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.8833\n",
            "Epoch 242/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1562e-04 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.8844\n",
            "Epoch 243/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1030e-04 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.8854\n",
            "Epoch 244/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0869e-04 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.8844\n",
            "Epoch 245/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0796e-04 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.8844\n",
            "Epoch 246/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0062e-04 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.8854\n",
            "Epoch 247/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0015e-04 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.8844\n",
            "Epoch 248/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9522e-04 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.8854\n",
            "Epoch 249/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9579e-04 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.8844\n",
            "Epoch 250/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9012e-04 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.8844\n",
            "Epoch 251/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8703e-04 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8844\n",
            "Epoch 252/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8603e-04 - accuracy: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.8823\n",
            "Epoch 253/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8493e-04 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.8896\n",
            "Epoch 254/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8604e-04 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.8865\n",
            "Epoch 255/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7687e-04 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.8844\n",
            "Epoch 256/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7192e-04 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.8844\n",
            "Epoch 257/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.7084e-04 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.8833\n",
            "Epoch 258/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6812e-04 - accuracy: 1.0000 - val_loss: 0.6092 - val_accuracy: 0.8854\n",
            "Epoch 259/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6750e-04 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.8844\n",
            "Epoch 260/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.6306e-04 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.8844\n",
            "Epoch 261/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5998e-04 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.8854\n",
            "Epoch 262/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5720e-04 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 0.8865\n",
            "Epoch 263/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5524e-04 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.8844\n",
            "Epoch 264/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5269e-04 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.8844\n",
            "Epoch 265/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.5056e-04 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.8844\n",
            "Epoch 266/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.6172 - val_accuracy: 0.8854\n",
            "Epoch 267/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4924e-04 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.8854\n",
            "Epoch 268/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4332e-04 - accuracy: 1.0000 - val_loss: 0.6172 - val_accuracy: 0.8844\n",
            "Epoch 269/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.4066e-04 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.8844\n",
            "Epoch 270/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3809e-04 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.8833\n",
            "Epoch 271/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.3703e-04 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.8833\n",
            "Epoch 272/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3436e-04 - accuracy: 1.0000 - val_loss: 0.6213 - val_accuracy: 0.8833\n",
            "Epoch 273/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3708e-04 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.8875\n",
            "Epoch 274/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.3499e-04 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.8865\n",
            "Epoch 275/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2847e-04 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.8833\n",
            "Epoch 276/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.2737e-04 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 0.8844\n",
            "Epoch 277/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2544e-04 - accuracy: 1.0000 - val_loss: 0.6262 - val_accuracy: 0.8844\n",
            "Epoch 278/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2444e-04 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8865\n",
            "Epoch 279/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.2021e-04 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.8854\n",
            "Epoch 280/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1898e-04 - accuracy: 1.0000 - val_loss: 0.6314 - val_accuracy: 0.8844\n",
            "Epoch 281/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1904e-04 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.8844\n",
            "Epoch 282/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1717e-04 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.8854\n",
            "Epoch 283/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1430e-04 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.8854\n",
            "Epoch 284/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.1439e-04 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.8844\n",
            "Epoch 285/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1319e-04 - accuracy: 1.0000 - val_loss: 0.6357 - val_accuracy: 0.8865\n",
            "Epoch 286/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1419e-04 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.8833\n",
            "Epoch 287/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1675e-04 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.8813\n",
            "Epoch 288/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1443e-04 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.8823\n",
            "Epoch 289/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.1005e-04 - accuracy: 1.0000 - val_loss: 0.6375 - val_accuracy: 0.8833\n",
            "Epoch 290/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0356e-04 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.8833\n",
            "Epoch 291/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.0229e-04 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8833\n",
            "Epoch 292/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.9481e-05 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 0.8865\n",
            "Epoch 293/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.8287e-05 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.8844\n",
            "Epoch 294/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.8309e-05 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.8833\n",
            "Epoch 295/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.6908e-05 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 0.8833\n",
            "Epoch 296/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.4121e-05 - accuracy: 1.0000 - val_loss: 0.6439 - val_accuracy: 0.8844\n",
            "Epoch 297/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.3302e-05 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.8833\n",
            "Epoch 298/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.0912e-05 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.8844\n",
            "Epoch 299/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 8.9537e-05 - accuracy: 1.0000 - val_loss: 0.6434 - val_accuracy: 0.8833\n",
            "Epoch 300/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.7716e-05 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.8833\n",
            "Epoch 301/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8165e-05 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.8844\n",
            "Epoch 302/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.6317e-05 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.8854\n",
            "Epoch 303/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.5076e-05 - accuracy: 1.0000 - val_loss: 0.6493 - val_accuracy: 0.8844\n",
            "Epoch 304/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4655e-05 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.8833\n",
            "Epoch 305/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.2305e-05 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 0.8833\n",
            "Epoch 306/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0712e-05 - accuracy: 1.0000 - val_loss: 0.6482 - val_accuracy: 0.8844\n",
            "Epoch 307/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.9453e-05 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.8844\n",
            "Epoch 308/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.8967e-05 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 0.8854\n",
            "Epoch 309/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.8248e-05 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8833\n",
            "Epoch 310/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.6899e-05 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.8844\n",
            "Epoch 311/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.5782e-05 - accuracy: 1.0000 - val_loss: 0.6529 - val_accuracy: 0.8844\n",
            "Epoch 312/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.3627e-05 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.8823\n",
            "Epoch 313/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.2482e-05 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.8833\n",
            "Epoch 314/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.1644e-05 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8823\n",
            "Epoch 315/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.0662e-05 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8833\n",
            "Epoch 316/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.0230e-05 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.8833\n",
            "Epoch 317/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.9480e-05 - accuracy: 1.0000 - val_loss: 0.6565 - val_accuracy: 0.8844\n",
            "Epoch 318/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.8164e-05 - accuracy: 1.0000 - val_loss: 0.6584 - val_accuracy: 0.8844\n",
            "Epoch 319/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.7181e-05 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.8865\n",
            "Epoch 320/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.6792e-05 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.8854\n",
            "Epoch 321/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.4911e-05 - accuracy: 1.0000 - val_loss: 0.6606 - val_accuracy: 0.8844\n",
            "Epoch 322/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.4350e-05 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.8844\n",
            "Epoch 323/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.3359e-05 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8854\n",
            "Epoch 324/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.3212e-05 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 0.8833\n",
            "Epoch 325/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.2313e-05 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.8844\n",
            "Epoch 326/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.1631e-05 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.8896\n",
            "Epoch 327/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.0427e-05 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.8844\n",
            "Epoch 328/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8828e-05 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.8833\n",
            "Epoch 329/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8126e-05 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8823\n",
            "Epoch 330/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.7900e-05 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.8833\n",
            "Epoch 331/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.6428e-05 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 0.8865\n",
            "Epoch 332/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5548e-05 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.8844\n",
            "Epoch 333/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.4959e-05 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.8844\n",
            "Epoch 334/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3953e-05 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.8865\n",
            "Epoch 335/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.3968e-05 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.8844\n",
            "Epoch 336/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2648e-05 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.8833\n",
            "Epoch 337/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2300e-05 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.8844\n",
            "Epoch 338/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0743e-05 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.8833\n",
            "Epoch 339/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0279e-05 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8844\n",
            "Epoch 340/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0324e-05 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8854\n",
            "Epoch 341/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.9048e-05 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8833\n",
            "Epoch 342/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8024e-05 - accuracy: 1.0000 - val_loss: 0.6778 - val_accuracy: 0.8865\n",
            "Epoch 343/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.7143e-05 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8854\n",
            "Epoch 344/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6617e-05 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8833\n",
            "Epoch 345/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6044e-05 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8854\n",
            "Epoch 346/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5784e-05 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8833\n",
            "Epoch 347/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.5042e-05 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8854\n",
            "Epoch 348/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4648e-05 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8833\n",
            "Epoch 349/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3839e-05 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.8865\n",
            "Epoch 350/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2866e-05 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8865\n",
            "Epoch 351/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.2393e-05 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8844\n",
            "Epoch 352/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.1847e-05 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.8854\n",
            "Epoch 353/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.1235e-05 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8833\n",
            "Epoch 354/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0918e-05 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.8854\n",
            "Epoch 355/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.0258e-05 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8844\n",
            "Epoch 356/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9463e-05 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.8844\n",
            "Epoch 357/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.8833e-05 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8865\n",
            "Epoch 358/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8439e-05 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8854\n",
            "Epoch 359/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7914e-05 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8844\n",
            "Epoch 360/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7896e-05 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8833\n",
            "Epoch 361/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.7181e-05 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8875\n",
            "Epoch 362/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6672e-05 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.8844\n",
            "Epoch 363/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.6808e-05 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8844\n",
            "Epoch 364/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.6258e-05 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8854\n",
            "Epoch 365/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5291e-05 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.8854\n",
            "Epoch 366/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.4292e-05 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8844\n",
            "Epoch 367/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3857e-05 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8844\n",
            "Epoch 368/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3522e-05 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8854\n",
            "Epoch 369/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2829e-05 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8865\n",
            "Epoch 370/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2413e-05 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8854\n",
            "Epoch 371/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2084e-05 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8865\n",
            "Epoch 372/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1330e-05 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8854\n",
            "Epoch 373/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1053e-05 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8854\n",
            "Epoch 374/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1022e-05 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8844\n",
            "Epoch 375/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0479e-05 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8844\n",
            "Epoch 376/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0234e-05 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.8865\n",
            "Epoch 377/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9452e-05 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8854\n",
            "Epoch 378/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9124e-05 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8854\n",
            "Epoch 379/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8923e-05 - accuracy: 1.0000 - val_loss: 0.7050 - val_accuracy: 0.8865\n",
            "Epoch 380/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8340e-05 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8865\n",
            "Epoch 381/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.8231e-05 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8865\n",
            "Epoch 382/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7305e-05 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8833\n",
            "Epoch 383/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7069e-05 - accuracy: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.8854\n",
            "Epoch 384/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6607e-05 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8854\n",
            "Epoch 385/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6338e-05 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8854\n",
            "Epoch 386/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5741e-05 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8844\n",
            "Epoch 387/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5472e-05 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.8844\n",
            "Epoch 388/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5112e-05 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.8854\n",
            "Epoch 389/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4659e-05 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8844\n",
            "Epoch 390/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4388e-05 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8865\n",
            "Epoch 391/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4044e-05 - accuracy: 1.0000 - val_loss: 0.7136 - val_accuracy: 0.8844\n",
            "Epoch 392/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3886e-05 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.8875\n",
            "Epoch 393/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3695e-05 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.8833\n",
            "Epoch 394/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3124e-05 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8865\n",
            "Epoch 395/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3122e-05 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.8875\n",
            "Epoch 396/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2519e-05 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8833\n",
            "Epoch 397/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2330e-05 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8844\n",
            "Epoch 398/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2103e-05 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8865\n",
            "Epoch 399/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2010e-05 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8875\n",
            "Epoch 400/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2384e-05 - accuracy: 1.0000 - val_loss: 0.7244 - val_accuracy: 0.8865\n",
            "Epoch 401/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.9684 - val_accuracy: 0.8656\n",
            "Epoch 402/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.9389 - accuracy: 0.8420 - val_loss: 2.1048 - val_accuracy: 0.7063\n",
            "Epoch 403/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.8399 - val_loss: 1.3616 - val_accuracy: 0.7729\n",
            "Epoch 404/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9222 - val_loss: 0.9538 - val_accuracy: 0.8292\n",
            "Epoch 405/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9743 - val_loss: 0.7951 - val_accuracy: 0.8542\n",
            "Epoch 406/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 0.7300 - val_accuracy: 0.8615\n",
            "Epoch 407/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.7537 - val_accuracy: 0.8698\n",
            "Epoch 408/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.6569 - val_accuracy: 0.8740\n",
            "Epoch 409/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.8781\n",
            "Epoch 410/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8760\n",
            "Epoch 411/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8719\n",
            "Epoch 412/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.7293e-04 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8719\n",
            "Epoch 413/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.1286e-04 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.8719\n",
            "Epoch 414/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 8.7193e-04 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8719\n",
            "Epoch 415/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.3127e-04 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8719\n",
            "Epoch 416/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.9498e-04 - accuracy: 1.0000 - val_loss: 0.6746 - val_accuracy: 0.8719\n",
            "Epoch 417/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 7.6478e-04 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8719\n",
            "Epoch 418/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.4035e-04 - accuracy: 1.0000 - val_loss: 0.6771 - val_accuracy: 0.8719\n",
            "Epoch 419/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.0986e-04 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.8719\n",
            "Epoch 420/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.8742e-04 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.8729\n",
            "Epoch 421/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.6503e-04 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8760\n",
            "Epoch 422/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.4879e-04 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8740\n",
            "Epoch 423/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.2825e-04 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8760\n",
            "Epoch 424/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.1448e-04 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.8750\n",
            "Epoch 425/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9396e-04 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8760\n",
            "Epoch 426/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.8037e-04 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.8792\n",
            "Epoch 427/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.6764e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8760\n",
            "Epoch 428/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.5323e-04 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.8771\n",
            "Epoch 429/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.4113e-04 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8781\n",
            "Epoch 430/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.2835e-04 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8792\n",
            "Epoch 431/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.1652e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8760\n",
            "Epoch 432/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.0679e-04 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8781\n",
            "Epoch 433/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.9459e-04 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8781\n",
            "Epoch 434/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.8533e-04 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8781\n",
            "Epoch 435/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.7494e-04 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8771\n",
            "Epoch 436/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.6598e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8781\n",
            "Epoch 437/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5772e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8771\n",
            "Epoch 438/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.5049e-04 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.8760\n",
            "Epoch 439/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.4037e-04 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8781\n",
            "Epoch 440/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.3270e-04 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8792\n",
            "Epoch 441/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.2823e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8781\n",
            "Epoch 442/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.1943e-04 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8771\n",
            "Epoch 443/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.1100e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8781\n",
            "Epoch 444/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 4.0401e-04 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8802\n",
            "Epoch 445/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.9779e-04 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.8771\n",
            "Epoch 446/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.9086e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8781\n",
            "Epoch 447/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.8430e-04 - accuracy: 1.0000 - val_loss: 0.6917 - val_accuracy: 0.8781\n",
            "Epoch 448/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.7796e-04 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.8771\n",
            "Epoch 449/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.7291e-04 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.8792\n",
            "Epoch 450/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.6635e-04 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8781\n",
            "Epoch 451/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.6186e-04 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8792\n",
            "Epoch 452/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5590e-04 - accuracy: 1.0000 - val_loss: 0.6944 - val_accuracy: 0.8781\n",
            "Epoch 453/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5035e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8781\n",
            "Epoch 454/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.4558e-04 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.8792\n",
            "Epoch 455/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.4022e-04 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.8760\n",
            "Epoch 456/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3561e-04 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8781\n",
            "Epoch 457/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.3051e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8781\n",
            "Epoch 458/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2709e-04 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.8781\n",
            "Epoch 459/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2230e-04 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.8781\n",
            "Epoch 460/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1662e-04 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8792\n",
            "Epoch 461/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.1242e-04 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.8781\n",
            "Epoch 462/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0863e-04 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8802\n",
            "Epoch 463/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.0411e-04 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8802\n",
            "Epoch 464/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9924e-04 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.8792\n",
            "Epoch 465/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9643e-04 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.8792\n",
            "Epoch 466/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9235e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8802\n",
            "Epoch 467/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8685e-04 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.8781\n",
            "Epoch 468/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8365e-04 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8781\n",
            "Epoch 469/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.8112e-04 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8781\n",
            "Epoch 470/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.7675e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8792\n",
            "Epoch 471/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.7381e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8792\n",
            "Epoch 472/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6924e-04 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8792\n",
            "Epoch 473/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6569e-04 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.8781\n",
            "Epoch 474/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.6204e-04 - accuracy: 1.0000 - val_loss: 0.7032 - val_accuracy: 0.8792\n",
            "Epoch 475/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5942e-04 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8792\n",
            "Epoch 476/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5544e-04 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.8792\n",
            "Epoch 477/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.5207e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8792\n",
            "Epoch 478/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4953e-04 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.8792\n",
            "Epoch 479/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4609e-04 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8792\n",
            "Epoch 480/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4354e-04 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.8781\n",
            "Epoch 481/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.4025e-04 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.8792\n",
            "Epoch 482/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3714e-04 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8781\n",
            "Epoch 483/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3432e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8781\n",
            "Epoch 484/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.3182e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8792\n",
            "Epoch 485/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2870e-04 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8792\n",
            "Epoch 486/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2590e-04 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8802\n",
            "Epoch 487/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2301e-04 - accuracy: 1.0000 - val_loss: 0.7059 - val_accuracy: 0.8792\n",
            "Epoch 488/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.2124e-04 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.8781\n",
            "Epoch 489/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1816e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8771\n",
            "Epoch 490/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1467e-04 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8781\n",
            "Epoch 491/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.1343e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8771\n",
            "Epoch 492/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.1046e-04 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8781\n",
            "Epoch 493/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0817e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8771\n",
            "Epoch 494/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0569e-04 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8781\n",
            "Epoch 495/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.0336e-04 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.8781\n",
            "Epoch 496/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.0122e-04 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8781\n",
            "Epoch 497/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9863e-04 - accuracy: 1.0000 - val_loss: 0.7099 - val_accuracy: 0.8781\n",
            "Epoch 498/500\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1.9624e-04 - accuracy: 1.0000 - val_loss: 0.7102 - val_accuracy: 0.8781\n",
            "Epoch 499/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9425e-04 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8781\n",
            "Epoch 500/500\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.9148e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.8781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pau32nCTQri2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "173e1c24-8122-49ae-d58d-59bdd53487c7"
      },
      "source": [
        "plt.plot(classifier3.history['loss'])\n",
        "plt.plot(classifier3.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dTGnZs5TQri4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dbf96f33-3d49-4289-a804-a1cc52d088ab"
      },
      "source": [
        "plt.plot(classifier3.history['accuracy'])\n",
        "plt.plot(classifier3.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "svfT6Pg7QrjD"
      },
      "source": [
        "#LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "__xiWBbdQrjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "58331bc0-8446-4246-c5c0-9a11d3a02627"
      },
      "source": [
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, Y3, test_size=0.25)\n",
        "X_train3 = np.reshape(X_train3, (X_train3.shape[0], 1, X_train3.shape[1]))\n",
        "X_test3 = np.reshape(X_test3, (X_test3.shape[0], 1, X_test3.shape[1]))\n",
        "input_shape = (X_train3.shape[1], X_train3.shape[2])\n",
        "model = Sequential()\n",
        "adam1 = Adam(learning_rate=0.0009)\n",
        "model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.25, return_sequences=True,input_shape=input_shape))\n",
        "model.add(LSTM(units=64,  dropout=0.05, recurrent_dropout=0.25, return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=20, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam1, metrics=[\"accuracy\"],)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 128)            79872     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1, 64)             49408     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 20)                1300      \n",
            "=================================================================\n",
            "Total params: 130,580\n",
            "Trainable params: 130,580\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CnPbXo-vQrjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5be63ab2-8cc2-4329-b2e1-ab19627797c9"
      },
      "source": [
        "batch_size = 35 # num of training examples per minibatch\n",
        "num_epochs =300\n",
        "classify3 = model.fit(\n",
        "    X_train3,\n",
        "    y_train3,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(X_test3,y_test3),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 2.9563 - accuracy: 0.1399 - val_loss: 2.8799 - val_accuracy: 0.1729\n",
            "Epoch 2/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 2.6307 - accuracy: 0.2170 - val_loss: 2.3567 - val_accuracy: 0.2240\n",
            "Epoch 3/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 2.1385 - accuracy: 0.2934 - val_loss: 1.9293 - val_accuracy: 0.3510\n",
            "Epoch 4/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 1.7830 - accuracy: 0.4184 - val_loss: 1.6114 - val_accuracy: 0.4802\n",
            "Epoch 5/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 1.5449 - accuracy: 0.5056 - val_loss: 1.4266 - val_accuracy: 0.5437\n",
            "Epoch 6/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 1.4092 - accuracy: 0.5691 - val_loss: 1.3075 - val_accuracy: 0.5792\n",
            "Epoch 7/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 1.2936 - accuracy: 0.6097 - val_loss: 1.2125 - val_accuracy: 0.6292\n",
            "Epoch 8/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 1.2267 - accuracy: 0.6267 - val_loss: 1.1303 - val_accuracy: 0.6510\n",
            "Epoch 9/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 1.1611 - accuracy: 0.6569 - val_loss: 1.0700 - val_accuracy: 0.6833\n",
            "Epoch 10/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 1.0937 - accuracy: 0.6865 - val_loss: 1.0162 - val_accuracy: 0.6948\n",
            "Epoch 11/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 1.0562 - accuracy: 0.6955 - val_loss: 0.9701 - val_accuracy: 0.7063\n",
            "Epoch 12/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.9875 - accuracy: 0.7156 - val_loss: 0.9264 - val_accuracy: 0.7219\n",
            "Epoch 13/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.9430 - accuracy: 0.7417 - val_loss: 0.8890 - val_accuracy: 0.7344\n",
            "Epoch 14/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.8875 - accuracy: 0.7587 - val_loss: 0.8438 - val_accuracy: 0.7437\n",
            "Epoch 15/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.8752 - accuracy: 0.7583 - val_loss: 0.8023 - val_accuracy: 0.7583\n",
            "Epoch 16/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.8127 - accuracy: 0.7812 - val_loss: 0.7741 - val_accuracy: 0.7656\n",
            "Epoch 17/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.7736 - accuracy: 0.8003 - val_loss: 0.7352 - val_accuracy: 0.7823\n",
            "Epoch 18/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.7503 - accuracy: 0.8076 - val_loss: 0.7222 - val_accuracy: 0.7833\n",
            "Epoch 19/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.7265 - accuracy: 0.8170 - val_loss: 0.6799 - val_accuracy: 0.7958\n",
            "Epoch 20/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.6762 - accuracy: 0.8299 - val_loss: 0.6615 - val_accuracy: 0.7948\n",
            "Epoch 21/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.6674 - accuracy: 0.8330 - val_loss: 0.6425 - val_accuracy: 0.8083\n",
            "Epoch 22/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.6019 - accuracy: 0.8351 - val_loss: 0.6154 - val_accuracy: 0.8229\n",
            "Epoch 23/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.6002 - accuracy: 0.8562 - val_loss: 0.6085 - val_accuracy: 0.8177\n",
            "Epoch 24/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.5630 - accuracy: 0.8562 - val_loss: 0.5865 - val_accuracy: 0.8323\n",
            "Epoch 25/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.5800 - accuracy: 0.8552 - val_loss: 0.5577 - val_accuracy: 0.8500\n",
            "Epoch 26/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.5488 - accuracy: 0.8663 - val_loss: 0.5519 - val_accuracy: 0.8365\n",
            "Epoch 27/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4817 - accuracy: 0.8861 - val_loss: 0.5309 - val_accuracy: 0.8490\n",
            "Epoch 28/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4849 - accuracy: 0.8785 - val_loss: 0.5185 - val_accuracy: 0.8479\n",
            "Epoch 29/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4527 - accuracy: 0.8833 - val_loss: 0.4901 - val_accuracy: 0.8656\n",
            "Epoch 30/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4434 - accuracy: 0.8896 - val_loss: 0.4803 - val_accuracy: 0.8656\n",
            "Epoch 31/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4455 - accuracy: 0.8899 - val_loss: 0.4674 - val_accuracy: 0.8677\n",
            "Epoch 32/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4189 - accuracy: 0.8941 - val_loss: 0.4589 - val_accuracy: 0.8792\n",
            "Epoch 33/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3752 - accuracy: 0.9118 - val_loss: 0.4378 - val_accuracy: 0.8823\n",
            "Epoch 34/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3773 - accuracy: 0.9076 - val_loss: 0.4282 - val_accuracy: 0.8813\n",
            "Epoch 35/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.3604 - accuracy: 0.9125 - val_loss: 0.4145 - val_accuracy: 0.8906\n",
            "Epoch 36/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3516 - accuracy: 0.9128 - val_loss: 0.4103 - val_accuracy: 0.8917\n",
            "Epoch 37/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3489 - accuracy: 0.9122 - val_loss: 0.4130 - val_accuracy: 0.8875\n",
            "Epoch 38/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.3235 - accuracy: 0.9205 - val_loss: 0.3961 - val_accuracy: 0.8854\n",
            "Epoch 39/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3177 - accuracy: 0.9219 - val_loss: 0.3760 - val_accuracy: 0.9031\n",
            "Epoch 40/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3060 - accuracy: 0.9187 - val_loss: 0.3816 - val_accuracy: 0.8833\n",
            "Epoch 41/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.3040 - accuracy: 0.9243 - val_loss: 0.3773 - val_accuracy: 0.9000\n",
            "Epoch 42/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.2875 - accuracy: 0.9281 - val_loss: 0.3601 - val_accuracy: 0.8990\n",
            "Epoch 43/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.2849 - accuracy: 0.9240 - val_loss: 0.3466 - val_accuracy: 0.9073\n",
            "Epoch 44/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.2701 - accuracy: 0.9347 - val_loss: 0.3546 - val_accuracy: 0.9000\n",
            "Epoch 45/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2478 - accuracy: 0.9441 - val_loss: 0.3446 - val_accuracy: 0.9052\n",
            "Epoch 46/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2388 - accuracy: 0.9375 - val_loss: 0.3300 - val_accuracy: 0.9062\n",
            "Epoch 47/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2355 - accuracy: 0.9431 - val_loss: 0.3256 - val_accuracy: 0.9083\n",
            "Epoch 48/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2217 - accuracy: 0.9458 - val_loss: 0.3300 - val_accuracy: 0.9031\n",
            "Epoch 49/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2135 - accuracy: 0.9486 - val_loss: 0.3187 - val_accuracy: 0.9094\n",
            "Epoch 50/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2117 - accuracy: 0.9483 - val_loss: 0.3216 - val_accuracy: 0.9115\n",
            "Epoch 51/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.2102 - accuracy: 0.9396 - val_loss: 0.3111 - val_accuracy: 0.9115\n",
            "Epoch 52/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.2042 - accuracy: 0.9493 - val_loss: 0.3069 - val_accuracy: 0.9031\n",
            "Epoch 53/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.1932 - accuracy: 0.9503 - val_loss: 0.3037 - val_accuracy: 0.9167\n",
            "Epoch 54/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.1901 - accuracy: 0.9510 - val_loss: 0.3064 - val_accuracy: 0.9104\n",
            "Epoch 55/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2081 - accuracy: 0.9444 - val_loss: 0.2982 - val_accuracy: 0.9156\n",
            "Epoch 56/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1847 - accuracy: 0.9542 - val_loss: 0.2767 - val_accuracy: 0.9240\n",
            "Epoch 57/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.1769 - accuracy: 0.9549 - val_loss: 0.2841 - val_accuracy: 0.9177\n",
            "Epoch 58/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1700 - accuracy: 0.9608 - val_loss: 0.2864 - val_accuracy: 0.9115\n",
            "Epoch 59/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1738 - accuracy: 0.9569 - val_loss: 0.2693 - val_accuracy: 0.9240\n",
            "Epoch 60/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1571 - accuracy: 0.9618 - val_loss: 0.2819 - val_accuracy: 0.9219\n",
            "Epoch 61/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.1510 - accuracy: 0.9628 - val_loss: 0.2760 - val_accuracy: 0.9177\n",
            "Epoch 62/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1541 - accuracy: 0.9601 - val_loss: 0.2702 - val_accuracy: 0.9167\n",
            "Epoch 63/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.1418 - accuracy: 0.9667 - val_loss: 0.2583 - val_accuracy: 0.9271\n",
            "Epoch 64/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1428 - accuracy: 0.9632 - val_loss: 0.2621 - val_accuracy: 0.9260\n",
            "Epoch 65/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1371 - accuracy: 0.9670 - val_loss: 0.2551 - val_accuracy: 0.9323\n",
            "Epoch 66/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1392 - accuracy: 0.9622 - val_loss: 0.2525 - val_accuracy: 0.9292\n",
            "Epoch 67/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1267 - accuracy: 0.9705 - val_loss: 0.2580 - val_accuracy: 0.9240\n",
            "Epoch 68/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1393 - accuracy: 0.9653 - val_loss: 0.2613 - val_accuracy: 0.9198\n",
            "Epoch 69/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1353 - accuracy: 0.9642 - val_loss: 0.2698 - val_accuracy: 0.9198\n",
            "Epoch 70/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1212 - accuracy: 0.9708 - val_loss: 0.2600 - val_accuracy: 0.9260\n",
            "Epoch 71/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1232 - accuracy: 0.9701 - val_loss: 0.2560 - val_accuracy: 0.9323\n",
            "Epoch 72/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1300 - accuracy: 0.9674 - val_loss: 0.2678 - val_accuracy: 0.9167\n",
            "Epoch 73/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.9670 - val_loss: 0.2653 - val_accuracy: 0.9125\n",
            "Epoch 74/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1183 - accuracy: 0.9691 - val_loss: 0.2502 - val_accuracy: 0.9177\n",
            "Epoch 75/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1045 - accuracy: 0.9760 - val_loss: 0.2467 - val_accuracy: 0.9250\n",
            "Epoch 76/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1045 - accuracy: 0.9740 - val_loss: 0.2325 - val_accuracy: 0.9354\n",
            "Epoch 77/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1022 - accuracy: 0.9753 - val_loss: 0.2470 - val_accuracy: 0.9167\n",
            "Epoch 78/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1081 - accuracy: 0.9733 - val_loss: 0.2314 - val_accuracy: 0.9281\n",
            "Epoch 79/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1082 - accuracy: 0.9701 - val_loss: 0.2390 - val_accuracy: 0.9271\n",
            "Epoch 80/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0952 - accuracy: 0.9743 - val_loss: 0.2289 - val_accuracy: 0.9302\n",
            "Epoch 81/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1014 - accuracy: 0.9719 - val_loss: 0.2289 - val_accuracy: 0.9333\n",
            "Epoch 82/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1004 - accuracy: 0.9747 - val_loss: 0.2326 - val_accuracy: 0.9323\n",
            "Epoch 83/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1012 - accuracy: 0.9747 - val_loss: 0.2236 - val_accuracy: 0.9323\n",
            "Epoch 84/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1065 - accuracy: 0.9760 - val_loss: 0.2453 - val_accuracy: 0.9260\n",
            "Epoch 85/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.1025 - accuracy: 0.9722 - val_loss: 0.2418 - val_accuracy: 0.9250\n",
            "Epoch 86/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0847 - accuracy: 0.9778 - val_loss: 0.2357 - val_accuracy: 0.9292\n",
            "Epoch 87/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0940 - accuracy: 0.9757 - val_loss: 0.2261 - val_accuracy: 0.9333\n",
            "Epoch 88/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0932 - accuracy: 0.9753 - val_loss: 0.2184 - val_accuracy: 0.9375\n",
            "Epoch 89/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0917 - accuracy: 0.9743 - val_loss: 0.2217 - val_accuracy: 0.9250\n",
            "Epoch 90/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0943 - accuracy: 0.9757 - val_loss: 0.2377 - val_accuracy: 0.9229\n",
            "Epoch 91/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0916 - accuracy: 0.9743 - val_loss: 0.2444 - val_accuracy: 0.9250\n",
            "Epoch 92/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0862 - accuracy: 0.9764 - val_loss: 0.2316 - val_accuracy: 0.9302\n",
            "Epoch 93/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0849 - accuracy: 0.9774 - val_loss: 0.2361 - val_accuracy: 0.9292\n",
            "Epoch 94/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0815 - accuracy: 0.9785 - val_loss: 0.2403 - val_accuracy: 0.9260\n",
            "Epoch 95/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9819 - val_loss: 0.2291 - val_accuracy: 0.9250\n",
            "Epoch 96/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0843 - accuracy: 0.9788 - val_loss: 0.2368 - val_accuracy: 0.9271\n",
            "Epoch 97/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0910 - accuracy: 0.9764 - val_loss: 0.2287 - val_accuracy: 0.9281\n",
            "Epoch 98/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0732 - accuracy: 0.9826 - val_loss: 0.2378 - val_accuracy: 0.9271\n",
            "Epoch 99/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0929 - accuracy: 0.9726 - val_loss: 0.2262 - val_accuracy: 0.9260\n",
            "Epoch 100/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0783 - accuracy: 0.9806 - val_loss: 0.2204 - val_accuracy: 0.9344\n",
            "Epoch 101/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0756 - accuracy: 0.9812 - val_loss: 0.2195 - val_accuracy: 0.9260\n",
            "Epoch 102/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0657 - accuracy: 0.9819 - val_loss: 0.2397 - val_accuracy: 0.9271\n",
            "Epoch 103/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0698 - accuracy: 0.9809 - val_loss: 0.2224 - val_accuracy: 0.9323\n",
            "Epoch 104/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0897 - accuracy: 0.9736 - val_loss: 0.2285 - val_accuracy: 0.9323\n",
            "Epoch 105/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0834 - accuracy: 0.9771 - val_loss: 0.2281 - val_accuracy: 0.9229\n",
            "Epoch 106/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9802 - val_loss: 0.2410 - val_accuracy: 0.9292\n",
            "Epoch 107/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0695 - accuracy: 0.9840 - val_loss: 0.2198 - val_accuracy: 0.9312\n",
            "Epoch 108/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0718 - accuracy: 0.9809 - val_loss: 0.2232 - val_accuracy: 0.9260\n",
            "Epoch 109/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0703 - accuracy: 0.9809 - val_loss: 0.2228 - val_accuracy: 0.9260\n",
            "Epoch 110/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0656 - accuracy: 0.9826 - val_loss: 0.2082 - val_accuracy: 0.9323\n",
            "Epoch 111/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0745 - accuracy: 0.9774 - val_loss: 0.2106 - val_accuracy: 0.9323\n",
            "Epoch 112/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0660 - accuracy: 0.9809 - val_loss: 0.2128 - val_accuracy: 0.9344\n",
            "Epoch 113/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0644 - accuracy: 0.9823 - val_loss: 0.2146 - val_accuracy: 0.9323\n",
            "Epoch 114/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9795 - val_loss: 0.2171 - val_accuracy: 0.9365\n",
            "Epoch 115/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0635 - accuracy: 0.9819 - val_loss: 0.2211 - val_accuracy: 0.9344\n",
            "Epoch 116/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0663 - accuracy: 0.9806 - val_loss: 0.2206 - val_accuracy: 0.9323\n",
            "Epoch 117/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9767 - val_loss: 0.2605 - val_accuracy: 0.9208\n",
            "Epoch 118/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0728 - accuracy: 0.9806 - val_loss: 0.2403 - val_accuracy: 0.9302\n",
            "Epoch 119/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0679 - accuracy: 0.9833 - val_loss: 0.2191 - val_accuracy: 0.9323\n",
            "Epoch 120/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0587 - accuracy: 0.9847 - val_loss: 0.2192 - val_accuracy: 0.9292\n",
            "Epoch 121/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0612 - accuracy: 0.9858 - val_loss: 0.2163 - val_accuracy: 0.9323\n",
            "Epoch 122/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0664 - accuracy: 0.9795 - val_loss: 0.2172 - val_accuracy: 0.9375\n",
            "Epoch 123/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0588 - accuracy: 0.9844 - val_loss: 0.2225 - val_accuracy: 0.9375\n",
            "Epoch 124/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0649 - accuracy: 0.9816 - val_loss: 0.2124 - val_accuracy: 0.9344\n",
            "Epoch 125/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9830 - val_loss: 0.2135 - val_accuracy: 0.9302\n",
            "Epoch 126/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0656 - accuracy: 0.9816 - val_loss: 0.2396 - val_accuracy: 0.9312\n",
            "Epoch 127/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0650 - accuracy: 0.9802 - val_loss: 0.2289 - val_accuracy: 0.9271\n",
            "Epoch 128/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0595 - accuracy: 0.9819 - val_loss: 0.2222 - val_accuracy: 0.9323\n",
            "Epoch 129/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0583 - accuracy: 0.9833 - val_loss: 0.2314 - val_accuracy: 0.9312\n",
            "Epoch 130/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0554 - accuracy: 0.9851 - val_loss: 0.2274 - val_accuracy: 0.9333\n",
            "Epoch 131/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0523 - accuracy: 0.9865 - val_loss: 0.1997 - val_accuracy: 0.9365\n",
            "Epoch 132/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0605 - accuracy: 0.9819 - val_loss: 0.2203 - val_accuracy: 0.9385\n",
            "Epoch 133/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0616 - accuracy: 0.9833 - val_loss: 0.2097 - val_accuracy: 0.9333\n",
            "Epoch 134/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0638 - accuracy: 0.9806 - val_loss: 0.2251 - val_accuracy: 0.9292\n",
            "Epoch 135/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0606 - accuracy: 0.9837 - val_loss: 0.2253 - val_accuracy: 0.9385\n",
            "Epoch 136/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0480 - accuracy: 0.9865 - val_loss: 0.2157 - val_accuracy: 0.9323\n",
            "Epoch 137/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0478 - accuracy: 0.9882 - val_loss: 0.2209 - val_accuracy: 0.9365\n",
            "Epoch 138/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.2036 - val_accuracy: 0.9385\n",
            "Epoch 139/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0508 - accuracy: 0.9861 - val_loss: 0.2320 - val_accuracy: 0.9344\n",
            "Epoch 140/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0455 - accuracy: 0.9885 - val_loss: 0.2100 - val_accuracy: 0.9333\n",
            "Epoch 141/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9837 - val_loss: 0.2125 - val_accuracy: 0.9396\n",
            "Epoch 142/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0486 - accuracy: 0.9861 - val_loss: 0.2358 - val_accuracy: 0.9208\n",
            "Epoch 143/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0563 - accuracy: 0.9837 - val_loss: 0.2007 - val_accuracy: 0.9417\n",
            "Epoch 144/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9885 - val_loss: 0.2363 - val_accuracy: 0.9302\n",
            "Epoch 145/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.2277 - val_accuracy: 0.9396\n",
            "Epoch 146/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0453 - accuracy: 0.9882 - val_loss: 0.2313 - val_accuracy: 0.9354\n",
            "Epoch 147/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9865 - val_loss: 0.2571 - val_accuracy: 0.9281\n",
            "Epoch 148/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0503 - accuracy: 0.9892 - val_loss: 0.2218 - val_accuracy: 0.9354\n",
            "Epoch 149/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0457 - accuracy: 0.9882 - val_loss: 0.2176 - val_accuracy: 0.9250\n",
            "Epoch 150/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0531 - accuracy: 0.9851 - val_loss: 0.2178 - val_accuracy: 0.9323\n",
            "Epoch 151/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.1874 - val_accuracy: 0.9417\n",
            "Epoch 152/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0470 - accuracy: 0.9854 - val_loss: 0.2203 - val_accuracy: 0.9323\n",
            "Epoch 153/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0548 - accuracy: 0.9847 - val_loss: 0.2160 - val_accuracy: 0.9385\n",
            "Epoch 154/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0452 - accuracy: 0.9892 - val_loss: 0.2282 - val_accuracy: 0.9302\n",
            "Epoch 155/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0599 - accuracy: 0.9833 - val_loss: 0.2005 - val_accuracy: 0.9385\n",
            "Epoch 156/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0400 - accuracy: 0.9899 - val_loss: 0.1849 - val_accuracy: 0.9448\n",
            "Epoch 157/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9889 - val_loss: 0.1938 - val_accuracy: 0.9385\n",
            "Epoch 158/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0497 - accuracy: 0.9858 - val_loss: 0.2024 - val_accuracy: 0.9333\n",
            "Epoch 159/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0534 - accuracy: 0.9844 - val_loss: 0.2062 - val_accuracy: 0.9354\n",
            "Epoch 160/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 0.2143 - val_accuracy: 0.9438\n",
            "Epoch 161/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0447 - accuracy: 0.9865 - val_loss: 0.2067 - val_accuracy: 0.9365\n",
            "Epoch 162/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0496 - accuracy: 0.9868 - val_loss: 0.2201 - val_accuracy: 0.9354\n",
            "Epoch 163/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9896 - val_loss: 0.1894 - val_accuracy: 0.9479\n",
            "Epoch 164/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9875 - val_loss: 0.1769 - val_accuracy: 0.9500\n",
            "Epoch 165/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.2090 - val_accuracy: 0.9344\n",
            "Epoch 166/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0477 - accuracy: 0.9844 - val_loss: 0.2356 - val_accuracy: 0.9281\n",
            "Epoch 167/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 0.2173 - val_accuracy: 0.9365\n",
            "Epoch 168/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.2298 - val_accuracy: 0.9281\n",
            "Epoch 169/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0418 - accuracy: 0.9892 - val_loss: 0.2292 - val_accuracy: 0.9312\n",
            "Epoch 170/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 0.2082 - val_accuracy: 0.9365\n",
            "Epoch 171/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0301 - accuracy: 0.9944 - val_loss: 0.2106 - val_accuracy: 0.9333\n",
            "Epoch 172/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0473 - accuracy: 0.9878 - val_loss: 0.2124 - val_accuracy: 0.9354\n",
            "Epoch 173/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.2070 - val_accuracy: 0.9375\n",
            "Epoch 174/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0452 - accuracy: 0.9872 - val_loss: 0.2232 - val_accuracy: 0.9323\n",
            "Epoch 175/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 0.2006 - val_accuracy: 0.9396\n",
            "Epoch 176/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.1905 - val_accuracy: 0.9458\n",
            "Epoch 177/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.2175 - val_accuracy: 0.9292\n",
            "Epoch 178/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.2156 - val_accuracy: 0.9344\n",
            "Epoch 179/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9910 - val_loss: 0.2047 - val_accuracy: 0.9375\n",
            "Epoch 180/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 0.9882 - val_loss: 0.2432 - val_accuracy: 0.9208\n",
            "Epoch 181/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0333 - accuracy: 0.9920 - val_loss: 0.2229 - val_accuracy: 0.9312\n",
            "Epoch 182/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9844 - val_loss: 0.2220 - val_accuracy: 0.9333\n",
            "Epoch 183/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0324 - accuracy: 0.9917 - val_loss: 0.2087 - val_accuracy: 0.9375\n",
            "Epoch 184/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0419 - accuracy: 0.9882 - val_loss: 0.2199 - val_accuracy: 0.9302\n",
            "Epoch 185/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.2392 - val_accuracy: 0.9344\n",
            "Epoch 186/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0378 - accuracy: 0.9903 - val_loss: 0.1881 - val_accuracy: 0.9458\n",
            "Epoch 187/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.2375 - val_accuracy: 0.9333\n",
            "Epoch 188/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.2223 - val_accuracy: 0.9365\n",
            "Epoch 189/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0466 - accuracy: 0.9889 - val_loss: 0.1860 - val_accuracy: 0.9479\n",
            "Epoch 190/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9906 - val_loss: 0.1871 - val_accuracy: 0.9438\n",
            "Epoch 191/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9903 - val_loss: 0.2074 - val_accuracy: 0.9396\n",
            "Epoch 192/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9858 - val_loss: 0.2211 - val_accuracy: 0.9396\n",
            "Epoch 193/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0407 - accuracy: 0.9892 - val_loss: 0.2140 - val_accuracy: 0.9333\n",
            "Epoch 194/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 0.2345 - val_accuracy: 0.9312\n",
            "Epoch 195/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9913 - val_loss: 0.2170 - val_accuracy: 0.9312\n",
            "Epoch 196/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0378 - accuracy: 0.9896 - val_loss: 0.2173 - val_accuracy: 0.9417\n",
            "Epoch 197/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0431 - accuracy: 0.9892 - val_loss: 0.2343 - val_accuracy: 0.9385\n",
            "Epoch 198/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0372 - accuracy: 0.9896 - val_loss: 0.2240 - val_accuracy: 0.9365\n",
            "Epoch 199/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0374 - accuracy: 0.9910 - val_loss: 0.2255 - val_accuracy: 0.9302\n",
            "Epoch 200/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.2081 - val_accuracy: 0.9427\n",
            "Epoch 201/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9910 - val_loss: 0.2198 - val_accuracy: 0.9302\n",
            "Epoch 202/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9927 - val_loss: 0.2091 - val_accuracy: 0.9469\n",
            "Epoch 203/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.2185 - val_accuracy: 0.9427\n",
            "Epoch 204/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9899 - val_loss: 0.2135 - val_accuracy: 0.9458\n",
            "Epoch 205/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0353 - accuracy: 0.9917 - val_loss: 0.2248 - val_accuracy: 0.9292\n",
            "Epoch 206/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.2054 - val_accuracy: 0.9396\n",
            "Epoch 207/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.2041 - val_accuracy: 0.9417\n",
            "Epoch 208/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.2032 - val_accuracy: 0.9427\n",
            "Epoch 209/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9865 - val_loss: 0.2097 - val_accuracy: 0.9458\n",
            "Epoch 210/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.2271 - val_accuracy: 0.9240\n",
            "Epoch 211/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.2253 - val_accuracy: 0.9396\n",
            "Epoch 212/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.1932 - val_accuracy: 0.9438\n",
            "Epoch 213/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.1929 - val_accuracy: 0.9458\n",
            "Epoch 214/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.2046 - val_accuracy: 0.9479\n",
            "Epoch 215/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.1964 - val_accuracy: 0.9458\n",
            "Epoch 216/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 0.1888 - val_accuracy: 0.9552\n",
            "Epoch 217/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.2365 - val_accuracy: 0.9354\n",
            "Epoch 218/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.2242 - val_accuracy: 0.9417\n",
            "Epoch 219/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.2219 - val_accuracy: 0.9396\n",
            "Epoch 220/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.1984 - val_accuracy: 0.9458\n",
            "Epoch 221/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.2523 - val_accuracy: 0.9354\n",
            "Epoch 222/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9903 - val_loss: 0.2237 - val_accuracy: 0.9365\n",
            "Epoch 223/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0220 - accuracy: 0.9958 - val_loss: 0.2171 - val_accuracy: 0.9375\n",
            "Epoch 224/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.2151 - val_accuracy: 0.9469\n",
            "Epoch 225/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 0.2163 - val_accuracy: 0.9375\n",
            "Epoch 226/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9924 - val_loss: 0.2161 - val_accuracy: 0.9417\n",
            "Epoch 227/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.1980 - val_accuracy: 0.9417\n",
            "Epoch 228/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9937 - val_loss: 0.2320 - val_accuracy: 0.9417\n",
            "Epoch 229/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9941 - val_loss: 0.2327 - val_accuracy: 0.9385\n",
            "Epoch 230/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0275 - accuracy: 0.9920 - val_loss: 0.2108 - val_accuracy: 0.9438\n",
            "Epoch 231/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 0.2204 - val_accuracy: 0.9417\n",
            "Epoch 232/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 0.2245 - val_accuracy: 0.9438\n",
            "Epoch 233/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9924 - val_loss: 0.2459 - val_accuracy: 0.9385\n",
            "Epoch 234/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9927 - val_loss: 0.2144 - val_accuracy: 0.9469\n",
            "Epoch 235/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9885 - val_loss: 0.2258 - val_accuracy: 0.9427\n",
            "Epoch 236/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.2067 - val_accuracy: 0.9469\n",
            "Epoch 237/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9899 - val_loss: 0.2271 - val_accuracy: 0.9396\n",
            "Epoch 238/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0373 - accuracy: 0.9903 - val_loss: 0.2174 - val_accuracy: 0.9427\n",
            "Epoch 239/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.2130 - val_accuracy: 0.9458\n",
            "Epoch 240/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.2275 - val_accuracy: 0.9406\n",
            "Epoch 241/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0285 - accuracy: 0.9931 - val_loss: 0.2331 - val_accuracy: 0.9385\n",
            "Epoch 242/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9906 - val_loss: 0.2441 - val_accuracy: 0.9302\n",
            "Epoch 243/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0357 - accuracy: 0.9899 - val_loss: 0.2085 - val_accuracy: 0.9396\n",
            "Epoch 244/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 0.2182 - val_accuracy: 0.9448\n",
            "Epoch 245/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.2108 - val_accuracy: 0.9448\n",
            "Epoch 246/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0295 - accuracy: 0.9927 - val_loss: 0.2174 - val_accuracy: 0.9448\n",
            "Epoch 247/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.2284 - val_accuracy: 0.9427\n",
            "Epoch 248/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0256 - accuracy: 0.9937 - val_loss: 0.2231 - val_accuracy: 0.9448\n",
            "Epoch 249/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 0.2220 - val_accuracy: 0.9396\n",
            "Epoch 250/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.2298 - val_accuracy: 0.9427\n",
            "Epoch 251/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.2506 - val_accuracy: 0.9333\n",
            "Epoch 252/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.2226 - val_accuracy: 0.9375\n",
            "Epoch 253/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0321 - accuracy: 0.9878 - val_loss: 0.2161 - val_accuracy: 0.9354\n",
            "Epoch 254/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0293 - accuracy: 0.9913 - val_loss: 0.1951 - val_accuracy: 0.9500\n",
            "Epoch 255/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 0.1920 - val_accuracy: 0.9438\n",
            "Epoch 256/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.2113 - val_accuracy: 0.9448\n",
            "Epoch 257/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.2237 - val_accuracy: 0.9396\n",
            "Epoch 258/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.2204 - val_accuracy: 0.9438\n",
            "Epoch 259/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.2018 - val_accuracy: 0.9542\n",
            "Epoch 260/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.2091 - val_accuracy: 0.9427\n",
            "Epoch 261/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.2336 - val_accuracy: 0.9385\n",
            "Epoch 262/300\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.2332 - val_accuracy: 0.9396\n",
            "Epoch 263/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.2100 - val_accuracy: 0.9479\n",
            "Epoch 264/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.2258 - val_accuracy: 0.9354\n",
            "Epoch 265/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.2027 - val_accuracy: 0.9448\n",
            "Epoch 266/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.2172 - val_accuracy: 0.9469\n",
            "Epoch 267/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.2164 - val_accuracy: 0.9458\n",
            "Epoch 268/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.2251 - val_accuracy: 0.9469\n",
            "Epoch 269/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.2204 - val_accuracy: 0.9385\n",
            "Epoch 270/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.2108 - val_accuracy: 0.9479\n",
            "Epoch 271/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.2409 - val_accuracy: 0.9354\n",
            "Epoch 272/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0347 - accuracy: 0.9903 - val_loss: 0.1962 - val_accuracy: 0.9469\n",
            "Epoch 273/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0298 - accuracy: 0.9931 - val_loss: 0.2656 - val_accuracy: 0.9302\n",
            "Epoch 274/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.2338 - val_accuracy: 0.9375\n",
            "Epoch 275/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9931 - val_loss: 0.2219 - val_accuracy: 0.9479\n",
            "Epoch 276/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.2018 - val_accuracy: 0.9542\n",
            "Epoch 277/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.2132 - val_accuracy: 0.9490\n",
            "Epoch 278/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9920 - val_loss: 0.2331 - val_accuracy: 0.9417\n",
            "Epoch 279/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9913 - val_loss: 0.2398 - val_accuracy: 0.9385\n",
            "Epoch 280/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.2235 - val_accuracy: 0.9448\n",
            "Epoch 281/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.2184 - val_accuracy: 0.9406\n",
            "Epoch 282/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.2180 - val_accuracy: 0.9458\n",
            "Epoch 283/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.2002 - val_accuracy: 0.9469\n",
            "Epoch 284/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.2099 - val_accuracy: 0.9417\n",
            "Epoch 285/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.2110 - val_accuracy: 0.9490\n",
            "Epoch 286/300\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9934 - val_loss: 0.2074 - val_accuracy: 0.9500\n",
            "Epoch 287/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.2239 - val_accuracy: 0.9417\n",
            "Epoch 288/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 0.2216 - val_accuracy: 0.9427\n",
            "Epoch 289/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.2147 - val_accuracy: 0.9448\n",
            "Epoch 290/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.2415 - val_accuracy: 0.9448\n",
            "Epoch 291/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0351 - accuracy: 0.9910 - val_loss: 0.2609 - val_accuracy: 0.9385\n",
            "Epoch 292/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.2131 - val_accuracy: 0.9458\n",
            "Epoch 293/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.2182 - val_accuracy: 0.9448\n",
            "Epoch 294/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.2097 - val_accuracy: 0.9479\n",
            "Epoch 295/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.2210 - val_accuracy: 0.9427\n",
            "Epoch 296/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.2247 - val_accuracy: 0.9469\n",
            "Epoch 297/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.2167 - val_accuracy: 0.9521\n",
            "Epoch 298/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0281 - accuracy: 0.9934 - val_loss: 0.2061 - val_accuracy: 0.9521\n",
            "Epoch 299/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0181 - accuracy: 0.9934 - val_loss: 0.2248 - val_accuracy: 0.9479\n",
            "Epoch 300/300\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.2386 - val_accuracy: 0.9396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k7AjBmU2QrjL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJE0LqS1QrjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8fd0fb-d9da-43e4-bdf8-9f62309cf6b1"
      },
      "source": [
        "plt.plot(classify3.history['loss'])\n",
        "plt.plot(classify3.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RRp7MxTkQrjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8332d5a9-d5c8-4b43-ff5f-07f77abf297b"
      },
      "source": [
        "plt.plot(classify3.history['accuracy'])\n",
        "plt.plot(classify3.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QivMgCiyQrjU"
      },
      "source": [
        "#BiLSTM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1WpTZHDWQrjU",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U87y4fEKQrjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af16e94b-e71d-4172-8841-fc3eef14bba3"
      },
      "source": [
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, Y3, test_size=0.25)\n",
        "X_train3 = np.reshape(X_train3, (X_train3.shape[0], 1, X_train3.shape[1]))\n",
        "X_test3 = np.reshape(X_test3, (X_test3.shape[0], 1, X_test3.shape[1]))\n",
        "input_shape = (X_train3.shape[1], X_train3.shape[2])\n",
        "model = Sequential()\n",
        "adam1 = Adam(learning_rate=0.0009)\n",
        "model.add(Bidirectional(LSTM(units=128, dropout=0.05, recurrent_dropout=0.25, return_sequences=True),input_shape=input_shape))\n",
        "model.add(Bidirectional(LSTM(units=64,  dropout=0.05, recurrent_dropout=0.25, return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=20, activation=\"softmax\"))\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam1, metrics=[\"accuracy\"],)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 1, 256)            159744    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1, 128)            164352    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 326,676\n",
            "Trainable params: 326,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4tvPAIQeQrjY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8160fe57-92a9-4715-aa4a-ca2f4a373055"
      },
      "source": [
        "batch_size = 35 # num of training examples per minibatch\n",
        "num_epochs =300\n",
        "classify = model.fit(\n",
        "    X_train3,\n",
        "    y_train3,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(X_test3,y_test3),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "83/83 [==============================] - 2s 26ms/step - loss: 2.8524 - accuracy: 0.1851 - val_loss: 2.5419 - val_accuracy: 0.2031\n",
            "Epoch 2/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 2.1993 - accuracy: 0.2861 - val_loss: 1.9200 - val_accuracy: 0.3510\n",
            "Epoch 3/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 1.6551 - accuracy: 0.4500 - val_loss: 1.4586 - val_accuracy: 0.5521\n",
            "Epoch 4/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 1.3133 - accuracy: 0.5646 - val_loss: 1.2190 - val_accuracy: 0.5958\n",
            "Epoch 5/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 1.1516 - accuracy: 0.6264 - val_loss: 1.0812 - val_accuracy: 0.6656\n",
            "Epoch 6/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 1.0240 - accuracy: 0.6753 - val_loss: 0.9759 - val_accuracy: 0.6927\n",
            "Epoch 7/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.9282 - accuracy: 0.7059 - val_loss: 0.8890 - val_accuracy: 0.7115\n",
            "Epoch 8/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.8673 - accuracy: 0.7319 - val_loss: 0.8357 - val_accuracy: 0.7281\n",
            "Epoch 9/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.8001 - accuracy: 0.7556 - val_loss: 0.7806 - val_accuracy: 0.7469\n",
            "Epoch 10/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.7301 - accuracy: 0.7757 - val_loss: 0.7262 - val_accuracy: 0.7677\n",
            "Epoch 11/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.6907 - accuracy: 0.7837 - val_loss: 0.6829 - val_accuracy: 0.7771\n",
            "Epoch 12/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.6276 - accuracy: 0.8122 - val_loss: 0.6489 - val_accuracy: 0.7854\n",
            "Epoch 13/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.6129 - accuracy: 0.8125 - val_loss: 0.6359 - val_accuracy: 0.7875\n",
            "Epoch 14/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.5784 - accuracy: 0.8295 - val_loss: 0.5997 - val_accuracy: 0.8115\n",
            "Epoch 15/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.5350 - accuracy: 0.8455 - val_loss: 0.5690 - val_accuracy: 0.8208\n",
            "Epoch 16/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.4953 - accuracy: 0.8628 - val_loss: 0.5369 - val_accuracy: 0.8271\n",
            "Epoch 17/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.4742 - accuracy: 0.8635 - val_loss: 0.5245 - val_accuracy: 0.8354\n",
            "Epoch 18/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.4618 - accuracy: 0.8653 - val_loss: 0.5070 - val_accuracy: 0.8302\n",
            "Epoch 19/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.4200 - accuracy: 0.8872 - val_loss: 0.4848 - val_accuracy: 0.8542\n",
            "Epoch 20/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.3875 - accuracy: 0.8951 - val_loss: 0.4707 - val_accuracy: 0.8417\n",
            "Epoch 21/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.3772 - accuracy: 0.8962 - val_loss: 0.4640 - val_accuracy: 0.8448\n",
            "Epoch 22/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.3510 - accuracy: 0.9031 - val_loss: 0.4379 - val_accuracy: 0.8625\n",
            "Epoch 23/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.3225 - accuracy: 0.9118 - val_loss: 0.4492 - val_accuracy: 0.8562\n",
            "Epoch 24/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2962 - accuracy: 0.9226 - val_loss: 0.4385 - val_accuracy: 0.8594\n",
            "Epoch 25/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2968 - accuracy: 0.9191 - val_loss: 0.4233 - val_accuracy: 0.8625\n",
            "Epoch 26/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.3018 - accuracy: 0.9187 - val_loss: 0.4160 - val_accuracy: 0.8615\n",
            "Epoch 27/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2793 - accuracy: 0.9257 - val_loss: 0.4045 - val_accuracy: 0.8687\n",
            "Epoch 28/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2575 - accuracy: 0.9295 - val_loss: 0.4094 - val_accuracy: 0.8573\n",
            "Epoch 29/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2255 - accuracy: 0.9396 - val_loss: 0.4094 - val_accuracy: 0.8708\n",
            "Epoch 30/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2305 - accuracy: 0.9389 - val_loss: 0.3964 - val_accuracy: 0.8677\n",
            "Epoch 31/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2219 - accuracy: 0.9444 - val_loss: 0.3878 - val_accuracy: 0.8760\n",
            "Epoch 32/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1968 - accuracy: 0.9479 - val_loss: 0.3693 - val_accuracy: 0.8823\n",
            "Epoch 33/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.2020 - accuracy: 0.9486 - val_loss: 0.3824 - val_accuracy: 0.8833\n",
            "Epoch 34/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1921 - accuracy: 0.9479 - val_loss: 0.3948 - val_accuracy: 0.8687\n",
            "Epoch 35/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1798 - accuracy: 0.9514 - val_loss: 0.3751 - val_accuracy: 0.8760\n",
            "Epoch 36/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1562 - accuracy: 0.9611 - val_loss: 0.3765 - val_accuracy: 0.8740\n",
            "Epoch 37/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1607 - accuracy: 0.9590 - val_loss: 0.3646 - val_accuracy: 0.8802\n",
            "Epoch 38/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1661 - accuracy: 0.9587 - val_loss: 0.3865 - val_accuracy: 0.8760\n",
            "Epoch 39/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1588 - accuracy: 0.9587 - val_loss: 0.3622 - val_accuracy: 0.8823\n",
            "Epoch 40/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1310 - accuracy: 0.9674 - val_loss: 0.3688 - val_accuracy: 0.8813\n",
            "Epoch 41/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1316 - accuracy: 0.9715 - val_loss: 0.3764 - val_accuracy: 0.8844\n",
            "Epoch 42/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.1221 - accuracy: 0.9698 - val_loss: 0.3647 - val_accuracy: 0.8833\n",
            "Epoch 43/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1309 - accuracy: 0.9694 - val_loss: 0.3744 - val_accuracy: 0.8719\n",
            "Epoch 44/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1160 - accuracy: 0.9740 - val_loss: 0.3847 - val_accuracy: 0.8802\n",
            "Epoch 45/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1222 - accuracy: 0.9688 - val_loss: 0.3668 - val_accuracy: 0.8844\n",
            "Epoch 46/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0969 - accuracy: 0.9806 - val_loss: 0.3510 - val_accuracy: 0.8917\n",
            "Epoch 47/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1019 - accuracy: 0.9778 - val_loss: 0.3642 - val_accuracy: 0.8813\n",
            "Epoch 48/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.1087 - accuracy: 0.9736 - val_loss: 0.3654 - val_accuracy: 0.8844\n",
            "Epoch 49/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.1077 - accuracy: 0.9701 - val_loss: 0.3723 - val_accuracy: 0.8813\n",
            "Epoch 50/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0914 - accuracy: 0.9774 - val_loss: 0.3855 - val_accuracy: 0.8760\n",
            "Epoch 51/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0860 - accuracy: 0.9788 - val_loss: 0.3661 - val_accuracy: 0.8750\n",
            "Epoch 52/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0828 - accuracy: 0.9826 - val_loss: 0.3686 - val_accuracy: 0.8865\n",
            "Epoch 53/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0833 - accuracy: 0.9837 - val_loss: 0.3674 - val_accuracy: 0.8750\n",
            "Epoch 54/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0735 - accuracy: 0.9833 - val_loss: 0.3562 - val_accuracy: 0.8813\n",
            "Epoch 55/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0797 - accuracy: 0.9812 - val_loss: 0.3670 - val_accuracy: 0.8792\n",
            "Epoch 56/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0807 - accuracy: 0.9806 - val_loss: 0.3584 - val_accuracy: 0.8844\n",
            "Epoch 57/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0759 - accuracy: 0.9833 - val_loss: 0.3630 - val_accuracy: 0.8844\n",
            "Epoch 58/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0738 - accuracy: 0.9823 - val_loss: 0.3617 - val_accuracy: 0.8854\n",
            "Epoch 59/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0695 - accuracy: 0.9830 - val_loss: 0.3576 - val_accuracy: 0.8875\n",
            "Epoch 60/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0684 - accuracy: 0.9872 - val_loss: 0.3546 - val_accuracy: 0.8865\n",
            "Epoch 61/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0642 - accuracy: 0.9851 - val_loss: 0.3541 - val_accuracy: 0.8938\n",
            "Epoch 62/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0718 - accuracy: 0.9806 - val_loss: 0.3914 - val_accuracy: 0.8823\n",
            "Epoch 63/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0711 - accuracy: 0.9823 - val_loss: 0.3781 - val_accuracy: 0.8802\n",
            "Epoch 64/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0674 - accuracy: 0.9837 - val_loss: 0.3931 - val_accuracy: 0.8760\n",
            "Epoch 65/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0662 - accuracy: 0.9854 - val_loss: 0.3670 - val_accuracy: 0.8833\n",
            "Epoch 66/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0549 - accuracy: 0.9854 - val_loss: 0.3707 - val_accuracy: 0.8771\n",
            "Epoch 67/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0594 - accuracy: 0.9865 - val_loss: 0.3776 - val_accuracy: 0.8813\n",
            "Epoch 68/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0557 - accuracy: 0.9875 - val_loss: 0.3914 - val_accuracy: 0.8906\n",
            "Epoch 69/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0520 - accuracy: 0.9865 - val_loss: 0.3530 - val_accuracy: 0.8896\n",
            "Epoch 70/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0490 - accuracy: 0.9878 - val_loss: 0.3900 - val_accuracy: 0.8833\n",
            "Epoch 71/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0491 - accuracy: 0.9885 - val_loss: 0.3905 - val_accuracy: 0.8844\n",
            "Epoch 72/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0523 - accuracy: 0.9892 - val_loss: 0.3991 - val_accuracy: 0.8740\n",
            "Epoch 73/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0495 - accuracy: 0.9851 - val_loss: 0.3937 - val_accuracy: 0.8885\n",
            "Epoch 74/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0476 - accuracy: 0.9872 - val_loss: 0.4139 - val_accuracy: 0.8792\n",
            "Epoch 75/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0433 - accuracy: 0.9896 - val_loss: 0.3975 - val_accuracy: 0.8854\n",
            "Epoch 76/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0375 - accuracy: 0.9941 - val_loss: 0.3813 - val_accuracy: 0.8927\n",
            "Epoch 77/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0409 - accuracy: 0.9899 - val_loss: 0.3728 - val_accuracy: 0.8927\n",
            "Epoch 78/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0370 - accuracy: 0.9920 - val_loss: 0.3689 - val_accuracy: 0.8917\n",
            "Epoch 79/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 0.3979 - val_accuracy: 0.8833\n",
            "Epoch 80/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.3920 - val_accuracy: 0.8885\n",
            "Epoch 81/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0471 - accuracy: 0.9889 - val_loss: 0.4192 - val_accuracy: 0.8792\n",
            "Epoch 82/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0339 - accuracy: 0.9931 - val_loss: 0.4014 - val_accuracy: 0.8865\n",
            "Epoch 83/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0350 - accuracy: 0.9903 - val_loss: 0.3988 - val_accuracy: 0.8833\n",
            "Epoch 84/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0401 - accuracy: 0.9903 - val_loss: 0.3838 - val_accuracy: 0.8927\n",
            "Epoch 85/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0387 - accuracy: 0.9913 - val_loss: 0.3846 - val_accuracy: 0.8865\n",
            "Epoch 86/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0342 - accuracy: 0.9913 - val_loss: 0.3909 - val_accuracy: 0.8854\n",
            "Epoch 87/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0384 - accuracy: 0.9903 - val_loss: 0.3994 - val_accuracy: 0.8896\n",
            "Epoch 88/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0397 - accuracy: 0.9910 - val_loss: 0.3909 - val_accuracy: 0.8875\n",
            "Epoch 89/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0430 - accuracy: 0.9903 - val_loss: 0.4048 - val_accuracy: 0.8854\n",
            "Epoch 90/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0343 - accuracy: 0.9917 - val_loss: 0.3853 - val_accuracy: 0.8844\n",
            "Epoch 91/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0286 - accuracy: 0.9937 - val_loss: 0.4150 - val_accuracy: 0.8896\n",
            "Epoch 92/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0328 - accuracy: 0.9924 - val_loss: 0.3786 - val_accuracy: 0.8917\n",
            "Epoch 93/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0350 - accuracy: 0.9910 - val_loss: 0.4022 - val_accuracy: 0.8896\n",
            "Epoch 94/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0272 - accuracy: 0.9948 - val_loss: 0.3816 - val_accuracy: 0.8917\n",
            "Epoch 95/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.3867 - val_accuracy: 0.8927\n",
            "Epoch 96/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0337 - accuracy: 0.9906 - val_loss: 0.3882 - val_accuracy: 0.8896\n",
            "Epoch 97/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0294 - accuracy: 0.9941 - val_loss: 0.4107 - val_accuracy: 0.8844\n",
            "Epoch 98/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0258 - accuracy: 0.9948 - val_loss: 0.4084 - val_accuracy: 0.8875\n",
            "Epoch 99/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0275 - accuracy: 0.9934 - val_loss: 0.3881 - val_accuracy: 0.8938\n",
            "Epoch 100/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.4117 - val_accuracy: 0.8927\n",
            "Epoch 101/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.3915 - val_accuracy: 0.8896\n",
            "Epoch 102/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.3955 - val_accuracy: 0.8990\n",
            "Epoch 103/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0272 - accuracy: 0.9951 - val_loss: 0.3834 - val_accuracy: 0.8917\n",
            "Epoch 104/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.4202 - val_accuracy: 0.8875\n",
            "Epoch 105/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 0.4075 - val_accuracy: 0.8865\n",
            "Epoch 106/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.4169 - val_accuracy: 0.8802\n",
            "Epoch 107/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0217 - accuracy: 0.9958 - val_loss: 0.3999 - val_accuracy: 0.8896\n",
            "Epoch 108/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.3850 - val_accuracy: 0.8990\n",
            "Epoch 109/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.3870 - val_accuracy: 0.8969\n",
            "Epoch 110/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0257 - accuracy: 0.9934 - val_loss: 0.4035 - val_accuracy: 0.8833\n",
            "Epoch 111/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.3906 - val_accuracy: 0.8917\n",
            "Epoch 112/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 0.4082 - val_accuracy: 0.8813\n",
            "Epoch 113/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.3970 - val_accuracy: 0.8927\n",
            "Epoch 114/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 0.3940 - val_accuracy: 0.8958\n",
            "Epoch 115/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0187 - accuracy: 0.9965 - val_loss: 0.4166 - val_accuracy: 0.8875\n",
            "Epoch 116/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.4145 - val_accuracy: 0.8854\n",
            "Epoch 117/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.4415 - val_accuracy: 0.8906\n",
            "Epoch 118/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.4218 - val_accuracy: 0.8865\n",
            "Epoch 119/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.4218 - val_accuracy: 0.8896\n",
            "Epoch 120/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.4495 - val_accuracy: 0.8833\n",
            "Epoch 121/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.4556 - val_accuracy: 0.8885\n",
            "Epoch 122/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 0.4214 - val_accuracy: 0.8906\n",
            "Epoch 123/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 0.4292 - val_accuracy: 0.8875\n",
            "Epoch 124/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.4204 - val_accuracy: 0.8938\n",
            "Epoch 125/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.3996 - val_accuracy: 0.8927\n",
            "Epoch 126/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.4286 - val_accuracy: 0.8896\n",
            "Epoch 127/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.4323 - val_accuracy: 0.8885\n",
            "Epoch 128/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.4352 - val_accuracy: 0.8969\n",
            "Epoch 129/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.4181 - val_accuracy: 0.8885\n",
            "Epoch 130/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.4167 - val_accuracy: 0.8844\n",
            "Epoch 131/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.4325 - val_accuracy: 0.8948\n",
            "Epoch 132/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.4170 - val_accuracy: 0.8969\n",
            "Epoch 133/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.4431 - val_accuracy: 0.8938\n",
            "Epoch 134/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.4345 - val_accuracy: 0.8833\n",
            "Epoch 135/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.4199 - val_accuracy: 0.8896\n",
            "Epoch 136/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.4522 - val_accuracy: 0.8927\n",
            "Epoch 137/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.4399 - val_accuracy: 0.8917\n",
            "Epoch 138/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0223 - accuracy: 0.9948 - val_loss: 0.4477 - val_accuracy: 0.8917\n",
            "Epoch 139/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.4418 - val_accuracy: 0.8917\n",
            "Epoch 140/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0247 - accuracy: 0.9944 - val_loss: 0.4372 - val_accuracy: 0.8885\n",
            "Epoch 141/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.4564 - val_accuracy: 0.8906\n",
            "Epoch 142/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.4299 - val_accuracy: 0.8927\n",
            "Epoch 143/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.4415 - val_accuracy: 0.8927\n",
            "Epoch 144/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.4599 - val_accuracy: 0.8792\n",
            "Epoch 145/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.4560 - val_accuracy: 0.8885\n",
            "Epoch 146/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.4287 - val_accuracy: 0.8948\n",
            "Epoch 147/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.4419 - val_accuracy: 0.8979\n",
            "Epoch 148/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.4225 - val_accuracy: 0.8979\n",
            "Epoch 149/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0200 - accuracy: 0.9958 - val_loss: 0.4537 - val_accuracy: 0.8865\n",
            "Epoch 150/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.4452 - val_accuracy: 0.8885\n",
            "Epoch 151/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.4379 - val_accuracy: 0.8885\n",
            "Epoch 152/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.4487 - val_accuracy: 0.8917\n",
            "Epoch 153/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.4284 - val_accuracy: 0.8896\n",
            "Epoch 154/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.4277 - val_accuracy: 0.8885\n",
            "Epoch 155/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.4387 - val_accuracy: 0.8885\n",
            "Epoch 156/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.4604 - val_accuracy: 0.8854\n",
            "Epoch 157/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.4522 - val_accuracy: 0.8917\n",
            "Epoch 158/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.4457 - val_accuracy: 0.8917\n",
            "Epoch 159/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.5036 - val_accuracy: 0.8896\n",
            "Epoch 160/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.4260 - val_accuracy: 0.8958\n",
            "Epoch 161/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.4334 - val_accuracy: 0.9000\n",
            "Epoch 162/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.4470 - val_accuracy: 0.8938\n",
            "Epoch 163/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.4205 - val_accuracy: 0.8948\n",
            "Epoch 164/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.4252 - val_accuracy: 0.8979\n",
            "Epoch 165/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.4620 - val_accuracy: 0.8875\n",
            "Epoch 166/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.4269 - val_accuracy: 0.8958\n",
            "Epoch 167/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.4234 - val_accuracy: 0.8938\n",
            "Epoch 168/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.4358 - val_accuracy: 0.8917\n",
            "Epoch 169/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0179 - accuracy: 0.9920 - val_loss: 0.4275 - val_accuracy: 0.9062\n",
            "Epoch 170/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.4233 - val_accuracy: 0.8885\n",
            "Epoch 171/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.4783 - val_accuracy: 0.8938\n",
            "Epoch 172/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.4866 - val_accuracy: 0.8948\n",
            "Epoch 173/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.4554 - val_accuracy: 0.8969\n",
            "Epoch 174/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.4248 - val_accuracy: 0.8990\n",
            "Epoch 175/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.4530 - val_accuracy: 0.8927\n",
            "Epoch 176/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.4600 - val_accuracy: 0.8958\n",
            "Epoch 177/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.4561 - val_accuracy: 0.8917\n",
            "Epoch 178/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.4338 - val_accuracy: 0.8948\n",
            "Epoch 179/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.3982 - val_accuracy: 0.8990\n",
            "Epoch 180/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.4122 - val_accuracy: 0.8969\n",
            "Epoch 181/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.4725 - val_accuracy: 0.8875\n",
            "Epoch 182/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.4674 - val_accuracy: 0.8875\n",
            "Epoch 183/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.4554 - val_accuracy: 0.8958\n",
            "Epoch 184/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.4580 - val_accuracy: 0.8938\n",
            "Epoch 185/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.4447 - val_accuracy: 0.8979\n",
            "Epoch 186/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.4466 - val_accuracy: 0.8969\n",
            "Epoch 187/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.4500 - val_accuracy: 0.8927\n",
            "Epoch 188/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.4760 - val_accuracy: 0.8958\n",
            "Epoch 189/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.4443 - val_accuracy: 0.8969\n",
            "Epoch 190/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.4394 - val_accuracy: 0.8906\n",
            "Epoch 191/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.4515 - val_accuracy: 0.8917\n",
            "Epoch 192/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.4319 - val_accuracy: 0.8885\n",
            "Epoch 193/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.4286 - val_accuracy: 0.8958\n",
            "Epoch 194/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.4581 - val_accuracy: 0.8906\n",
            "Epoch 195/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.4522 - val_accuracy: 0.8896\n",
            "Epoch 196/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.4470 - val_accuracy: 0.8875\n",
            "Epoch 197/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.4326 - val_accuracy: 0.9021\n",
            "Epoch 198/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.4304 - val_accuracy: 0.8979\n",
            "Epoch 199/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.4448 - val_accuracy: 0.8948\n",
            "Epoch 200/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.4484 - val_accuracy: 0.8958\n",
            "Epoch 201/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.4435 - val_accuracy: 0.8990\n",
            "Epoch 202/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.4531 - val_accuracy: 0.8917\n",
            "Epoch 203/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.4267 - val_accuracy: 0.9000\n",
            "Epoch 204/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.4204 - val_accuracy: 0.9010\n",
            "Epoch 205/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.4407 - val_accuracy: 0.8958\n",
            "Epoch 206/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.4510 - val_accuracy: 0.8979\n",
            "Epoch 207/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0060 - accuracy: 0.9997 - val_loss: 0.4631 - val_accuracy: 0.8896\n",
            "Epoch 208/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.4719 - val_accuracy: 0.8844\n",
            "Epoch 209/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.4782 - val_accuracy: 0.8917\n",
            "Epoch 210/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.4610 - val_accuracy: 0.8917\n",
            "Epoch 211/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.4583 - val_accuracy: 0.8958\n",
            "Epoch 212/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.4510 - val_accuracy: 0.8927\n",
            "Epoch 213/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.4834 - val_accuracy: 0.8875\n",
            "Epoch 214/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.4948 - val_accuracy: 0.8938\n",
            "Epoch 215/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.4599 - val_accuracy: 0.8958\n",
            "Epoch 216/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.6066 - val_accuracy: 0.8771\n",
            "Epoch 217/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.4508 - val_accuracy: 0.8938\n",
            "Epoch 218/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.4606 - val_accuracy: 0.9000\n",
            "Epoch 219/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.4579 - val_accuracy: 0.8969\n",
            "Epoch 220/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4317 - val_accuracy: 0.8958\n",
            "Epoch 221/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.5013 - val_accuracy: 0.8844\n",
            "Epoch 222/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.4621 - val_accuracy: 0.8906\n",
            "Epoch 223/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.5473 - val_accuracy: 0.8750\n",
            "Epoch 224/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.4622 - val_accuracy: 0.8969\n",
            "Epoch 225/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.4411 - val_accuracy: 0.8927\n",
            "Epoch 226/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.4397 - val_accuracy: 0.8938\n",
            "Epoch 227/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.4553 - val_accuracy: 0.8948\n",
            "Epoch 228/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.4594 - val_accuracy: 0.8969\n",
            "Epoch 229/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.4260 - val_accuracy: 0.9010\n",
            "Epoch 230/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.4413 - val_accuracy: 0.8958\n",
            "Epoch 231/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.4246 - val_accuracy: 0.9031\n",
            "Epoch 232/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.4221 - val_accuracy: 0.9062\n",
            "Epoch 233/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.4227 - val_accuracy: 0.9010\n",
            "Epoch 234/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.4615 - val_accuracy: 0.8979\n",
            "Epoch 235/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.4553 - val_accuracy: 0.8969\n",
            "Epoch 236/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.4873 - val_accuracy: 0.8948\n",
            "Epoch 237/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.4525 - val_accuracy: 0.8958\n",
            "Epoch 238/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.4434 - val_accuracy: 0.8938\n",
            "Epoch 239/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.4449 - val_accuracy: 0.8927\n",
            "Epoch 240/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.4315 - val_accuracy: 0.8875\n",
            "Epoch 241/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.4373 - val_accuracy: 0.8938\n",
            "Epoch 242/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.4364 - val_accuracy: 0.8885\n",
            "Epoch 243/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.4225 - val_accuracy: 0.8979\n",
            "Epoch 244/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.4565 - val_accuracy: 0.8969\n",
            "Epoch 245/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.4707 - val_accuracy: 0.8969\n",
            "Epoch 246/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4653 - val_accuracy: 0.8979\n",
            "Epoch 247/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.4486 - val_accuracy: 0.8969\n",
            "Epoch 248/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.4752 - val_accuracy: 0.8885\n",
            "Epoch 249/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.4735 - val_accuracy: 0.8917\n",
            "Epoch 250/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.4713 - val_accuracy: 0.8917\n",
            "Epoch 251/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.4645 - val_accuracy: 0.9021\n",
            "Epoch 252/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0093 - accuracy: 0.9962 - val_loss: 0.4771 - val_accuracy: 0.8854\n",
            "Epoch 253/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4598 - val_accuracy: 0.8948\n",
            "Epoch 254/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0105 - accuracy: 0.9944 - val_loss: 0.4997 - val_accuracy: 0.8885\n",
            "Epoch 255/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.5019 - val_accuracy: 0.8844\n",
            "Epoch 256/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.5137 - val_accuracy: 0.8927\n",
            "Epoch 257/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.4967 - val_accuracy: 0.8906\n",
            "Epoch 258/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.4619 - val_accuracy: 0.8927\n",
            "Epoch 259/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.5162 - val_accuracy: 0.8802\n",
            "Epoch 260/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0090 - accuracy: 0.9962 - val_loss: 0.4692 - val_accuracy: 0.8938\n",
            "Epoch 261/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.4565 - val_accuracy: 0.8969\n",
            "Epoch 262/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.4596 - val_accuracy: 0.9010\n",
            "Epoch 263/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.4503 - val_accuracy: 0.8958\n",
            "Epoch 264/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.4505 - val_accuracy: 0.9021\n",
            "Epoch 265/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4621 - val_accuracy: 0.9000\n",
            "Epoch 266/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.4576 - val_accuracy: 0.8990\n",
            "Epoch 267/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4468 - val_accuracy: 0.8979\n",
            "Epoch 268/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.4400 - val_accuracy: 0.8979\n",
            "Epoch 269/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.4620 - val_accuracy: 0.8958\n",
            "Epoch 270/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.4600 - val_accuracy: 0.8958\n",
            "Epoch 271/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.5003 - val_accuracy: 0.8885\n",
            "Epoch 272/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.4760 - val_accuracy: 0.8927\n",
            "Epoch 273/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.5132 - val_accuracy: 0.8948\n",
            "Epoch 274/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.4707 - val_accuracy: 0.9031\n",
            "Epoch 275/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.4423 - val_accuracy: 0.8948\n",
            "Epoch 276/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.4806 - val_accuracy: 0.8927\n",
            "Epoch 277/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.4863 - val_accuracy: 0.8917\n",
            "Epoch 278/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.4452 - val_accuracy: 0.8927\n",
            "Epoch 279/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.4578 - val_accuracy: 0.8927\n",
            "Epoch 280/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.5018 - val_accuracy: 0.8896\n",
            "Epoch 281/300\n",
            "83/83 [==============================] - 1s 16ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.4689 - val_accuracy: 0.9000\n",
            "Epoch 282/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.4834 - val_accuracy: 0.8969\n",
            "Epoch 283/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.4952 - val_accuracy: 0.8990\n",
            "Epoch 284/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.5022 - val_accuracy: 0.8979\n",
            "Epoch 285/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.4669 - val_accuracy: 0.9031\n",
            "Epoch 286/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.4847 - val_accuracy: 0.8958\n",
            "Epoch 287/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.5021 - val_accuracy: 0.8969\n",
            "Epoch 288/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.4590 - val_accuracy: 0.8969\n",
            "Epoch 289/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.4707 - val_accuracy: 0.9083\n",
            "Epoch 290/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.4713 - val_accuracy: 0.9094\n",
            "Epoch 291/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.4611 - val_accuracy: 0.9042\n",
            "Epoch 292/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.4658 - val_accuracy: 0.9052\n",
            "Epoch 293/300\n",
            "83/83 [==============================] - 1s 17ms/step - loss: 0.0039 - accuracy: 0.9997 - val_loss: 0.4855 - val_accuracy: 0.9083\n",
            "Epoch 294/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.4873 - val_accuracy: 0.9021\n",
            "Epoch 295/300\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.5058 - val_accuracy: 0.8938\n",
            "Epoch 296/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.4676 - val_accuracy: 0.9042\n",
            "Epoch 297/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.4488 - val_accuracy: 0.9104\n",
            "Epoch 298/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.4647 - val_accuracy: 0.9000\n",
            "Epoch 299/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.4513 - val_accuracy: 0.8990\n",
            "Epoch 300/300\n",
            "83/83 [==============================] - 1s 15ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.4713 - val_accuracy: 0.9010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZDb9oO6pQrje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22e9979-01b0-49f6-b6cd-c3bb1b5bd050"
      },
      "source": [
        "plt.plot(classify.history['loss'])\n",
        "plt.plot(classify.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlSR9yDXQrjg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "29d16a83-cf94-4fc9-ece7-e97ad9cd76b4"
      },
      "source": [
        "plt.plot(classify.history['accuracy'])\n",
        "plt.plot(classify.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmKUHi91reic",
        "colab_type": "text"
      },
      "source": [
        "# 1D Convolution Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDf9fM1Bth6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30f5fb5a-fa1a-4df8-abe9-c6047a8dcd2f"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import keras\n",
        "import tensorflow.keras.layers as layers\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Bidirectional\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxhqMlmmtr_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63c351c4-7e40-4b7c-9d02-a3bd6b6528f5"
      },
      "source": [
        "data = pd.read_csv('dataset-instrument-big.csv')\n",
        "# Dropping unneccesary columns\n",
        "data = data.drop(['filename'],axis=1)\n",
        "#Encoding the Labels\n",
        "raga_list = data.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "X_train.shape[1], X_train.shape[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R2r-U7eKrpvc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "21f47841-9fb6-4b8a-98d0-279cd8f56f35"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(32,3, activation = \"relu\",padding = 'same', input_shape=input_shape))\n",
        "model.add(layers.Conv1D(64,3,activation = 'relu',padding = 'same'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64,activation = 'relu'))\n",
        "model.add(layers.Dense(20,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1, 32)             2624      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1, 64)             6208      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                1300      \n",
            "=================================================================\n",
            "Total params: 14,292\n",
            "Trainable params: 14,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2sARSDFArpvf",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nfk1N3RDrpvg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6e817f4-3a85-4507-f742-b559a3050c62"
      },
      "source": [
        "classifier = model.fit(X_train, y_train,batch_size=128, epochs=400, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.9897 - accuracy: 0.0645 - val_loss: 2.9693 - val_accuracy: 0.0927\n",
            "Epoch 2/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.9555 - accuracy: 0.1042 - val_loss: 2.9371 - val_accuracy: 0.1369\n",
            "Epoch 3/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.1370 - val_loss: 2.8685 - val_accuracy: 0.1446\n",
            "Epoch 4/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.8039 - accuracy: 0.1531 - val_loss: 2.7252 - val_accuracy: 0.1769\n",
            "Epoch 5/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.6239 - accuracy: 0.1771 - val_loss: 2.4922 - val_accuracy: 0.1896\n",
            "Epoch 6/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 2.3955 - accuracy: 0.2085 - val_loss: 2.2284 - val_accuracy: 0.2543\n",
            "Epoch 7/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.1861 - accuracy: 0.2540 - val_loss: 2.0291 - val_accuracy: 0.2985\n",
            "Epoch 8/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.0383 - accuracy: 0.2638 - val_loss: 1.8916 - val_accuracy: 0.3401\n",
            "Epoch 9/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.9314 - accuracy: 0.3174 - val_loss: 1.7985 - val_accuracy: 0.3639\n",
            "Epoch 10/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.8521 - accuracy: 0.3342 - val_loss: 1.7123 - val_accuracy: 0.3818\n",
            "Epoch 11/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.7767 - accuracy: 0.3462 - val_loss: 1.6514 - val_accuracy: 0.4192\n",
            "Epoch 12/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.7417 - accuracy: 0.3553 - val_loss: 1.5981 - val_accuracy: 0.4252\n",
            "Epoch 13/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.6786 - accuracy: 0.3867 - val_loss: 1.5348 - val_accuracy: 0.4515\n",
            "Epoch 14/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.6360 - accuracy: 0.3837 - val_loss: 1.4956 - val_accuracy: 0.4770\n",
            "Epoch 15/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.5850 - accuracy: 0.3991 - val_loss: 1.4423 - val_accuracy: 0.4600\n",
            "Epoch 16/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.5634 - accuracy: 0.4100 - val_loss: 1.4068 - val_accuracy: 0.4796\n",
            "Epoch 17/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.5233 - accuracy: 0.4165 - val_loss: 1.3593 - val_accuracy: 0.5298\n",
            "Epoch 18/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 1.4855 - accuracy: 0.4282 - val_loss: 1.3306 - val_accuracy: 0.5417\n",
            "Epoch 19/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.4413 - accuracy: 0.4453 - val_loss: 1.2863 - val_accuracy: 0.5672\n",
            "Epoch 20/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.4235 - accuracy: 0.4472 - val_loss: 1.2668 - val_accuracy: 0.5502\n",
            "Epoch 21/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.4042 - accuracy: 0.4435 - val_loss: 1.2417 - val_accuracy: 0.5570\n",
            "Epoch 22/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.3680 - accuracy: 0.4774 - val_loss: 1.2265 - val_accuracy: 0.5663\n",
            "Epoch 23/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.3702 - accuracy: 0.4749 - val_loss: 1.1976 - val_accuracy: 0.5893\n",
            "Epoch 24/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.3336 - accuracy: 0.4832 - val_loss: 1.1871 - val_accuracy: 0.5765\n",
            "Epoch 25/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.3132 - accuracy: 0.4931 - val_loss: 1.1547 - val_accuracy: 0.5876\n",
            "Epoch 26/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2874 - accuracy: 0.4865 - val_loss: 1.1510 - val_accuracy: 0.6003\n",
            "Epoch 27/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2770 - accuracy: 0.4942 - val_loss: 1.1189 - val_accuracy: 0.6012\n",
            "Epoch 28/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2694 - accuracy: 0.5055 - val_loss: 1.1056 - val_accuracy: 0.6071\n",
            "Epoch 29/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2422 - accuracy: 0.5164 - val_loss: 1.0878 - val_accuracy: 0.6233\n",
            "Epoch 30/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2223 - accuracy: 0.5222 - val_loss: 1.0666 - val_accuracy: 0.6233\n",
            "Epoch 31/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2207 - accuracy: 0.5248 - val_loss: 1.0516 - val_accuracy: 0.6437\n",
            "Epoch 32/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.1913 - accuracy: 0.5292 - val_loss: 1.0261 - val_accuracy: 0.6446\n",
            "Epoch 33/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1666 - accuracy: 0.5488 - val_loss: 1.0157 - val_accuracy: 0.6556\n",
            "Epoch 34/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1488 - accuracy: 0.5448 - val_loss: 1.0025 - val_accuracy: 0.6607\n",
            "Epoch 35/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1521 - accuracy: 0.5466 - val_loss: 1.0091 - val_accuracy: 0.6259\n",
            "Epoch 36/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 1.1706 - accuracy: 0.5321 - val_loss: 0.9782 - val_accuracy: 0.6556\n",
            "Epoch 37/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.5674 - val_loss: 0.9784 - val_accuracy: 0.6675\n",
            "Epoch 38/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1230 - accuracy: 0.5663 - val_loss: 0.9402 - val_accuracy: 0.6684\n",
            "Epoch 39/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.1247 - accuracy: 0.5590 - val_loss: 0.9237 - val_accuracy: 0.6913\n",
            "Epoch 40/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1074 - accuracy: 0.5758 - val_loss: 0.9236 - val_accuracy: 0.6981\n",
            "Epoch 41/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0853 - accuracy: 0.5845 - val_loss: 0.9245 - val_accuracy: 0.6837\n",
            "Epoch 42/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0643 - accuracy: 0.5776 - val_loss: 0.9279 - val_accuracy: 0.6794\n",
            "Epoch 43/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0704 - accuracy: 0.5754 - val_loss: 0.9347 - val_accuracy: 0.6658\n",
            "Epoch 44/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0470 - accuracy: 0.5824 - val_loss: 0.9000 - val_accuracy: 0.6837\n",
            "Epoch 45/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0323 - accuracy: 0.5980 - val_loss: 0.8833 - val_accuracy: 0.6930\n",
            "Epoch 46/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0222 - accuracy: 0.5951 - val_loss: 0.8625 - val_accuracy: 0.7117\n",
            "Epoch 47/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0292 - accuracy: 0.5948 - val_loss: 0.8370 - val_accuracy: 0.7202\n",
            "Epoch 48/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0234 - accuracy: 0.5835 - val_loss: 0.8363 - val_accuracy: 0.7143\n",
            "Epoch 49/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0024 - accuracy: 0.6119 - val_loss: 0.8375 - val_accuracy: 0.7270\n",
            "Epoch 50/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.9859 - accuracy: 0.6210 - val_loss: 0.8192 - val_accuracy: 0.7313\n",
            "Epoch 51/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9754 - accuracy: 0.6082 - val_loss: 0.8102 - val_accuracy: 0.7347\n",
            "Epoch 52/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9763 - accuracy: 0.6006 - val_loss: 0.8013 - val_accuracy: 0.7270\n",
            "Epoch 53/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.9806 - accuracy: 0.6071 - val_loss: 0.8073 - val_accuracy: 0.7287\n",
            "Epoch 54/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9634 - accuracy: 0.6181 - val_loss: 0.7788 - val_accuracy: 0.7517\n",
            "Epoch 55/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.9351 - accuracy: 0.6396 - val_loss: 0.7938 - val_accuracy: 0.7236\n",
            "Epoch 56/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9456 - accuracy: 0.6257 - val_loss: 0.7883 - val_accuracy: 0.7279\n",
            "Epoch 57/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9590 - accuracy: 0.6224 - val_loss: 0.7785 - val_accuracy: 0.7313\n",
            "Epoch 58/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9217 - accuracy: 0.6385 - val_loss: 0.7583 - val_accuracy: 0.7491\n",
            "Epoch 59/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.9349 - accuracy: 0.6294 - val_loss: 0.7489 - val_accuracy: 0.7611\n",
            "Epoch 60/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9252 - accuracy: 0.6392 - val_loss: 0.7414 - val_accuracy: 0.7611\n",
            "Epoch 61/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8840 - accuracy: 0.6629 - val_loss: 0.7585 - val_accuracy: 0.7347\n",
            "Epoch 62/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9115 - accuracy: 0.6283 - val_loss: 0.7355 - val_accuracy: 0.7466\n",
            "Epoch 63/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8829 - accuracy: 0.6545 - val_loss: 0.7447 - val_accuracy: 0.7466\n",
            "Epoch 64/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9080 - accuracy: 0.6425 - val_loss: 0.7315 - val_accuracy: 0.7594\n",
            "Epoch 65/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8840 - accuracy: 0.6472 - val_loss: 0.7279 - val_accuracy: 0.7577\n",
            "Epoch 66/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.8834 - accuracy: 0.6549 - val_loss: 0.7039 - val_accuracy: 0.7602\n",
            "Epoch 67/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9023 - accuracy: 0.6407 - val_loss: 0.6924 - val_accuracy: 0.7738\n",
            "Epoch 68/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8636 - accuracy: 0.6567 - val_loss: 0.7098 - val_accuracy: 0.7415\n",
            "Epoch 69/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8723 - accuracy: 0.6552 - val_loss: 0.6692 - val_accuracy: 0.7645\n",
            "Epoch 70/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8697 - accuracy: 0.6542 - val_loss: 0.7022 - val_accuracy: 0.7440\n",
            "Epoch 71/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8492 - accuracy: 0.6509 - val_loss: 0.6806 - val_accuracy: 0.7764\n",
            "Epoch 72/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8434 - accuracy: 0.6687 - val_loss: 0.6569 - val_accuracy: 0.7857\n",
            "Epoch 73/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8401 - accuracy: 0.6636 - val_loss: 0.6651 - val_accuracy: 0.7653\n",
            "Epoch 74/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8424 - accuracy: 0.6742 - val_loss: 0.6627 - val_accuracy: 0.7789\n",
            "Epoch 75/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8307 - accuracy: 0.6691 - val_loss: 0.6365 - val_accuracy: 0.7934\n",
            "Epoch 76/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8200 - accuracy: 0.6851 - val_loss: 0.6544 - val_accuracy: 0.7806\n",
            "Epoch 77/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.6975 - val_loss: 0.6285 - val_accuracy: 0.7832\n",
            "Epoch 78/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8327 - accuracy: 0.6709 - val_loss: 0.6373 - val_accuracy: 0.7959\n",
            "Epoch 79/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.8190 - accuracy: 0.6727 - val_loss: 0.6380 - val_accuracy: 0.7798\n",
            "Epoch 80/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7997 - accuracy: 0.6961 - val_loss: 0.6235 - val_accuracy: 0.7891\n",
            "Epoch 81/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7993 - accuracy: 0.6855 - val_loss: 0.6284 - val_accuracy: 0.7772\n",
            "Epoch 82/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.7874 - accuracy: 0.6957 - val_loss: 0.6239 - val_accuracy: 0.7891\n",
            "Epoch 83/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8046 - accuracy: 0.6778 - val_loss: 0.6334 - val_accuracy: 0.7789\n",
            "Epoch 84/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7521 - accuracy: 0.7015 - val_loss: 0.6062 - val_accuracy: 0.7917\n",
            "Epoch 85/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.6942 - val_loss: 0.6033 - val_accuracy: 0.7900\n",
            "Epoch 86/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8052 - accuracy: 0.6826 - val_loss: 0.6015 - val_accuracy: 0.7993\n",
            "Epoch 87/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7824 - accuracy: 0.7037 - val_loss: 0.6237 - val_accuracy: 0.7670\n",
            "Epoch 88/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7644 - accuracy: 0.7026 - val_loss: 0.6100 - val_accuracy: 0.7925\n",
            "Epoch 89/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7539 - accuracy: 0.7128 - val_loss: 0.5995 - val_accuracy: 0.7925\n",
            "Epoch 90/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7601 - accuracy: 0.6990 - val_loss: 0.5981 - val_accuracy: 0.8019\n",
            "Epoch 91/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7370 - accuracy: 0.7092 - val_loss: 0.5729 - val_accuracy: 0.8104\n",
            "Epoch 92/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7579 - accuracy: 0.6997 - val_loss: 0.5592 - val_accuracy: 0.8240\n",
            "Epoch 93/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7249 - accuracy: 0.7136 - val_loss: 0.5618 - val_accuracy: 0.8316\n",
            "Epoch 94/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7294 - accuracy: 0.7168 - val_loss: 0.5548 - val_accuracy: 0.8197\n",
            "Epoch 95/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.7176 - val_loss: 0.5444 - val_accuracy: 0.8435\n",
            "Epoch 96/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7259 - accuracy: 0.7161 - val_loss: 0.5483 - val_accuracy: 0.8197\n",
            "Epoch 97/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7346 - accuracy: 0.7136 - val_loss: 0.5503 - val_accuracy: 0.8121\n",
            "Epoch 98/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7389 - accuracy: 0.7059 - val_loss: 0.5557 - val_accuracy: 0.7883\n",
            "Epoch 99/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.7227 - val_loss: 0.5656 - val_accuracy: 0.7985\n",
            "Epoch 100/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7054 - accuracy: 0.7292 - val_loss: 0.5375 - val_accuracy: 0.8112\n",
            "Epoch 101/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7260 - accuracy: 0.7092 - val_loss: 0.5557 - val_accuracy: 0.8070\n",
            "Epoch 102/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.7085 - val_loss: 0.5462 - val_accuracy: 0.8265\n",
            "Epoch 103/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7222 - accuracy: 0.7026 - val_loss: 0.5425 - val_accuracy: 0.8274\n",
            "Epoch 104/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7044 - accuracy: 0.7157 - val_loss: 0.5256 - val_accuracy: 0.8282\n",
            "Epoch 105/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.7208 - val_loss: 0.5272 - val_accuracy: 0.8214\n",
            "Epoch 106/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6776 - accuracy: 0.7358 - val_loss: 0.5375 - val_accuracy: 0.8214\n",
            "Epoch 107/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7066 - accuracy: 0.7194 - val_loss: 0.5141 - val_accuracy: 0.8401\n",
            "Epoch 108/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7197 - accuracy: 0.7092 - val_loss: 0.5269 - val_accuracy: 0.8197\n",
            "Epoch 109/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.7347 - val_loss: 0.5482 - val_accuracy: 0.8240\n",
            "Epoch 110/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.7201 - val_loss: 0.5180 - val_accuracy: 0.8308\n",
            "Epoch 111/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.7402 - val_loss: 0.5147 - val_accuracy: 0.8350\n",
            "Epoch 112/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.7442 - val_loss: 0.4949 - val_accuracy: 0.8503\n",
            "Epoch 113/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.7434 - val_loss: 0.5003 - val_accuracy: 0.8282\n",
            "Epoch 114/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.7482 - val_loss: 0.4934 - val_accuracy: 0.8469\n",
            "Epoch 115/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.7482 - val_loss: 0.5025 - val_accuracy: 0.8350\n",
            "Epoch 116/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6974 - accuracy: 0.7216 - val_loss: 0.4996 - val_accuracy: 0.8274\n",
            "Epoch 117/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6564 - accuracy: 0.7449 - val_loss: 0.4772 - val_accuracy: 0.8444\n",
            "Epoch 118/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6663 - accuracy: 0.7431 - val_loss: 0.4940 - val_accuracy: 0.8401\n",
            "Epoch 119/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.7500 - val_loss: 0.4824 - val_accuracy: 0.8444\n",
            "Epoch 120/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.7434 - val_loss: 0.4613 - val_accuracy: 0.8665\n",
            "Epoch 121/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7369 - val_loss: 0.4735 - val_accuracy: 0.8656\n",
            "Epoch 122/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.7649 - val_loss: 0.4639 - val_accuracy: 0.8469\n",
            "Epoch 123/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.7569 - val_loss: 0.4650 - val_accuracy: 0.8554\n",
            "Epoch 124/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.7354 - val_loss: 0.5033 - val_accuracy: 0.8282\n",
            "Epoch 125/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7427 - val_loss: 0.4942 - val_accuracy: 0.8333\n",
            "Epoch 126/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.7569 - val_loss: 0.4935 - val_accuracy: 0.8299\n",
            "Epoch 127/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7635 - val_loss: 0.4684 - val_accuracy: 0.8563\n",
            "Epoch 128/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.7584 - val_loss: 0.4792 - val_accuracy: 0.8274\n",
            "Epoch 129/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.7482 - val_loss: 0.4518 - val_accuracy: 0.8580\n",
            "Epoch 130/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7730 - val_loss: 0.4669 - val_accuracy: 0.8418\n",
            "Epoch 131/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7558 - val_loss: 0.4693 - val_accuracy: 0.8376\n",
            "Epoch 132/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6151 - accuracy: 0.7613 - val_loss: 0.4656 - val_accuracy: 0.8316\n",
            "Epoch 133/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6051 - accuracy: 0.7635 - val_loss: 0.4615 - val_accuracy: 0.8563\n",
            "Epoch 134/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.7522 - val_loss: 0.4742 - val_accuracy: 0.8299\n",
            "Epoch 135/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.7580 - val_loss: 0.4417 - val_accuracy: 0.8690\n",
            "Epoch 136/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6050 - accuracy: 0.7587 - val_loss: 0.4558 - val_accuracy: 0.8605\n",
            "Epoch 137/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.7646 - val_loss: 0.4642 - val_accuracy: 0.8461\n",
            "Epoch 138/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.7577 - val_loss: 0.4432 - val_accuracy: 0.8639\n",
            "Epoch 139/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7591 - val_loss: 0.4305 - val_accuracy: 0.8759\n",
            "Epoch 140/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7653 - val_loss: 0.4458 - val_accuracy: 0.8605\n",
            "Epoch 141/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7700 - val_loss: 0.4372 - val_accuracy: 0.8571\n",
            "Epoch 142/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.7660 - val_loss: 0.4303 - val_accuracy: 0.8741\n",
            "Epoch 143/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5826 - accuracy: 0.7726 - val_loss: 0.4384 - val_accuracy: 0.8554\n",
            "Epoch 144/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5867 - accuracy: 0.7711 - val_loss: 0.4418 - val_accuracy: 0.8529\n",
            "Epoch 145/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.7679 - val_loss: 0.4383 - val_accuracy: 0.8605\n",
            "Epoch 146/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.7781 - val_loss: 0.4364 - val_accuracy: 0.8520\n",
            "Epoch 147/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7777 - val_loss: 0.4397 - val_accuracy: 0.8571\n",
            "Epoch 148/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7598 - val_loss: 0.4521 - val_accuracy: 0.8427\n",
            "Epoch 149/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7773 - val_loss: 0.4386 - val_accuracy: 0.8461\n",
            "Epoch 150/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7759 - val_loss: 0.4431 - val_accuracy: 0.8486\n",
            "Epoch 151/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7773 - val_loss: 0.3953 - val_accuracy: 0.8793\n",
            "Epoch 152/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7846 - val_loss: 0.4466 - val_accuracy: 0.8495\n",
            "Epoch 153/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.7802 - val_loss: 0.4299 - val_accuracy: 0.8631\n",
            "Epoch 154/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5561 - accuracy: 0.7828 - val_loss: 0.4062 - val_accuracy: 0.8724\n",
            "Epoch 155/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7773 - val_loss: 0.4217 - val_accuracy: 0.8597\n",
            "Epoch 156/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7886 - val_loss: 0.4367 - val_accuracy: 0.8469\n",
            "Epoch 157/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.7773 - val_loss: 0.4171 - val_accuracy: 0.8724\n",
            "Epoch 158/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.7690 - val_loss: 0.4456 - val_accuracy: 0.8512\n",
            "Epoch 159/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.7788 - val_loss: 0.4352 - val_accuracy: 0.8588\n",
            "Epoch 160/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7864 - val_loss: 0.4462 - val_accuracy: 0.8503\n",
            "Epoch 161/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7857 - val_loss: 0.4233 - val_accuracy: 0.8707\n",
            "Epoch 162/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7857 - val_loss: 0.3988 - val_accuracy: 0.8827\n",
            "Epoch 163/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7945 - val_loss: 0.4355 - val_accuracy: 0.8546\n",
            "Epoch 164/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7864 - val_loss: 0.3993 - val_accuracy: 0.8920\n",
            "Epoch 165/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.7828 - val_loss: 0.3881 - val_accuracy: 0.8852\n",
            "Epoch 166/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7850 - val_loss: 0.4219 - val_accuracy: 0.8639\n",
            "Epoch 167/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.8050 - val_loss: 0.3877 - val_accuracy: 0.8869\n",
            "Epoch 168/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7941 - val_loss: 0.3834 - val_accuracy: 0.8886\n",
            "Epoch 169/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7966 - val_loss: 0.4123 - val_accuracy: 0.8776\n",
            "Epoch 170/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7985 - val_loss: 0.3688 - val_accuracy: 0.8776\n",
            "Epoch 171/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.8054 - val_loss: 0.3804 - val_accuracy: 0.8835\n",
            "Epoch 172/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7879 - val_loss: 0.3911 - val_accuracy: 0.8818\n",
            "Epoch 173/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.8032 - val_loss: 0.4023 - val_accuracy: 0.8707\n",
            "Epoch 174/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7996 - val_loss: 0.4521 - val_accuracy: 0.8478\n",
            "Epoch 175/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7908 - val_loss: 0.3990 - val_accuracy: 0.8759\n",
            "Epoch 176/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7912 - val_loss: 0.4032 - val_accuracy: 0.8571\n",
            "Epoch 177/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.8007 - val_loss: 0.4246 - val_accuracy: 0.8520\n",
            "Epoch 178/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7963 - val_loss: 0.3788 - val_accuracy: 0.8801\n",
            "Epoch 179/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.8025 - val_loss: 0.3967 - val_accuracy: 0.8869\n",
            "Epoch 180/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.7985 - val_loss: 0.4057 - val_accuracy: 0.8656\n",
            "Epoch 181/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7952 - val_loss: 0.4129 - val_accuracy: 0.8512\n",
            "Epoch 182/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.8094 - val_loss: 0.3969 - val_accuracy: 0.8563\n",
            "Epoch 183/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.8076 - val_loss: 0.3804 - val_accuracy: 0.8733\n",
            "Epoch 184/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7912 - val_loss: 0.3771 - val_accuracy: 0.8767\n",
            "Epoch 185/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.8087 - val_loss: 0.3798 - val_accuracy: 0.8878\n",
            "Epoch 186/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7952 - val_loss: 0.4131 - val_accuracy: 0.8469\n",
            "Epoch 187/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.8014 - val_loss: 0.3716 - val_accuracy: 0.8741\n",
            "Epoch 188/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7948 - val_loss: 0.3648 - val_accuracy: 0.8895\n",
            "Epoch 189/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7974 - val_loss: 0.3839 - val_accuracy: 0.8588\n",
            "Epoch 190/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.8076 - val_loss: 0.3636 - val_accuracy: 0.8963\n",
            "Epoch 191/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.8109 - val_loss: 0.3607 - val_accuracy: 0.8767\n",
            "Epoch 192/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.8098 - val_loss: 0.3794 - val_accuracy: 0.8631\n",
            "Epoch 193/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.8007 - val_loss: 0.4666 - val_accuracy: 0.8078\n",
            "Epoch 194/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.8050 - val_loss: 0.3582 - val_accuracy: 0.8835\n",
            "Epoch 195/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.8061 - val_loss: 0.3438 - val_accuracy: 0.8801\n",
            "Epoch 196/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.8211 - val_loss: 0.3697 - val_accuracy: 0.8793\n",
            "Epoch 197/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.8185 - val_loss: 0.3934 - val_accuracy: 0.8690\n",
            "Epoch 198/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.8163 - val_loss: 0.3603 - val_accuracy: 0.8835\n",
            "Epoch 199/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.8163 - val_loss: 0.3417 - val_accuracy: 0.8937\n",
            "Epoch 200/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.8174 - val_loss: 0.3916 - val_accuracy: 0.8580\n",
            "Epoch 201/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.8116 - val_loss: 0.3874 - val_accuracy: 0.8682\n",
            "Epoch 202/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8196 - val_loss: 0.3831 - val_accuracy: 0.8750\n",
            "Epoch 203/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.8163 - val_loss: 0.3654 - val_accuracy: 0.8827\n",
            "Epoch 204/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.8225 - val_loss: 0.3264 - val_accuracy: 0.9082\n",
            "Epoch 205/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.8152 - val_loss: 0.3587 - val_accuracy: 0.8852\n",
            "Epoch 206/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.8076 - val_loss: 0.3681 - val_accuracy: 0.8827\n",
            "Epoch 207/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.8262 - val_loss: 0.3733 - val_accuracy: 0.8801\n",
            "Epoch 208/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.8203 - val_loss: 0.3686 - val_accuracy: 0.8835\n",
            "Epoch 209/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.8280 - val_loss: 0.3836 - val_accuracy: 0.8682\n",
            "Epoch 210/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.8258 - val_loss: 0.3419 - val_accuracy: 0.8946\n",
            "Epoch 211/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.8233 - val_loss: 0.3463 - val_accuracy: 0.8861\n",
            "Epoch 212/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8160 - val_loss: 0.3555 - val_accuracy: 0.8818\n",
            "Epoch 213/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.8233 - val_loss: 0.3654 - val_accuracy: 0.8759\n",
            "Epoch 214/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.8298 - val_loss: 0.3421 - val_accuracy: 0.8929\n",
            "Epoch 215/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.8251 - val_loss: 0.3897 - val_accuracy: 0.8665\n",
            "Epoch 216/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.8265 - val_loss: 0.3538 - val_accuracy: 0.8903\n",
            "Epoch 217/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8265 - val_loss: 0.3411 - val_accuracy: 0.8886\n",
            "Epoch 218/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8386 - val_loss: 0.3647 - val_accuracy: 0.8903\n",
            "Epoch 219/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8302 - val_loss: 0.3449 - val_accuracy: 0.8835\n",
            "Epoch 220/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.8211 - val_loss: 0.3354 - val_accuracy: 0.9090\n",
            "Epoch 221/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.8192 - val_loss: 0.3541 - val_accuracy: 0.8852\n",
            "Epoch 222/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.8214 - val_loss: 0.3533 - val_accuracy: 0.8716\n",
            "Epoch 223/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8338 - val_loss: 0.3447 - val_accuracy: 0.9014\n",
            "Epoch 224/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.8163 - val_loss: 0.3596 - val_accuracy: 0.8733\n",
            "Epoch 225/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.8222 - val_loss: 0.3810 - val_accuracy: 0.8699\n",
            "Epoch 226/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8251 - val_loss: 0.3373 - val_accuracy: 0.8903\n",
            "Epoch 227/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8273 - val_loss: 0.3724 - val_accuracy: 0.8716\n",
            "Epoch 228/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8345 - val_loss: 0.3341 - val_accuracy: 0.9039\n",
            "Epoch 229/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8473 - val_loss: 0.3464 - val_accuracy: 0.8835\n",
            "Epoch 230/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.8324 - val_loss: 0.3515 - val_accuracy: 0.8750\n",
            "Epoch 231/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8349 - val_loss: 0.3203 - val_accuracy: 0.8954\n",
            "Epoch 232/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8331 - val_loss: 0.3369 - val_accuracy: 0.8920\n",
            "Epoch 233/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8276 - val_loss: 0.3371 - val_accuracy: 0.8954\n",
            "Epoch 234/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8353 - val_loss: 0.3646 - val_accuracy: 0.8750\n",
            "Epoch 235/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8335 - val_loss: 0.3335 - val_accuracy: 0.8920\n",
            "Epoch 236/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8236 - val_loss: 0.3223 - val_accuracy: 0.9056\n",
            "Epoch 237/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8342 - val_loss: 0.3352 - val_accuracy: 0.8988\n",
            "Epoch 238/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8367 - val_loss: 0.4011 - val_accuracy: 0.8571\n",
            "Epoch 239/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.8411 - val_loss: 0.3344 - val_accuracy: 0.9031\n",
            "Epoch 240/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8251 - val_loss: 0.3481 - val_accuracy: 0.8895\n",
            "Epoch 241/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8342 - val_loss: 0.3480 - val_accuracy: 0.8937\n",
            "Epoch 242/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8418 - val_loss: 0.3206 - val_accuracy: 0.9056\n",
            "Epoch 243/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8397 - val_loss: 0.3510 - val_accuracy: 0.8818\n",
            "Epoch 244/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8291 - val_loss: 0.3284 - val_accuracy: 0.8946\n",
            "Epoch 245/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8437 - val_loss: 0.3212 - val_accuracy: 0.9073\n",
            "Epoch 246/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8404 - val_loss: 0.3167 - val_accuracy: 0.9031\n",
            "Epoch 247/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8382 - val_loss: 0.3916 - val_accuracy: 0.8478\n",
            "Epoch 248/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8291 - val_loss: 0.3502 - val_accuracy: 0.8844\n",
            "Epoch 249/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8324 - val_loss: 0.3523 - val_accuracy: 0.8767\n",
            "Epoch 250/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8437 - val_loss: 0.3212 - val_accuracy: 0.8954\n",
            "Epoch 251/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8455 - val_loss: 0.3423 - val_accuracy: 0.8912\n",
            "Epoch 252/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8364 - val_loss: 0.3454 - val_accuracy: 0.8912\n",
            "Epoch 253/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8411 - val_loss: 0.3731 - val_accuracy: 0.8724\n",
            "Epoch 254/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8360 - val_loss: 0.3354 - val_accuracy: 0.9005\n",
            "Epoch 255/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8495 - val_loss: 0.3312 - val_accuracy: 0.8920\n",
            "Epoch 256/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8360 - val_loss: 0.3335 - val_accuracy: 0.8793\n",
            "Epoch 257/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8345 - val_loss: 0.3430 - val_accuracy: 0.8929\n",
            "Epoch 258/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8338 - val_loss: 0.3690 - val_accuracy: 0.8631\n",
            "Epoch 259/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8349 - val_loss: 0.3150 - val_accuracy: 0.8997\n",
            "Epoch 260/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8378 - val_loss: 0.3858 - val_accuracy: 0.8639\n",
            "Epoch 261/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8404 - val_loss: 0.3233 - val_accuracy: 0.8988\n",
            "Epoch 262/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8466 - val_loss: 0.3316 - val_accuracy: 0.8861\n",
            "Epoch 263/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8407 - val_loss: 0.3196 - val_accuracy: 0.8954\n",
            "Epoch 264/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8528 - val_loss: 0.3744 - val_accuracy: 0.8665\n",
            "Epoch 265/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8458 - val_loss: 0.3355 - val_accuracy: 0.8895\n",
            "Epoch 266/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8520 - val_loss: 0.3173 - val_accuracy: 0.9031\n",
            "Epoch 267/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8586 - val_loss: 0.3091 - val_accuracy: 0.9031\n",
            "Epoch 268/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8517 - val_loss: 0.3499 - val_accuracy: 0.8682\n",
            "Epoch 269/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8553 - val_loss: 0.3211 - val_accuracy: 0.9099\n",
            "Epoch 270/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8280 - val_loss: 0.3668 - val_accuracy: 0.8707\n",
            "Epoch 271/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8571 - val_loss: 0.3700 - val_accuracy: 0.8759\n",
            "Epoch 272/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8491 - val_loss: 0.2926 - val_accuracy: 0.9090\n",
            "Epoch 273/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8513 - val_loss: 0.2872 - val_accuracy: 0.9141\n",
            "Epoch 274/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8400 - val_loss: 0.3576 - val_accuracy: 0.8793\n",
            "Epoch 275/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8480 - val_loss: 0.3760 - val_accuracy: 0.8597\n",
            "Epoch 276/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8542 - val_loss: 0.3001 - val_accuracy: 0.8988\n",
            "Epoch 277/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8484 - val_loss: 0.3048 - val_accuracy: 0.8886\n",
            "Epoch 278/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8550 - val_loss: 0.3170 - val_accuracy: 0.8903\n",
            "Epoch 279/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8499 - val_loss: 0.2860 - val_accuracy: 0.9141\n",
            "Epoch 280/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8560 - val_loss: 0.2939 - val_accuracy: 0.9133\n",
            "Epoch 281/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8550 - val_loss: 0.3129 - val_accuracy: 0.9014\n",
            "Epoch 282/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8542 - val_loss: 0.3155 - val_accuracy: 0.8963\n",
            "Epoch 283/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8466 - val_loss: 0.3073 - val_accuracy: 0.8971\n",
            "Epoch 284/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8506 - val_loss: 0.3101 - val_accuracy: 0.9124\n",
            "Epoch 285/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8491 - val_loss: 0.3260 - val_accuracy: 0.8980\n",
            "Epoch 286/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8590 - val_loss: 0.2737 - val_accuracy: 0.9226\n",
            "Epoch 287/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8513 - val_loss: 0.2877 - val_accuracy: 0.9116\n",
            "Epoch 288/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8524 - val_loss: 0.3268 - val_accuracy: 0.8784\n",
            "Epoch 289/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8433 - val_loss: 0.3466 - val_accuracy: 0.8827\n",
            "Epoch 290/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8550 - val_loss: 0.3323 - val_accuracy: 0.8844\n",
            "Epoch 291/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8564 - val_loss: 0.3229 - val_accuracy: 0.8954\n",
            "Epoch 292/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8491 - val_loss: 0.3514 - val_accuracy: 0.8793\n",
            "Epoch 293/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8531 - val_loss: 0.3540 - val_accuracy: 0.8801\n",
            "Epoch 294/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8542 - val_loss: 0.3527 - val_accuracy: 0.8810\n",
            "Epoch 295/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8630 - val_loss: 0.3271 - val_accuracy: 0.8912\n",
            "Epoch 296/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8586 - val_loss: 0.3146 - val_accuracy: 0.9022\n",
            "Epoch 297/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8564 - val_loss: 0.3370 - val_accuracy: 0.8835\n",
            "Epoch 298/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8466 - val_loss: 0.3527 - val_accuracy: 0.8818\n",
            "Epoch 299/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8499 - val_loss: 0.3094 - val_accuracy: 0.9039\n",
            "Epoch 300/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8477 - val_loss: 0.3348 - val_accuracy: 0.8912\n",
            "Epoch 301/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8542 - val_loss: 0.3642 - val_accuracy: 0.8656\n",
            "Epoch 302/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8608 - val_loss: 0.3613 - val_accuracy: 0.8690\n",
            "Epoch 303/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8692 - val_loss: 0.3450 - val_accuracy: 0.8759\n",
            "Epoch 304/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8608 - val_loss: 0.3336 - val_accuracy: 0.8920\n",
            "Epoch 305/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8560 - val_loss: 0.3932 - val_accuracy: 0.8520\n",
            "Epoch 306/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8666 - val_loss: 0.3023 - val_accuracy: 0.9099\n",
            "Epoch 307/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8663 - val_loss: 0.3156 - val_accuracy: 0.8963\n",
            "Epoch 308/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8677 - val_loss: 0.2984 - val_accuracy: 0.9065\n",
            "Epoch 309/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8648 - val_loss: 0.3214 - val_accuracy: 0.9005\n",
            "Epoch 310/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8604 - val_loss: 0.3003 - val_accuracy: 0.9039\n",
            "Epoch 311/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8648 - val_loss: 0.3258 - val_accuracy: 0.9005\n",
            "Epoch 312/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8692 - val_loss: 0.3129 - val_accuracy: 0.8954\n",
            "Epoch 313/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8641 - val_loss: 0.3121 - val_accuracy: 0.8954\n",
            "Epoch 314/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8601 - val_loss: 0.3363 - val_accuracy: 0.8869\n",
            "Epoch 315/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8673 - val_loss: 0.2997 - val_accuracy: 0.8946\n",
            "Epoch 316/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8794 - val_loss: 0.2774 - val_accuracy: 0.9133\n",
            "Epoch 317/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8633 - val_loss: 0.3157 - val_accuracy: 0.8954\n",
            "Epoch 318/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8637 - val_loss: 0.3582 - val_accuracy: 0.8801\n",
            "Epoch 319/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8619 - val_loss: 0.2889 - val_accuracy: 0.9133\n",
            "Epoch 320/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8743 - val_loss: 0.3595 - val_accuracy: 0.8622\n",
            "Epoch 321/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8524 - val_loss: 0.3089 - val_accuracy: 0.8971\n",
            "Epoch 322/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8670 - val_loss: 0.3015 - val_accuracy: 0.9065\n",
            "Epoch 323/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8757 - val_loss: 0.3170 - val_accuracy: 0.8861\n",
            "Epoch 324/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3534 - accuracy: 0.8593 - val_loss: 0.3284 - val_accuracy: 0.8861\n",
            "Epoch 325/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8633 - val_loss: 0.3561 - val_accuracy: 0.8759\n",
            "Epoch 326/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.8688 - val_loss: 0.3102 - val_accuracy: 0.9048\n",
            "Epoch 327/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8783 - val_loss: 0.3279 - val_accuracy: 0.8793\n",
            "Epoch 328/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8797 - val_loss: 0.3232 - val_accuracy: 0.8835\n",
            "Epoch 329/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8626 - val_loss: 0.3190 - val_accuracy: 0.8844\n",
            "Epoch 330/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8717 - val_loss: 0.3150 - val_accuracy: 0.8929\n",
            "Epoch 331/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8724 - val_loss: 0.3482 - val_accuracy: 0.8665\n",
            "Epoch 332/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8684 - val_loss: 0.3008 - val_accuracy: 0.9056\n",
            "Epoch 333/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8593 - val_loss: 0.3030 - val_accuracy: 0.9022\n",
            "Epoch 334/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8721 - val_loss: 0.3048 - val_accuracy: 0.9014\n",
            "Epoch 335/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8652 - val_loss: 0.2976 - val_accuracy: 0.9073\n",
            "Epoch 336/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8732 - val_loss: 0.3189 - val_accuracy: 0.8844\n",
            "Epoch 337/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8728 - val_loss: 0.3406 - val_accuracy: 0.8784\n",
            "Epoch 338/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8666 - val_loss: 0.2935 - val_accuracy: 0.9022\n",
            "Epoch 339/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8743 - val_loss: 0.3152 - val_accuracy: 0.8903\n",
            "Epoch 340/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8575 - val_loss: 0.3314 - val_accuracy: 0.8869\n",
            "Epoch 341/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8703 - val_loss: 0.3320 - val_accuracy: 0.8844\n",
            "Epoch 342/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8703 - val_loss: 0.3163 - val_accuracy: 0.8980\n",
            "Epoch 343/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8626 - val_loss: 0.3281 - val_accuracy: 0.8801\n",
            "Epoch 344/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8714 - val_loss: 0.3095 - val_accuracy: 0.9031\n",
            "Epoch 345/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8794 - val_loss: 0.3253 - val_accuracy: 0.8844\n",
            "Epoch 346/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8717 - val_loss: 0.3130 - val_accuracy: 0.8946\n",
            "Epoch 347/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8721 - val_loss: 0.3899 - val_accuracy: 0.8546\n",
            "Epoch 348/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8717 - val_loss: 0.3006 - val_accuracy: 0.9048\n",
            "Epoch 349/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8797 - val_loss: 0.3433 - val_accuracy: 0.8835\n",
            "Epoch 350/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8794 - val_loss: 0.3557 - val_accuracy: 0.8724\n",
            "Epoch 351/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8626 - val_loss: 0.3591 - val_accuracy: 0.8699\n",
            "Epoch 352/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8681 - val_loss: 0.3269 - val_accuracy: 0.8997\n",
            "Epoch 353/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.8703 - val_loss: 0.3475 - val_accuracy: 0.8639\n",
            "Epoch 354/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8619 - val_loss: 0.2955 - val_accuracy: 0.8920\n",
            "Epoch 355/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8794 - val_loss: 0.2829 - val_accuracy: 0.9082\n",
            "Epoch 356/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8746 - val_loss: 0.2999 - val_accuracy: 0.8852\n",
            "Epoch 357/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8652 - val_loss: 0.3142 - val_accuracy: 0.8810\n",
            "Epoch 358/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8699 - val_loss: 0.3169 - val_accuracy: 0.8827\n",
            "Epoch 359/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.8863 - val_loss: 0.2986 - val_accuracy: 0.9014\n",
            "Epoch 360/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8819 - val_loss: 0.3324 - val_accuracy: 0.8818\n",
            "Epoch 361/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8732 - val_loss: 0.3418 - val_accuracy: 0.8741\n",
            "Epoch 362/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3190 - accuracy: 0.8790 - val_loss: 0.3878 - val_accuracy: 0.8631\n",
            "Epoch 363/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3152 - accuracy: 0.8816 - val_loss: 0.3402 - val_accuracy: 0.8886\n",
            "Epoch 364/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8768 - val_loss: 0.3315 - val_accuracy: 0.8818\n",
            "Epoch 365/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3246 - accuracy: 0.8801 - val_loss: 0.3177 - val_accuracy: 0.8827\n",
            "Epoch 366/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8830 - val_loss: 0.3159 - val_accuracy: 0.8835\n",
            "Epoch 367/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8797 - val_loss: 0.2860 - val_accuracy: 0.9082\n",
            "Epoch 368/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.8932 - val_loss: 0.3007 - val_accuracy: 0.9048\n",
            "Epoch 369/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8823 - val_loss: 0.3268 - val_accuracy: 0.8776\n",
            "Epoch 370/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8794 - val_loss: 0.3213 - val_accuracy: 0.8861\n",
            "Epoch 371/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8786 - val_loss: 0.3093 - val_accuracy: 0.8929\n",
            "Epoch 372/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8768 - val_loss: 0.2860 - val_accuracy: 0.9082\n",
            "Epoch 373/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8732 - val_loss: 0.3491 - val_accuracy: 0.8656\n",
            "Epoch 374/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3099 - accuracy: 0.8794 - val_loss: 0.2803 - val_accuracy: 0.9158\n",
            "Epoch 375/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8830 - val_loss: 0.3039 - val_accuracy: 0.8988\n",
            "Epoch 376/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8732 - val_loss: 0.2970 - val_accuracy: 0.9031\n",
            "Epoch 377/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8750 - val_loss: 0.3095 - val_accuracy: 0.8963\n",
            "Epoch 378/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8670 - val_loss: 0.3396 - val_accuracy: 0.8759\n",
            "Epoch 379/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8688 - val_loss: 0.3327 - val_accuracy: 0.8920\n",
            "Epoch 380/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8819 - val_loss: 0.3030 - val_accuracy: 0.9022\n",
            "Epoch 381/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8794 - val_loss: 0.3223 - val_accuracy: 0.8827\n",
            "Epoch 382/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8914 - val_loss: 0.2978 - val_accuracy: 0.9031\n",
            "Epoch 383/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8856 - val_loss: 0.3739 - val_accuracy: 0.8571\n",
            "Epoch 384/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8819 - val_loss: 0.3278 - val_accuracy: 0.8784\n",
            "Epoch 385/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8856 - val_loss: 0.3890 - val_accuracy: 0.8546\n",
            "Epoch 386/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8819 - val_loss: 0.2926 - val_accuracy: 0.9073\n",
            "Epoch 387/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.8786 - val_loss: 0.3272 - val_accuracy: 0.8869\n",
            "Epoch 388/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8874 - val_loss: 0.3624 - val_accuracy: 0.8597\n",
            "Epoch 389/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8848 - val_loss: 0.3091 - val_accuracy: 0.8997\n",
            "Epoch 390/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8808 - val_loss: 0.3140 - val_accuracy: 0.8920\n",
            "Epoch 391/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.8936 - val_loss: 0.3369 - val_accuracy: 0.8699\n",
            "Epoch 392/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.8834 - val_loss: 0.3658 - val_accuracy: 0.8520\n",
            "Epoch 393/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8827 - val_loss: 0.2932 - val_accuracy: 0.9056\n",
            "Epoch 394/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8918 - val_loss: 0.3417 - val_accuracy: 0.8776\n",
            "Epoch 395/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8896 - val_loss: 0.3013 - val_accuracy: 0.8946\n",
            "Epoch 396/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8779 - val_loss: 0.3237 - val_accuracy: 0.8810\n",
            "Epoch 397/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8918 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
            "Epoch 398/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8870 - val_loss: 0.3630 - val_accuracy: 0.8707\n",
            "Epoch 399/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3077 - accuracy: 0.8801 - val_loss: 0.3429 - val_accuracy: 0.8776\n",
            "Epoch 400/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3012 - accuracy: 0.8856 - val_loss: 0.3276 - val_accuracy: 0.8852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dtw1E_Awrpvi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "15228daf-8c83-46e5-e6b8-ca06b90db587"
      },
      "source": [
        "plt.plot(classifier.history['loss'])\n",
        "plt.plot(classifier.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0IHzel09rpvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0fcadb8a-0da1-4978-fcfa-729196d0d92a"
      },
      "source": [
        "plt.plot(classifier.history['accuracy'])\n",
        "plt.plot(classifier.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BJa7gHUirpvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f4e1363a-ceee-4164-b0d2-622e5c7f71ca"
      },
      "source": [
        "model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-bc459dba29cd>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 12,  4, ..., 13, 12, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uu-tUeGnrpvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68c34018-4e9f-4793-ebdd-a7656c01bcc1"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 12,  4, ..., 13, 12, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ECpdEjS4rpvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5a99eeeb-5ae4-4a7d-a71d-bb849f02af4e"
      },
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3275521993637085, 0.8852040767669678]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqFygT70t0AH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "21f47841-9fb6-4b8a-98d0-279cd8f56f35"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv1D(32,3, activation = \"relu\",padding = 'same', input_shape=input_shape))\n",
        "model.add(layers.Conv1D(64,3,activation = 'relu',padding = 'same'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64,activation = 'relu'))\n",
        "model.add(layers.Dense(20,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1, 32)             2624      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1, 64)             6208      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                1300      \n",
            "=================================================================\n",
            "Total params: 14,292\n",
            "Trainable params: 14,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5G-IEL2w19s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSopc7vuygbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6e817f4-3a85-4507-f742-b559a3050c62"
      },
      "source": [
        "classifier = model.fit(X_train, y_train,batch_size=128, epochs=400, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 2.9897 - accuracy: 0.0645 - val_loss: 2.9693 - val_accuracy: 0.0927\n",
            "Epoch 2/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.9555 - accuracy: 0.1042 - val_loss: 2.9371 - val_accuracy: 0.1369\n",
            "Epoch 3/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 2.8979 - accuracy: 0.1370 - val_loss: 2.8685 - val_accuracy: 0.1446\n",
            "Epoch 4/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.8039 - accuracy: 0.1531 - val_loss: 2.7252 - val_accuracy: 0.1769\n",
            "Epoch 5/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.6239 - accuracy: 0.1771 - val_loss: 2.4922 - val_accuracy: 0.1896\n",
            "Epoch 6/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 2.3955 - accuracy: 0.2085 - val_loss: 2.2284 - val_accuracy: 0.2543\n",
            "Epoch 7/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.1861 - accuracy: 0.2540 - val_loss: 2.0291 - val_accuracy: 0.2985\n",
            "Epoch 8/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 2.0383 - accuracy: 0.2638 - val_loss: 1.8916 - val_accuracy: 0.3401\n",
            "Epoch 9/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.9314 - accuracy: 0.3174 - val_loss: 1.7985 - val_accuracy: 0.3639\n",
            "Epoch 10/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.8521 - accuracy: 0.3342 - val_loss: 1.7123 - val_accuracy: 0.3818\n",
            "Epoch 11/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.7767 - accuracy: 0.3462 - val_loss: 1.6514 - val_accuracy: 0.4192\n",
            "Epoch 12/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.7417 - accuracy: 0.3553 - val_loss: 1.5981 - val_accuracy: 0.4252\n",
            "Epoch 13/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.6786 - accuracy: 0.3867 - val_loss: 1.5348 - val_accuracy: 0.4515\n",
            "Epoch 14/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.6360 - accuracy: 0.3837 - val_loss: 1.4956 - val_accuracy: 0.4770\n",
            "Epoch 15/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.5850 - accuracy: 0.3991 - val_loss: 1.4423 - val_accuracy: 0.4600\n",
            "Epoch 16/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.5634 - accuracy: 0.4100 - val_loss: 1.4068 - val_accuracy: 0.4796\n",
            "Epoch 17/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.5233 - accuracy: 0.4165 - val_loss: 1.3593 - val_accuracy: 0.5298\n",
            "Epoch 18/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 1.4855 - accuracy: 0.4282 - val_loss: 1.3306 - val_accuracy: 0.5417\n",
            "Epoch 19/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.4413 - accuracy: 0.4453 - val_loss: 1.2863 - val_accuracy: 0.5672\n",
            "Epoch 20/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.4235 - accuracy: 0.4472 - val_loss: 1.2668 - val_accuracy: 0.5502\n",
            "Epoch 21/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.4042 - accuracy: 0.4435 - val_loss: 1.2417 - val_accuracy: 0.5570\n",
            "Epoch 22/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.3680 - accuracy: 0.4774 - val_loss: 1.2265 - val_accuracy: 0.5663\n",
            "Epoch 23/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.3702 - accuracy: 0.4749 - val_loss: 1.1976 - val_accuracy: 0.5893\n",
            "Epoch 24/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.3336 - accuracy: 0.4832 - val_loss: 1.1871 - val_accuracy: 0.5765\n",
            "Epoch 25/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.3132 - accuracy: 0.4931 - val_loss: 1.1547 - val_accuracy: 0.5876\n",
            "Epoch 26/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2874 - accuracy: 0.4865 - val_loss: 1.1510 - val_accuracy: 0.6003\n",
            "Epoch 27/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2770 - accuracy: 0.4942 - val_loss: 1.1189 - val_accuracy: 0.6012\n",
            "Epoch 28/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2694 - accuracy: 0.5055 - val_loss: 1.1056 - val_accuracy: 0.6071\n",
            "Epoch 29/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2422 - accuracy: 0.5164 - val_loss: 1.0878 - val_accuracy: 0.6233\n",
            "Epoch 30/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2223 - accuracy: 0.5222 - val_loss: 1.0666 - val_accuracy: 0.6233\n",
            "Epoch 31/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.2207 - accuracy: 0.5248 - val_loss: 1.0516 - val_accuracy: 0.6437\n",
            "Epoch 32/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.1913 - accuracy: 0.5292 - val_loss: 1.0261 - val_accuracy: 0.6446\n",
            "Epoch 33/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1666 - accuracy: 0.5488 - val_loss: 1.0157 - val_accuracy: 0.6556\n",
            "Epoch 34/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1488 - accuracy: 0.5448 - val_loss: 1.0025 - val_accuracy: 0.6607\n",
            "Epoch 35/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1521 - accuracy: 0.5466 - val_loss: 1.0091 - val_accuracy: 0.6259\n",
            "Epoch 36/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 1.1706 - accuracy: 0.5321 - val_loss: 0.9782 - val_accuracy: 0.6556\n",
            "Epoch 37/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.5674 - val_loss: 0.9784 - val_accuracy: 0.6675\n",
            "Epoch 38/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1230 - accuracy: 0.5663 - val_loss: 0.9402 - val_accuracy: 0.6684\n",
            "Epoch 39/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 1.1247 - accuracy: 0.5590 - val_loss: 0.9237 - val_accuracy: 0.6913\n",
            "Epoch 40/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.1074 - accuracy: 0.5758 - val_loss: 0.9236 - val_accuracy: 0.6981\n",
            "Epoch 41/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0853 - accuracy: 0.5845 - val_loss: 0.9245 - val_accuracy: 0.6837\n",
            "Epoch 42/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0643 - accuracy: 0.5776 - val_loss: 0.9279 - val_accuracy: 0.6794\n",
            "Epoch 43/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0704 - accuracy: 0.5754 - val_loss: 0.9347 - val_accuracy: 0.6658\n",
            "Epoch 44/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0470 - accuracy: 0.5824 - val_loss: 0.9000 - val_accuracy: 0.6837\n",
            "Epoch 45/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0323 - accuracy: 0.5980 - val_loss: 0.8833 - val_accuracy: 0.6930\n",
            "Epoch 46/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0222 - accuracy: 0.5951 - val_loss: 0.8625 - val_accuracy: 0.7117\n",
            "Epoch 47/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0292 - accuracy: 0.5948 - val_loss: 0.8370 - val_accuracy: 0.7202\n",
            "Epoch 48/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0234 - accuracy: 0.5835 - val_loss: 0.8363 - val_accuracy: 0.7143\n",
            "Epoch 49/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 1.0024 - accuracy: 0.6119 - val_loss: 0.8375 - val_accuracy: 0.7270\n",
            "Epoch 50/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.9859 - accuracy: 0.6210 - val_loss: 0.8192 - val_accuracy: 0.7313\n",
            "Epoch 51/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9754 - accuracy: 0.6082 - val_loss: 0.8102 - val_accuracy: 0.7347\n",
            "Epoch 52/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9763 - accuracy: 0.6006 - val_loss: 0.8013 - val_accuracy: 0.7270\n",
            "Epoch 53/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.9806 - accuracy: 0.6071 - val_loss: 0.8073 - val_accuracy: 0.7287\n",
            "Epoch 54/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9634 - accuracy: 0.6181 - val_loss: 0.7788 - val_accuracy: 0.7517\n",
            "Epoch 55/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.9351 - accuracy: 0.6396 - val_loss: 0.7938 - val_accuracy: 0.7236\n",
            "Epoch 56/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9456 - accuracy: 0.6257 - val_loss: 0.7883 - val_accuracy: 0.7279\n",
            "Epoch 57/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9590 - accuracy: 0.6224 - val_loss: 0.7785 - val_accuracy: 0.7313\n",
            "Epoch 58/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9217 - accuracy: 0.6385 - val_loss: 0.7583 - val_accuracy: 0.7491\n",
            "Epoch 59/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.9349 - accuracy: 0.6294 - val_loss: 0.7489 - val_accuracy: 0.7611\n",
            "Epoch 60/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9252 - accuracy: 0.6392 - val_loss: 0.7414 - val_accuracy: 0.7611\n",
            "Epoch 61/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8840 - accuracy: 0.6629 - val_loss: 0.7585 - val_accuracy: 0.7347\n",
            "Epoch 62/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9115 - accuracy: 0.6283 - val_loss: 0.7355 - val_accuracy: 0.7466\n",
            "Epoch 63/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8829 - accuracy: 0.6545 - val_loss: 0.7447 - val_accuracy: 0.7466\n",
            "Epoch 64/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9080 - accuracy: 0.6425 - val_loss: 0.7315 - val_accuracy: 0.7594\n",
            "Epoch 65/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8840 - accuracy: 0.6472 - val_loss: 0.7279 - val_accuracy: 0.7577\n",
            "Epoch 66/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.8834 - accuracy: 0.6549 - val_loss: 0.7039 - val_accuracy: 0.7602\n",
            "Epoch 67/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.9023 - accuracy: 0.6407 - val_loss: 0.6924 - val_accuracy: 0.7738\n",
            "Epoch 68/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8636 - accuracy: 0.6567 - val_loss: 0.7098 - val_accuracy: 0.7415\n",
            "Epoch 69/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8723 - accuracy: 0.6552 - val_loss: 0.6692 - val_accuracy: 0.7645\n",
            "Epoch 70/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8697 - accuracy: 0.6542 - val_loss: 0.7022 - val_accuracy: 0.7440\n",
            "Epoch 71/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8492 - accuracy: 0.6509 - val_loss: 0.6806 - val_accuracy: 0.7764\n",
            "Epoch 72/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8434 - accuracy: 0.6687 - val_loss: 0.6569 - val_accuracy: 0.7857\n",
            "Epoch 73/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8401 - accuracy: 0.6636 - val_loss: 0.6651 - val_accuracy: 0.7653\n",
            "Epoch 74/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8424 - accuracy: 0.6742 - val_loss: 0.6627 - val_accuracy: 0.7789\n",
            "Epoch 75/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8307 - accuracy: 0.6691 - val_loss: 0.6365 - val_accuracy: 0.7934\n",
            "Epoch 76/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8200 - accuracy: 0.6851 - val_loss: 0.6544 - val_accuracy: 0.7806\n",
            "Epoch 77/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.6975 - val_loss: 0.6285 - val_accuracy: 0.7832\n",
            "Epoch 78/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8327 - accuracy: 0.6709 - val_loss: 0.6373 - val_accuracy: 0.7959\n",
            "Epoch 79/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.8190 - accuracy: 0.6727 - val_loss: 0.6380 - val_accuracy: 0.7798\n",
            "Epoch 80/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7997 - accuracy: 0.6961 - val_loss: 0.6235 - val_accuracy: 0.7891\n",
            "Epoch 81/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7993 - accuracy: 0.6855 - val_loss: 0.6284 - val_accuracy: 0.7772\n",
            "Epoch 82/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.7874 - accuracy: 0.6957 - val_loss: 0.6239 - val_accuracy: 0.7891\n",
            "Epoch 83/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8046 - accuracy: 0.6778 - val_loss: 0.6334 - val_accuracy: 0.7789\n",
            "Epoch 84/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7521 - accuracy: 0.7015 - val_loss: 0.6062 - val_accuracy: 0.7917\n",
            "Epoch 85/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.6942 - val_loss: 0.6033 - val_accuracy: 0.7900\n",
            "Epoch 86/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.8052 - accuracy: 0.6826 - val_loss: 0.6015 - val_accuracy: 0.7993\n",
            "Epoch 87/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7824 - accuracy: 0.7037 - val_loss: 0.6237 - val_accuracy: 0.7670\n",
            "Epoch 88/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7644 - accuracy: 0.7026 - val_loss: 0.6100 - val_accuracy: 0.7925\n",
            "Epoch 89/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7539 - accuracy: 0.7128 - val_loss: 0.5995 - val_accuracy: 0.7925\n",
            "Epoch 90/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7601 - accuracy: 0.6990 - val_loss: 0.5981 - val_accuracy: 0.8019\n",
            "Epoch 91/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7370 - accuracy: 0.7092 - val_loss: 0.5729 - val_accuracy: 0.8104\n",
            "Epoch 92/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7579 - accuracy: 0.6997 - val_loss: 0.5592 - val_accuracy: 0.8240\n",
            "Epoch 93/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7249 - accuracy: 0.7136 - val_loss: 0.5618 - val_accuracy: 0.8316\n",
            "Epoch 94/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7294 - accuracy: 0.7168 - val_loss: 0.5548 - val_accuracy: 0.8197\n",
            "Epoch 95/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.7176 - val_loss: 0.5444 - val_accuracy: 0.8435\n",
            "Epoch 96/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7259 - accuracy: 0.7161 - val_loss: 0.5483 - val_accuracy: 0.8197\n",
            "Epoch 97/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7346 - accuracy: 0.7136 - val_loss: 0.5503 - val_accuracy: 0.8121\n",
            "Epoch 98/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7389 - accuracy: 0.7059 - val_loss: 0.5557 - val_accuracy: 0.7883\n",
            "Epoch 99/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.7227 - val_loss: 0.5656 - val_accuracy: 0.7985\n",
            "Epoch 100/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7054 - accuracy: 0.7292 - val_loss: 0.5375 - val_accuracy: 0.8112\n",
            "Epoch 101/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7260 - accuracy: 0.7092 - val_loss: 0.5557 - val_accuracy: 0.8070\n",
            "Epoch 102/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.7085 - val_loss: 0.5462 - val_accuracy: 0.8265\n",
            "Epoch 103/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7222 - accuracy: 0.7026 - val_loss: 0.5425 - val_accuracy: 0.8274\n",
            "Epoch 104/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7044 - accuracy: 0.7157 - val_loss: 0.5256 - val_accuracy: 0.8282\n",
            "Epoch 105/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.7208 - val_loss: 0.5272 - val_accuracy: 0.8214\n",
            "Epoch 106/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6776 - accuracy: 0.7358 - val_loss: 0.5375 - val_accuracy: 0.8214\n",
            "Epoch 107/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7066 - accuracy: 0.7194 - val_loss: 0.5141 - val_accuracy: 0.8401\n",
            "Epoch 108/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7197 - accuracy: 0.7092 - val_loss: 0.5269 - val_accuracy: 0.8197\n",
            "Epoch 109/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.7347 - val_loss: 0.5482 - val_accuracy: 0.8240\n",
            "Epoch 110/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.7201 - val_loss: 0.5180 - val_accuracy: 0.8308\n",
            "Epoch 111/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.7402 - val_loss: 0.5147 - val_accuracy: 0.8350\n",
            "Epoch 112/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.7442 - val_loss: 0.4949 - val_accuracy: 0.8503\n",
            "Epoch 113/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.7434 - val_loss: 0.5003 - val_accuracy: 0.8282\n",
            "Epoch 114/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.7482 - val_loss: 0.4934 - val_accuracy: 0.8469\n",
            "Epoch 115/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.7482 - val_loss: 0.5025 - val_accuracy: 0.8350\n",
            "Epoch 116/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6974 - accuracy: 0.7216 - val_loss: 0.4996 - val_accuracy: 0.8274\n",
            "Epoch 117/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6564 - accuracy: 0.7449 - val_loss: 0.4772 - val_accuracy: 0.8444\n",
            "Epoch 118/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6663 - accuracy: 0.7431 - val_loss: 0.4940 - val_accuracy: 0.8401\n",
            "Epoch 119/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.7500 - val_loss: 0.4824 - val_accuracy: 0.8444\n",
            "Epoch 120/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.7434 - val_loss: 0.4613 - val_accuracy: 0.8665\n",
            "Epoch 121/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7369 - val_loss: 0.4735 - val_accuracy: 0.8656\n",
            "Epoch 122/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.7649 - val_loss: 0.4639 - val_accuracy: 0.8469\n",
            "Epoch 123/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.7569 - val_loss: 0.4650 - val_accuracy: 0.8554\n",
            "Epoch 124/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.7354 - val_loss: 0.5033 - val_accuracy: 0.8282\n",
            "Epoch 125/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7427 - val_loss: 0.4942 - val_accuracy: 0.8333\n",
            "Epoch 126/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.7569 - val_loss: 0.4935 - val_accuracy: 0.8299\n",
            "Epoch 127/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7635 - val_loss: 0.4684 - val_accuracy: 0.8563\n",
            "Epoch 128/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.7584 - val_loss: 0.4792 - val_accuracy: 0.8274\n",
            "Epoch 129/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.7482 - val_loss: 0.4518 - val_accuracy: 0.8580\n",
            "Epoch 130/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7730 - val_loss: 0.4669 - val_accuracy: 0.8418\n",
            "Epoch 131/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7558 - val_loss: 0.4693 - val_accuracy: 0.8376\n",
            "Epoch 132/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6151 - accuracy: 0.7613 - val_loss: 0.4656 - val_accuracy: 0.8316\n",
            "Epoch 133/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6051 - accuracy: 0.7635 - val_loss: 0.4615 - val_accuracy: 0.8563\n",
            "Epoch 134/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.7522 - val_loss: 0.4742 - val_accuracy: 0.8299\n",
            "Epoch 135/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.7580 - val_loss: 0.4417 - val_accuracy: 0.8690\n",
            "Epoch 136/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6050 - accuracy: 0.7587 - val_loss: 0.4558 - val_accuracy: 0.8605\n",
            "Epoch 137/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.7646 - val_loss: 0.4642 - val_accuracy: 0.8461\n",
            "Epoch 138/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.7577 - val_loss: 0.4432 - val_accuracy: 0.8639\n",
            "Epoch 139/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7591 - val_loss: 0.4305 - val_accuracy: 0.8759\n",
            "Epoch 140/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7653 - val_loss: 0.4458 - val_accuracy: 0.8605\n",
            "Epoch 141/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7700 - val_loss: 0.4372 - val_accuracy: 0.8571\n",
            "Epoch 142/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.7660 - val_loss: 0.4303 - val_accuracy: 0.8741\n",
            "Epoch 143/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5826 - accuracy: 0.7726 - val_loss: 0.4384 - val_accuracy: 0.8554\n",
            "Epoch 144/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5867 - accuracy: 0.7711 - val_loss: 0.4418 - val_accuracy: 0.8529\n",
            "Epoch 145/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.7679 - val_loss: 0.4383 - val_accuracy: 0.8605\n",
            "Epoch 146/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.7781 - val_loss: 0.4364 - val_accuracy: 0.8520\n",
            "Epoch 147/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7777 - val_loss: 0.4397 - val_accuracy: 0.8571\n",
            "Epoch 148/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7598 - val_loss: 0.4521 - val_accuracy: 0.8427\n",
            "Epoch 149/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7773 - val_loss: 0.4386 - val_accuracy: 0.8461\n",
            "Epoch 150/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5695 - accuracy: 0.7759 - val_loss: 0.4431 - val_accuracy: 0.8486\n",
            "Epoch 151/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7773 - val_loss: 0.3953 - val_accuracy: 0.8793\n",
            "Epoch 152/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7846 - val_loss: 0.4466 - val_accuracy: 0.8495\n",
            "Epoch 153/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.7802 - val_loss: 0.4299 - val_accuracy: 0.8631\n",
            "Epoch 154/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5561 - accuracy: 0.7828 - val_loss: 0.4062 - val_accuracy: 0.8724\n",
            "Epoch 155/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7773 - val_loss: 0.4217 - val_accuracy: 0.8597\n",
            "Epoch 156/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7886 - val_loss: 0.4367 - val_accuracy: 0.8469\n",
            "Epoch 157/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.7773 - val_loss: 0.4171 - val_accuracy: 0.8724\n",
            "Epoch 158/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.7690 - val_loss: 0.4456 - val_accuracy: 0.8512\n",
            "Epoch 159/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.7788 - val_loss: 0.4352 - val_accuracy: 0.8588\n",
            "Epoch 160/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7864 - val_loss: 0.4462 - val_accuracy: 0.8503\n",
            "Epoch 161/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7857 - val_loss: 0.4233 - val_accuracy: 0.8707\n",
            "Epoch 162/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7857 - val_loss: 0.3988 - val_accuracy: 0.8827\n",
            "Epoch 163/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7945 - val_loss: 0.4355 - val_accuracy: 0.8546\n",
            "Epoch 164/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7864 - val_loss: 0.3993 - val_accuracy: 0.8920\n",
            "Epoch 165/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.7828 - val_loss: 0.3881 - val_accuracy: 0.8852\n",
            "Epoch 166/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7850 - val_loss: 0.4219 - val_accuracy: 0.8639\n",
            "Epoch 167/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.8050 - val_loss: 0.3877 - val_accuracy: 0.8869\n",
            "Epoch 168/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7941 - val_loss: 0.3834 - val_accuracy: 0.8886\n",
            "Epoch 169/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7966 - val_loss: 0.4123 - val_accuracy: 0.8776\n",
            "Epoch 170/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7985 - val_loss: 0.3688 - val_accuracy: 0.8776\n",
            "Epoch 171/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.8054 - val_loss: 0.3804 - val_accuracy: 0.8835\n",
            "Epoch 172/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7879 - val_loss: 0.3911 - val_accuracy: 0.8818\n",
            "Epoch 173/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.8032 - val_loss: 0.4023 - val_accuracy: 0.8707\n",
            "Epoch 174/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7996 - val_loss: 0.4521 - val_accuracy: 0.8478\n",
            "Epoch 175/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7908 - val_loss: 0.3990 - val_accuracy: 0.8759\n",
            "Epoch 176/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7912 - val_loss: 0.4032 - val_accuracy: 0.8571\n",
            "Epoch 177/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.8007 - val_loss: 0.4246 - val_accuracy: 0.8520\n",
            "Epoch 178/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7963 - val_loss: 0.3788 - val_accuracy: 0.8801\n",
            "Epoch 179/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.8025 - val_loss: 0.3967 - val_accuracy: 0.8869\n",
            "Epoch 180/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.7985 - val_loss: 0.4057 - val_accuracy: 0.8656\n",
            "Epoch 181/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7952 - val_loss: 0.4129 - val_accuracy: 0.8512\n",
            "Epoch 182/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.8094 - val_loss: 0.3969 - val_accuracy: 0.8563\n",
            "Epoch 183/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.8076 - val_loss: 0.3804 - val_accuracy: 0.8733\n",
            "Epoch 184/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7912 - val_loss: 0.3771 - val_accuracy: 0.8767\n",
            "Epoch 185/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.8087 - val_loss: 0.3798 - val_accuracy: 0.8878\n",
            "Epoch 186/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7952 - val_loss: 0.4131 - val_accuracy: 0.8469\n",
            "Epoch 187/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.8014 - val_loss: 0.3716 - val_accuracy: 0.8741\n",
            "Epoch 188/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7948 - val_loss: 0.3648 - val_accuracy: 0.8895\n",
            "Epoch 189/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7974 - val_loss: 0.3839 - val_accuracy: 0.8588\n",
            "Epoch 190/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.8076 - val_loss: 0.3636 - val_accuracy: 0.8963\n",
            "Epoch 191/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.8109 - val_loss: 0.3607 - val_accuracy: 0.8767\n",
            "Epoch 192/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.8098 - val_loss: 0.3794 - val_accuracy: 0.8631\n",
            "Epoch 193/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.8007 - val_loss: 0.4666 - val_accuracy: 0.8078\n",
            "Epoch 194/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.8050 - val_loss: 0.3582 - val_accuracy: 0.8835\n",
            "Epoch 195/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.8061 - val_loss: 0.3438 - val_accuracy: 0.8801\n",
            "Epoch 196/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.8211 - val_loss: 0.3697 - val_accuracy: 0.8793\n",
            "Epoch 197/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.8185 - val_loss: 0.3934 - val_accuracy: 0.8690\n",
            "Epoch 198/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.8163 - val_loss: 0.3603 - val_accuracy: 0.8835\n",
            "Epoch 199/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.8163 - val_loss: 0.3417 - val_accuracy: 0.8937\n",
            "Epoch 200/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.8174 - val_loss: 0.3916 - val_accuracy: 0.8580\n",
            "Epoch 201/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.8116 - val_loss: 0.3874 - val_accuracy: 0.8682\n",
            "Epoch 202/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8196 - val_loss: 0.3831 - val_accuracy: 0.8750\n",
            "Epoch 203/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.8163 - val_loss: 0.3654 - val_accuracy: 0.8827\n",
            "Epoch 204/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.8225 - val_loss: 0.3264 - val_accuracy: 0.9082\n",
            "Epoch 205/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.8152 - val_loss: 0.3587 - val_accuracy: 0.8852\n",
            "Epoch 206/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.8076 - val_loss: 0.3681 - val_accuracy: 0.8827\n",
            "Epoch 207/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.8262 - val_loss: 0.3733 - val_accuracy: 0.8801\n",
            "Epoch 208/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.8203 - val_loss: 0.3686 - val_accuracy: 0.8835\n",
            "Epoch 209/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.8280 - val_loss: 0.3836 - val_accuracy: 0.8682\n",
            "Epoch 210/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.8258 - val_loss: 0.3419 - val_accuracy: 0.8946\n",
            "Epoch 211/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.8233 - val_loss: 0.3463 - val_accuracy: 0.8861\n",
            "Epoch 212/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8160 - val_loss: 0.3555 - val_accuracy: 0.8818\n",
            "Epoch 213/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.8233 - val_loss: 0.3654 - val_accuracy: 0.8759\n",
            "Epoch 214/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.8298 - val_loss: 0.3421 - val_accuracy: 0.8929\n",
            "Epoch 215/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.8251 - val_loss: 0.3897 - val_accuracy: 0.8665\n",
            "Epoch 216/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.8265 - val_loss: 0.3538 - val_accuracy: 0.8903\n",
            "Epoch 217/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8265 - val_loss: 0.3411 - val_accuracy: 0.8886\n",
            "Epoch 218/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8386 - val_loss: 0.3647 - val_accuracy: 0.8903\n",
            "Epoch 219/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.8302 - val_loss: 0.3449 - val_accuracy: 0.8835\n",
            "Epoch 220/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.8211 - val_loss: 0.3354 - val_accuracy: 0.9090\n",
            "Epoch 221/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.8192 - val_loss: 0.3541 - val_accuracy: 0.8852\n",
            "Epoch 222/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.8214 - val_loss: 0.3533 - val_accuracy: 0.8716\n",
            "Epoch 223/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8338 - val_loss: 0.3447 - val_accuracy: 0.9014\n",
            "Epoch 224/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.8163 - val_loss: 0.3596 - val_accuracy: 0.8733\n",
            "Epoch 225/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.8222 - val_loss: 0.3810 - val_accuracy: 0.8699\n",
            "Epoch 226/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.8251 - val_loss: 0.3373 - val_accuracy: 0.8903\n",
            "Epoch 227/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8273 - val_loss: 0.3724 - val_accuracy: 0.8716\n",
            "Epoch 228/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8345 - val_loss: 0.3341 - val_accuracy: 0.9039\n",
            "Epoch 229/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8473 - val_loss: 0.3464 - val_accuracy: 0.8835\n",
            "Epoch 230/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.8324 - val_loss: 0.3515 - val_accuracy: 0.8750\n",
            "Epoch 231/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8349 - val_loss: 0.3203 - val_accuracy: 0.8954\n",
            "Epoch 232/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8331 - val_loss: 0.3369 - val_accuracy: 0.8920\n",
            "Epoch 233/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8276 - val_loss: 0.3371 - val_accuracy: 0.8954\n",
            "Epoch 234/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8353 - val_loss: 0.3646 - val_accuracy: 0.8750\n",
            "Epoch 235/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8335 - val_loss: 0.3335 - val_accuracy: 0.8920\n",
            "Epoch 236/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8236 - val_loss: 0.3223 - val_accuracy: 0.9056\n",
            "Epoch 237/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8342 - val_loss: 0.3352 - val_accuracy: 0.8988\n",
            "Epoch 238/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8367 - val_loss: 0.4011 - val_accuracy: 0.8571\n",
            "Epoch 239/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.8411 - val_loss: 0.3344 - val_accuracy: 0.9031\n",
            "Epoch 240/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8251 - val_loss: 0.3481 - val_accuracy: 0.8895\n",
            "Epoch 241/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8342 - val_loss: 0.3480 - val_accuracy: 0.8937\n",
            "Epoch 242/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8418 - val_loss: 0.3206 - val_accuracy: 0.9056\n",
            "Epoch 243/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8397 - val_loss: 0.3510 - val_accuracy: 0.8818\n",
            "Epoch 244/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8291 - val_loss: 0.3284 - val_accuracy: 0.8946\n",
            "Epoch 245/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8437 - val_loss: 0.3212 - val_accuracy: 0.9073\n",
            "Epoch 246/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8404 - val_loss: 0.3167 - val_accuracy: 0.9031\n",
            "Epoch 247/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8382 - val_loss: 0.3916 - val_accuracy: 0.8478\n",
            "Epoch 248/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8291 - val_loss: 0.3502 - val_accuracy: 0.8844\n",
            "Epoch 249/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8324 - val_loss: 0.3523 - val_accuracy: 0.8767\n",
            "Epoch 250/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8437 - val_loss: 0.3212 - val_accuracy: 0.8954\n",
            "Epoch 251/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8455 - val_loss: 0.3423 - val_accuracy: 0.8912\n",
            "Epoch 252/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8364 - val_loss: 0.3454 - val_accuracy: 0.8912\n",
            "Epoch 253/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8411 - val_loss: 0.3731 - val_accuracy: 0.8724\n",
            "Epoch 254/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8360 - val_loss: 0.3354 - val_accuracy: 0.9005\n",
            "Epoch 255/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8495 - val_loss: 0.3312 - val_accuracy: 0.8920\n",
            "Epoch 256/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8360 - val_loss: 0.3335 - val_accuracy: 0.8793\n",
            "Epoch 257/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8345 - val_loss: 0.3430 - val_accuracy: 0.8929\n",
            "Epoch 258/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8338 - val_loss: 0.3690 - val_accuracy: 0.8631\n",
            "Epoch 259/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8349 - val_loss: 0.3150 - val_accuracy: 0.8997\n",
            "Epoch 260/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8378 - val_loss: 0.3858 - val_accuracy: 0.8639\n",
            "Epoch 261/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8404 - val_loss: 0.3233 - val_accuracy: 0.8988\n",
            "Epoch 262/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8466 - val_loss: 0.3316 - val_accuracy: 0.8861\n",
            "Epoch 263/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8407 - val_loss: 0.3196 - val_accuracy: 0.8954\n",
            "Epoch 264/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8528 - val_loss: 0.3744 - val_accuracy: 0.8665\n",
            "Epoch 265/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8458 - val_loss: 0.3355 - val_accuracy: 0.8895\n",
            "Epoch 266/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8520 - val_loss: 0.3173 - val_accuracy: 0.9031\n",
            "Epoch 267/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8586 - val_loss: 0.3091 - val_accuracy: 0.9031\n",
            "Epoch 268/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8517 - val_loss: 0.3499 - val_accuracy: 0.8682\n",
            "Epoch 269/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8553 - val_loss: 0.3211 - val_accuracy: 0.9099\n",
            "Epoch 270/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8280 - val_loss: 0.3668 - val_accuracy: 0.8707\n",
            "Epoch 271/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8571 - val_loss: 0.3700 - val_accuracy: 0.8759\n",
            "Epoch 272/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8491 - val_loss: 0.2926 - val_accuracy: 0.9090\n",
            "Epoch 273/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8513 - val_loss: 0.2872 - val_accuracy: 0.9141\n",
            "Epoch 274/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8400 - val_loss: 0.3576 - val_accuracy: 0.8793\n",
            "Epoch 275/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8480 - val_loss: 0.3760 - val_accuracy: 0.8597\n",
            "Epoch 276/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8542 - val_loss: 0.3001 - val_accuracy: 0.8988\n",
            "Epoch 277/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8484 - val_loss: 0.3048 - val_accuracy: 0.8886\n",
            "Epoch 278/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8550 - val_loss: 0.3170 - val_accuracy: 0.8903\n",
            "Epoch 279/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8499 - val_loss: 0.2860 - val_accuracy: 0.9141\n",
            "Epoch 280/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8560 - val_loss: 0.2939 - val_accuracy: 0.9133\n",
            "Epoch 281/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8550 - val_loss: 0.3129 - val_accuracy: 0.9014\n",
            "Epoch 282/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8542 - val_loss: 0.3155 - val_accuracy: 0.8963\n",
            "Epoch 283/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8466 - val_loss: 0.3073 - val_accuracy: 0.8971\n",
            "Epoch 284/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8506 - val_loss: 0.3101 - val_accuracy: 0.9124\n",
            "Epoch 285/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8491 - val_loss: 0.3260 - val_accuracy: 0.8980\n",
            "Epoch 286/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8590 - val_loss: 0.2737 - val_accuracy: 0.9226\n",
            "Epoch 287/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8513 - val_loss: 0.2877 - val_accuracy: 0.9116\n",
            "Epoch 288/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8524 - val_loss: 0.3268 - val_accuracy: 0.8784\n",
            "Epoch 289/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8433 - val_loss: 0.3466 - val_accuracy: 0.8827\n",
            "Epoch 290/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8550 - val_loss: 0.3323 - val_accuracy: 0.8844\n",
            "Epoch 291/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8564 - val_loss: 0.3229 - val_accuracy: 0.8954\n",
            "Epoch 292/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8491 - val_loss: 0.3514 - val_accuracy: 0.8793\n",
            "Epoch 293/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8531 - val_loss: 0.3540 - val_accuracy: 0.8801\n",
            "Epoch 294/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8542 - val_loss: 0.3527 - val_accuracy: 0.8810\n",
            "Epoch 295/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8630 - val_loss: 0.3271 - val_accuracy: 0.8912\n",
            "Epoch 296/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8586 - val_loss: 0.3146 - val_accuracy: 0.9022\n",
            "Epoch 297/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8564 - val_loss: 0.3370 - val_accuracy: 0.8835\n",
            "Epoch 298/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8466 - val_loss: 0.3527 - val_accuracy: 0.8818\n",
            "Epoch 299/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8499 - val_loss: 0.3094 - val_accuracy: 0.9039\n",
            "Epoch 300/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8477 - val_loss: 0.3348 - val_accuracy: 0.8912\n",
            "Epoch 301/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8542 - val_loss: 0.3642 - val_accuracy: 0.8656\n",
            "Epoch 302/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8608 - val_loss: 0.3613 - val_accuracy: 0.8690\n",
            "Epoch 303/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8692 - val_loss: 0.3450 - val_accuracy: 0.8759\n",
            "Epoch 304/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8608 - val_loss: 0.3336 - val_accuracy: 0.8920\n",
            "Epoch 305/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8560 - val_loss: 0.3932 - val_accuracy: 0.8520\n",
            "Epoch 306/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8666 - val_loss: 0.3023 - val_accuracy: 0.9099\n",
            "Epoch 307/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8663 - val_loss: 0.3156 - val_accuracy: 0.8963\n",
            "Epoch 308/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8677 - val_loss: 0.2984 - val_accuracy: 0.9065\n",
            "Epoch 309/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8648 - val_loss: 0.3214 - val_accuracy: 0.9005\n",
            "Epoch 310/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8604 - val_loss: 0.3003 - val_accuracy: 0.9039\n",
            "Epoch 311/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8648 - val_loss: 0.3258 - val_accuracy: 0.9005\n",
            "Epoch 312/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8692 - val_loss: 0.3129 - val_accuracy: 0.8954\n",
            "Epoch 313/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8641 - val_loss: 0.3121 - val_accuracy: 0.8954\n",
            "Epoch 314/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8601 - val_loss: 0.3363 - val_accuracy: 0.8869\n",
            "Epoch 315/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8673 - val_loss: 0.2997 - val_accuracy: 0.8946\n",
            "Epoch 316/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8794 - val_loss: 0.2774 - val_accuracy: 0.9133\n",
            "Epoch 317/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8633 - val_loss: 0.3157 - val_accuracy: 0.8954\n",
            "Epoch 318/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8637 - val_loss: 0.3582 - val_accuracy: 0.8801\n",
            "Epoch 319/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8619 - val_loss: 0.2889 - val_accuracy: 0.9133\n",
            "Epoch 320/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8743 - val_loss: 0.3595 - val_accuracy: 0.8622\n",
            "Epoch 321/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8524 - val_loss: 0.3089 - val_accuracy: 0.8971\n",
            "Epoch 322/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8670 - val_loss: 0.3015 - val_accuracy: 0.9065\n",
            "Epoch 323/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8757 - val_loss: 0.3170 - val_accuracy: 0.8861\n",
            "Epoch 324/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3534 - accuracy: 0.8593 - val_loss: 0.3284 - val_accuracy: 0.8861\n",
            "Epoch 325/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8633 - val_loss: 0.3561 - val_accuracy: 0.8759\n",
            "Epoch 326/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.8688 - val_loss: 0.3102 - val_accuracy: 0.9048\n",
            "Epoch 327/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8783 - val_loss: 0.3279 - val_accuracy: 0.8793\n",
            "Epoch 328/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8797 - val_loss: 0.3232 - val_accuracy: 0.8835\n",
            "Epoch 329/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8626 - val_loss: 0.3190 - val_accuracy: 0.8844\n",
            "Epoch 330/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8717 - val_loss: 0.3150 - val_accuracy: 0.8929\n",
            "Epoch 331/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8724 - val_loss: 0.3482 - val_accuracy: 0.8665\n",
            "Epoch 332/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3526 - accuracy: 0.8684 - val_loss: 0.3008 - val_accuracy: 0.9056\n",
            "Epoch 333/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8593 - val_loss: 0.3030 - val_accuracy: 0.9022\n",
            "Epoch 334/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8721 - val_loss: 0.3048 - val_accuracy: 0.9014\n",
            "Epoch 335/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8652 - val_loss: 0.2976 - val_accuracy: 0.9073\n",
            "Epoch 336/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8732 - val_loss: 0.3189 - val_accuracy: 0.8844\n",
            "Epoch 337/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8728 - val_loss: 0.3406 - val_accuracy: 0.8784\n",
            "Epoch 338/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8666 - val_loss: 0.2935 - val_accuracy: 0.9022\n",
            "Epoch 339/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8743 - val_loss: 0.3152 - val_accuracy: 0.8903\n",
            "Epoch 340/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8575 - val_loss: 0.3314 - val_accuracy: 0.8869\n",
            "Epoch 341/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8703 - val_loss: 0.3320 - val_accuracy: 0.8844\n",
            "Epoch 342/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8703 - val_loss: 0.3163 - val_accuracy: 0.8980\n",
            "Epoch 343/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8626 - val_loss: 0.3281 - val_accuracy: 0.8801\n",
            "Epoch 344/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8714 - val_loss: 0.3095 - val_accuracy: 0.9031\n",
            "Epoch 345/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8794 - val_loss: 0.3253 - val_accuracy: 0.8844\n",
            "Epoch 346/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8717 - val_loss: 0.3130 - val_accuracy: 0.8946\n",
            "Epoch 347/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8721 - val_loss: 0.3899 - val_accuracy: 0.8546\n",
            "Epoch 348/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8717 - val_loss: 0.3006 - val_accuracy: 0.9048\n",
            "Epoch 349/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8797 - val_loss: 0.3433 - val_accuracy: 0.8835\n",
            "Epoch 350/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8794 - val_loss: 0.3557 - val_accuracy: 0.8724\n",
            "Epoch 351/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8626 - val_loss: 0.3591 - val_accuracy: 0.8699\n",
            "Epoch 352/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8681 - val_loss: 0.3269 - val_accuracy: 0.8997\n",
            "Epoch 353/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.8703 - val_loss: 0.3475 - val_accuracy: 0.8639\n",
            "Epoch 354/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8619 - val_loss: 0.2955 - val_accuracy: 0.8920\n",
            "Epoch 355/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8794 - val_loss: 0.2829 - val_accuracy: 0.9082\n",
            "Epoch 356/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8746 - val_loss: 0.2999 - val_accuracy: 0.8852\n",
            "Epoch 357/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8652 - val_loss: 0.3142 - val_accuracy: 0.8810\n",
            "Epoch 358/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8699 - val_loss: 0.3169 - val_accuracy: 0.8827\n",
            "Epoch 359/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.8863 - val_loss: 0.2986 - val_accuracy: 0.9014\n",
            "Epoch 360/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8819 - val_loss: 0.3324 - val_accuracy: 0.8818\n",
            "Epoch 361/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8732 - val_loss: 0.3418 - val_accuracy: 0.8741\n",
            "Epoch 362/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3190 - accuracy: 0.8790 - val_loss: 0.3878 - val_accuracy: 0.8631\n",
            "Epoch 363/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3152 - accuracy: 0.8816 - val_loss: 0.3402 - val_accuracy: 0.8886\n",
            "Epoch 364/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8768 - val_loss: 0.3315 - val_accuracy: 0.8818\n",
            "Epoch 365/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3246 - accuracy: 0.8801 - val_loss: 0.3177 - val_accuracy: 0.8827\n",
            "Epoch 366/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8830 - val_loss: 0.3159 - val_accuracy: 0.8835\n",
            "Epoch 367/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8797 - val_loss: 0.2860 - val_accuracy: 0.9082\n",
            "Epoch 368/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.8932 - val_loss: 0.3007 - val_accuracy: 0.9048\n",
            "Epoch 369/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8823 - val_loss: 0.3268 - val_accuracy: 0.8776\n",
            "Epoch 370/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8794 - val_loss: 0.3213 - val_accuracy: 0.8861\n",
            "Epoch 371/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8786 - val_loss: 0.3093 - val_accuracy: 0.8929\n",
            "Epoch 372/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8768 - val_loss: 0.2860 - val_accuracy: 0.9082\n",
            "Epoch 373/400\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8732 - val_loss: 0.3491 - val_accuracy: 0.8656\n",
            "Epoch 374/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3099 - accuracy: 0.8794 - val_loss: 0.2803 - val_accuracy: 0.9158\n",
            "Epoch 375/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8830 - val_loss: 0.3039 - val_accuracy: 0.8988\n",
            "Epoch 376/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8732 - val_loss: 0.2970 - val_accuracy: 0.9031\n",
            "Epoch 377/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8750 - val_loss: 0.3095 - val_accuracy: 0.8963\n",
            "Epoch 378/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8670 - val_loss: 0.3396 - val_accuracy: 0.8759\n",
            "Epoch 379/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8688 - val_loss: 0.3327 - val_accuracy: 0.8920\n",
            "Epoch 380/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8819 - val_loss: 0.3030 - val_accuracy: 0.9022\n",
            "Epoch 381/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8794 - val_loss: 0.3223 - val_accuracy: 0.8827\n",
            "Epoch 382/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8914 - val_loss: 0.2978 - val_accuracy: 0.9031\n",
            "Epoch 383/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8856 - val_loss: 0.3739 - val_accuracy: 0.8571\n",
            "Epoch 384/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8819 - val_loss: 0.3278 - val_accuracy: 0.8784\n",
            "Epoch 385/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8856 - val_loss: 0.3890 - val_accuracy: 0.8546\n",
            "Epoch 386/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8819 - val_loss: 0.2926 - val_accuracy: 0.9073\n",
            "Epoch 387/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.8786 - val_loss: 0.3272 - val_accuracy: 0.8869\n",
            "Epoch 388/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8874 - val_loss: 0.3624 - val_accuracy: 0.8597\n",
            "Epoch 389/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8848 - val_loss: 0.3091 - val_accuracy: 0.8997\n",
            "Epoch 390/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8808 - val_loss: 0.3140 - val_accuracy: 0.8920\n",
            "Epoch 391/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.8936 - val_loss: 0.3369 - val_accuracy: 0.8699\n",
            "Epoch 392/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.8834 - val_loss: 0.3658 - val_accuracy: 0.8520\n",
            "Epoch 393/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8827 - val_loss: 0.2932 - val_accuracy: 0.9056\n",
            "Epoch 394/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8918 - val_loss: 0.3417 - val_accuracy: 0.8776\n",
            "Epoch 395/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8896 - val_loss: 0.3013 - val_accuracy: 0.8946\n",
            "Epoch 396/400\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8779 - val_loss: 0.3237 - val_accuracy: 0.8810\n",
            "Epoch 397/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8918 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
            "Epoch 398/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8870 - val_loss: 0.3630 - val_accuracy: 0.8707\n",
            "Epoch 399/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3077 - accuracy: 0.8801 - val_loss: 0.3429 - val_accuracy: 0.8776\n",
            "Epoch 400/400\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3012 - accuracy: 0.8856 - val_loss: 0.3276 - val_accuracy: 0.8852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgPaKlVyysAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "15228daf-8c83-46e5-e6b8-ca06b90db587"
      },
      "source": [
        "plt.plot(classifier.history['loss'])\n",
        "plt.plot(classifier.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbTiNPYe9aQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0fcadb8a-0da1-4978-fcfa-729196d0d92a"
      },
      "source": [
        "plt.plot(classifier.history['accuracy'])\n",
        "plt.plot(classifier.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57wVi2Q79rqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f4e1363a-ceee-4164-b0d2-622e5c7f71ca"
      },
      "source": [
        "model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-bc459dba29cd>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 12,  4, ..., 13, 12, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cK1LXsKXcJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68c34018-4e9f-4793-ebdd-a7656c01bcc1"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 12,  4, ..., 13, 12, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMIS48dIXoyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5a99eeeb-5ae4-4a7d-a71d-bb849f02af4e"
      },
      "source": [
        "model.evaluate(x=X_test, y=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3275521993637085, 0.8852040767669678]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr9CIeMWryq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}