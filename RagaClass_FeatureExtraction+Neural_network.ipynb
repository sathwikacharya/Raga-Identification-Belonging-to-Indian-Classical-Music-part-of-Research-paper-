{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RagaClass-FeatureExtraction+Algo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4EmfUAjDuhc",
        "colab_type": "text"
      },
      "source": [
        "#Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdJFDmw1CIPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df4ip8iRBpiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('dataset-new.csv')\n",
        "# Dropping unneccesary columns\n",
        "data = data.drop(['filename'],axis=1)\n",
        "#Encoding the Labels\n",
        "raga_list = data.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR6Bcn1hHQtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "429635f9-9c92-4899-c00f-c21efa5fd0d1"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3V33nSTDhqC",
        "colab_type": "text"
      },
      "source": [
        "#XGBoost + Pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl4UITEGBWAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "595ad587-8e5e-4e8a-d375-0edc6ed23cbf"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMw-4t4rCM7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
        "D_test = xgb.DMatrix(X_test, label=Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8QM8Em3CiLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = {\n",
        "    'eta': 0.04, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,                  #Change when number of raga changes\n",
        "    'base_score': 0.5,\n",
        "    'booster':'gbtree',\n",
        "    'colsample_bylevel':1,\n",
        "    'colsample_bynode':1, \n",
        "    'colsample_bytree':0.7, \n",
        "    'gamma':0.0,\n",
        "    'learning_rate':0.1, \n",
        "    'min_child_weight':1, \n",
        "    'n_estimators':100, \n",
        "    'n_jobs':1,\n",
        "} \n",
        "\n",
        "steps = 20  # The number of training iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNv7MHskCkyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = xgb.train(param, D_train, steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYQf8zCNCyKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "165b96cb-867a-468f-e16d-93d73f43dc08"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "preds = model.predict(D_test)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
        "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
        "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 1.0\n",
            "Recall = 1.0\n",
            "Accuracy = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpcCenxifwyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "songname='/content/abogi.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "example=xgb.DMatrix(example)\n",
        "preds = model.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(best_preds)\n",
        "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w6XaFaDlU4",
        "colab_type": "text"
      },
      "source": [
        "#Logistic Regression + Pred\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08DrpBUkDpPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f5584152-4919-43c3-df95-d7366e3e3fb8"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "print('Accuracy of LogisticRegress classifier on training set: {:.3f}'.format(logreg.score(X_train, Y_train)))\n",
        "print('Accuracy of LogisticRegress classifier on test set: {:.3f}'.format(logreg.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LogisticRegress classifier on training set: 0.830\n",
            "Accuracy of LogisticRegress classifier on test set: 0.757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40vHTmbqF4ob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6914e743-0f00-46c2-f273-5ae5ed7225ed"
      },
      "source": [
        "import librosa\n",
        "songname='/content/hindolam.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = logreg.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwj3OAn0EoBH",
        "colab_type": "text"
      },
      "source": [
        "#Naive Bayes + Pred\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM1kTBRcEq7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4b22950c-651e-4bb0-a04f-0c5eaa5dd7c0"
      },
      "source": [
        "y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
        "modelNB = MultinomialNB()   \n",
        "modelNB.fit(X_train, Y_train)\n",
        "print('Accuracy of NaiveBayes classifier on training set: {:.2f}'.format(modelNB.score(X_train, Y_train)))\n",
        "print('Accuracy of NaiveBayes classifier on test set: {:.2f}'.format(modelNB.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of NaiveBayes classifier on training set: 0.44\n",
            "Accuracy of NaiveBayes classifier on test set: 0.38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3heLVQN8Ia6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2f9e3f04-32a3-49ff-c0c7-36de9f82e41f"
      },
      "source": [
        "import librosa\n",
        "songname='/content/abogi.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = modelNB.predict(example)\n",
        "#best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij1RE5crJ1dA",
        "colab_type": "text"
      },
      "source": [
        "#Random Forest + Preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO_PhrWEJ5PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "rf.fit(X_train, Y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1wvSWEbKGrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a1d557fe-d890-451f-d9b1-14fda7ef1090"
      },
      "source": [
        "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_train, Y_train)))\n",
        "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_test, Y_test)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of RandomForest classifier on training set: 1.00\n",
            "Accuracy of RandomForest classifier on training set: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3HW_QyMKf25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "f05e6964-eece-4f3d-cb8b-1cbd07cd7d1f"
      },
      "source": [
        "import librosa\n",
        "songname='/content/hindolam.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = rf.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(best_preds)\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dc7690f9f467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msongname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/hindolam.mp3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchroma_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hindolam.mp3'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "svPnSufGTfeS"
      },
      "source": [
        "#Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-SNS8rlsTfeT",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "InyDbmqVTfeW",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('dataset-nosource.csv')\n",
        "# Dropping unneccesary columns\n",
        "data = data.drop(['filename'],axis=1)\n",
        "#Encoding the Labels\n",
        "raga_list = data.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wyDAG_hZTfeY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1948038b-63ba-4758-b57c-e02548a4aa1b"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 5 5 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oY5sQhmpTfeb"
      },
      "source": [
        "#XGBoost + Pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qeILMpQ5Tfeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "90f98fc9-5354-45e4-f65c-dea5c90b056e"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CA2uQqf3Tfed",
        "colab": {}
      },
      "source": [
        "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
        "D_test = xgb.DMatrix(X_test, label=Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sW_wiYPkTfef",
        "colab": {}
      },
      "source": [
        "param = {\n",
        "    'eta': 0.04, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,                  #Change when number of raga changes\n",
        "    'base_score': 0.5,\n",
        "    'booster':'gbtree',\n",
        "    'colsample_bylevel':1,\n",
        "    'colsample_bynode':1, \n",
        "    'colsample_bytree':0.7, \n",
        "    'gamma':0.0,\n",
        "    'learning_rate':0.1, \n",
        "    'min_child_weight':1, \n",
        "    'n_estimators':100, \n",
        "    'n_jobs':1,\n",
        "} \n",
        "\n",
        "steps = 20  # The number of training iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h_FvGfdfTfei",
        "colab": {}
      },
      "source": [
        "model = xgb.train(param, D_train, steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wj66qxz_Tfek",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "8a62cc6a-33d9-4caf-9f58-4719cb1c6446"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "preds = model.predict(D_test)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
        "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
        "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.9962962962962962\n",
            "Recall = 0.9975609756097562\n",
            "Accuracy = 0.9966666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gonFKyFwTfem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "33899373-1953-47ab-93c8-c612094420fa"
      },
      "source": [
        "import librosa\n",
        "songname='/content/abogi.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "example=xgb.DMatrix(example)\n",
        "preds = model.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(best_preds)\n",
        "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Is3kzHzmTfeo"
      },
      "source": [
        "#Logistic Regression + Pred\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iPYv2OfOTfep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "6f3e1a64-738d-40fa-8aff-94f9a172ab27"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "print('Accuracy of LogisticRegress classifier on training set: {:.3f}'.format(logreg.score(X_train, Y_train)))\n",
        "print('Accuracy of LogisticRegress classifier on test set: {:.3f}'.format(logreg.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LogisticRegress classifier on training set: 0.837\n",
            "Accuracy of LogisticRegress classifier on test set: 0.790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5bjESCZ-Tfer",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6914e743-0f00-46c2-f273-5ae5ed7225ed"
      },
      "source": [
        "import librosa\n",
        "songname='/content/hindolam.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = logreg.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UUGlPJvRTfet"
      },
      "source": [
        "#Naive Bayes + Pred\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wtbo4QKGTfet",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6b9a01aa-6901-4194-c90a-6409269e5bd4"
      },
      "source": [
        "y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
        "modelNB = MultinomialNB()   \n",
        "modelNB.fit(X_train, Y_train)\n",
        "print('Accuracy of NaiveBayes classifier on training set: {:.2f}'.format(modelNB.score(X_train, Y_train)))\n",
        "print('Accuracy of NaiveBayes classifier on test set: {:.2f}'.format(modelNB.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of NaiveBayes classifier on training set: 0.48\n",
            "Accuracy of NaiveBayes classifier on test set: 0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sywfv0nUTfew",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2f9e3f04-32a3-49ff-c0c7-36de9f82e41f"
      },
      "source": [
        "import librosa\n",
        "songname='/content/abogi.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = modelNB.predict(example)\n",
        "#best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SqVBIudiTfex"
      },
      "source": [
        "#Random Forest + Preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UbDi02oOTfey",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "rf.fit(X_train, Y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "keEuaL7WTfez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0baec4ff-e5f4-42d6-a16c-debb7fbeb9cb"
      },
      "source": [
        "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_train, Y_train)))\n",
        "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_test, Y_test)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of RandomForest classifier on training set: 1.00\n",
            "Accuracy of RandomForest classifier on training set: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l-Hs225dTfe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "f05e6964-eece-4f3d-cb8b-1cbd07cd7d1f"
      },
      "source": [
        "import librosa\n",
        "songname='/content/hindolam.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = rf.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(best_preds)\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dc7690f9f467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msongname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/hindolam.mp3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchroma_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hindolam.mp3'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Nmy6t_WVgB",
        "colab_type": "text"
      },
      "source": [
        "# 20 Ragas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMbCPvKJWtOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ghvazcc2Wxh6"
      },
      "source": [
        "#Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yepVTYmWxiB",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3RlfQaSkWxiF",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('dataset-big.csv')\n",
        "# Dropping unneccesary columns\n",
        "data = data.drop(['filename'],axis=1)\n",
        "#Encoding the Labels\n",
        "raga_list = data.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P1WqqKcXWxiH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a56b04a-ffe3-4665-e361-fbcfbfb59540"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1  1  1 ... 13 13 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TorQgJ3iWxiL"
      },
      "source": [
        "#XGBoost + Pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIfgIfugWxiL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "96d9006f-d56a-47df-a8ef-8a70f5c57e68"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aYwmOu3GWxiO",
        "colab": {}
      },
      "source": [
        "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
        "D_test = xgb.DMatrix(X_test, label=Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YxSQK68BWxiP",
        "colab": {}
      },
      "source": [
        "param = {\n",
        "    'eta': 0.04, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 20,                  #Change when number of raga changes\n",
        "    'base_score': 0.5,\n",
        "    'booster':'gbtree',\n",
        "    'colsample_bylevel':1,\n",
        "    'colsample_bynode':1, \n",
        "    'colsample_bytree':0.7, \n",
        "    'gamma':0.0,\n",
        "    'learning_rate':0.1, \n",
        "    'min_child_weight':1, \n",
        "    'n_estimators':100, \n",
        "    'n_jobs':1,\n",
        "} \n",
        "\n",
        "steps = 20  # The number of training iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CoetgfL7WxiS",
        "colab": {}
      },
      "source": [
        "model = xgb.train(param, D_train, steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6HC1c6mdWxiV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2dc6a235-f9a5-4f4c-a79d-ccb9b4f1a9b7"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "preds = model.predict(D_test)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
        "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
        "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.9959444444444443\n",
            "Recall = 0.9959565412186379\n",
            "Accuracy = 0.99609375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FXkGC1ErWxiX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "33899373-1953-47ab-93c8-c612094420fa"
      },
      "source": [
        "import librosa\n",
        "songname='/content/abogi.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "example=xgb.DMatrix(example)\n",
        "preds = model.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(best_preds)\n",
        "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "npoBqi-ZWxib"
      },
      "source": [
        "#Logistic Regression + Pred\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kMzPWI6VWxic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7c901451-77de-4841-ca99-d7a1fdb8cfe7"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "print('Accuracy of LogisticRegress classifier on training set: {:.3f}'.format(logreg.score(X_train, Y_train)))\n",
        "print('Accuracy of LogisticRegress classifier on test set: {:.3f}'.format(logreg.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LogisticRegress classifier on training set: 0.651\n",
            "Accuracy of LogisticRegress classifier on test set: 0.590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blkmO4n4Wxif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6914e743-0f00-46c2-f273-5ae5ed7225ed"
      },
      "source": [
        "import librosa\n",
        "songname='/content/hindolam.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = logreg.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1HowVqZdWxii"
      },
      "source": [
        "#Naive Bayes + Pred\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_p8xjRmWxij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "50bfa9fc-033f-4364-807b-9fe691cb5cfa"
      },
      "source": [
        "y = encoder.fit_transform(raga_list)\n",
        "#Scaling the Feature columns\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
        "#Dividing data into training and Testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
        "modelNB = MultinomialNB()   \n",
        "modelNB.fit(X_train, Y_train)\n",
        "print('Accuracy of NaiveBayes classifier on training set: {:.2f}'.format(modelNB.score(X_train, Y_train)))\n",
        "print('Accuracy of NaiveBayes classifier on test set: {:.2f}'.format(modelNB.score(X_test, Y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of NaiveBayes classifier on training set: 0.23\n",
            "Accuracy of NaiveBayes classifier on test set: 0.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N71azDnHWxil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2f9e3f04-32a3-49ff-c0c7-36de9f82e41f"
      },
      "source": [
        "import librosa\n",
        "songname='/content/abogi.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = modelNB.predict(example)\n",
        "#best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Raga for this song is : abhogi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLmk9paxWxip"
      },
      "source": [
        "#Random Forest + Preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FUaD6l05Wxip",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "rf.fit(X_train, Y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ux4bgU5gWxir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1d67a52e-c910-455b-989c-6f94053b701f"
      },
      "source": [
        "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_train, Y_train)))\n",
        "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_test, Y_test)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of RandomForest classifier on training set: 1.00\n",
            "Accuracy of RandomForest classifier on training set: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nqoLc2h9Wxiv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "f05e6964-eece-4f3d-cb8b-1cbd07cd7d1f"
      },
      "source": [
        "import librosa\n",
        "songname='/content/hindolam.mp3'\n",
        "x, sr = librosa.load(songname, mono=True, duration=30)\n",
        "rmse = librosa.feature.rmse(y=x)[0]\n",
        "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
        "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "zcr = librosa.feature.zero_crossing_rate(x)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "\n",
        "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
        "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
        "dataset=pd.DataFrame(columns=columns)\n",
        "dataseries = pd.Series(data, index = dataset.columns)\n",
        "dataset = dataset.append(dataseries, ignore_index=True)\n",
        "\n",
        "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
        "preds = rf.predict(example)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "raganame=set()\n",
        "for i in range(len(raga_list)):\n",
        "  raganame.add((raga_list[i],y[i]))\n",
        "raganame=list(raganame)\n",
        "raganame.sort()\n",
        "print(best_preds)\n",
        "print(preds)\n",
        "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dc7690f9f467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msongname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/hindolam.mp3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchroma_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hindolam.mp3'"
          ]
        }
      ]
    }
  ]
}